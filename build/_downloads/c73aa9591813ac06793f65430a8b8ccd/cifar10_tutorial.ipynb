{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668\n=====================\n**\u7ffb\u8bd1\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`_\n\n\u5c31\u662f\u8fd9\u4e2a!\u4f60\u5df2\u7ecf\u4e86\u89e3\u4e86\u5982\u4f55\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u3001\u8ba1\u7b97\u635f\u5931\u548c\u66f4\u65b0\u7f51\u7edc\u7684\u6743\u91cd\u3002\n\n\u73b0\u5728\u4f60\u53ef\u80fd\u5728\u60f3\uff0c.......\n\n\u6570\u636e\u5982\u4f55?\n----------------\n\n\u901a\u5e38\uff0c\u5f53\u4f60\u5fc5\u987b\u5904\u7406\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\u6216\u89c6\u9891\u6570\u636e\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u6807\u51c6python\u5305\u5c06\u6570\u636e\u52a0\u8f7d\u5230numpy\u6570\u7ec4\u4e2d\u3002\n\u7136\u540e\u4f60\u53ef\u4ee5\u628a\u8fd9\u4e2aarray\u8f6c\u6362\u6210\u4e00\u4e2a ``torch.*Tensor`` \u3002\n\n-  \u5bf9\u4e8e\u56fe\u50cf, packages \u6bd4\u5982 Pillow, OpenCV \u5f88\u6709\u7528\n-  \u5bf9\u4e8e\u97f3\u9891, packages \u6bd4\u5982 scipy \u548c librosa\n-  \u5bf9\u4e8e\u6587\u672c, \u6216\u8005 raw Python \u6216\u8005 Cython based \u52a0\u8f7d, \u6216 NLTK \u548cSpaCy \u5f88\u6709\u7528\n\n\u6211\u4eec\u4e13\u95e8\u4e3avision\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a ``torchvision`` \u7684\u5305\uff0c\u5b83\u4e3a\u5e38\u89c1\u6570\u636e\u96c6(\u5982Imagenet\u3001CIFAR 10\u3001MNIST\u7b49)\u63d0\u4f9b\u4e86\u6570\u636e\u52a0\u8f7d\u5668\u3002\n\u4ee5\u53ca\u7528\u4e8e\u56fe\u50cf\u7684\u6570\u636e\u53d8\u6362\u5668(data transformers)\uff0c\u5373 ``torchvision.datasets`` \u548c ``torch.utils.data.DataLoader`` \u3002\n\n\u8fd9\u63d0\u4f9b\u4e86\u5de8\u5927\u7684\u65b9\u4fbf\uff0c\u907f\u514d\u4e86\u7f16\u5199\u6837\u677f\u4ee3\u7801\u3002\n\n\u5bf9\u4e8e\u672c\u6559\u7a0b\uff0c\u6211\u4eec\u5c06\u4f7f\u7528CIFAR 10\u6570\u636e\u96c6\u3002\u5b83\u6709\u201c\u98de\u673a\u201d\u3001\u201c\u6c7d\u8f66\u201d\u3001\u201c\u9e1f\u201d\u3001\u201c\u732b\u201d\u3001\u201c\u9e7f\u201d\u3001\u201c\u72d7\u201d\u3001\u201c\u9752\u86d9\u201d\u3001\u201c\u9a6c\u201d\u3001\u201c\u8239\u201d\u3001\u201c\u5361\u8f66\u201d\u3002\nCIFAR-10\u4e2d\u7684\u56fe\u50cf\u5927\u5c0f\u4e3a3x32x32\uff0c\u5373\u5c3a\u5bf8\u4e3a32x32\u50cf\u7d20\u76843\u901a\u9053\u5f69\u8272\u56fe\u50cf\u3002\n\n.. figure:: /_static/img/cifar10.png\n   :alt: cifar10\n\n   cifar10\n\n\n\u8bad\u7ec3\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u5668\n----------------------------\n\n\u6211\u4eec\u5c06\u6309\u987a\u5e8f\u505a\u4e00\u4e0b\u51e0\u6b65\u4e8b\u60c5:\n\n1. \u4f7f\u7528 ``torchvision`` \u52a0\u8f7d\u548c\u5f52\u4e00\u5316 CIFAR10 \u8bad\u7ec3\u96c6 \u548c \u6d4b\u8bd5\u96c6\n2. \u5b9a\u4e49\u4e00\u4e2a \u5377\u79ef\u795e\u7ecf\u7f51\u7edc(Convolutional Neural Network)\n3. \u5b9a\u4e49\u4e00\u4e2a\u635f\u5931\u51fd\u6570\n4. \u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\u7f51\u7edc\n5. \u5728\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u7f51\u7edc\n\n1. \u52a0\u8f7d\u548c\u5f52\u4e00\u5316 CIFAR10\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\u4f7f\u7528 ``torchvision``, \u52a0\u8f7d CIFAR10 \u6781\u5176\u7b80\u5355\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchvision\nimport torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "torchvision datasets \u7684\u8f93\u51fa\u662f PILImage \u7c7b\u578b\u7684 images, \u50cf\u7d20\u53d6\u503c\u8303\u56f4\u5728 [0, 1]\u3002\n\u6211\u4eec\u5c06\u5176\u53d8\u6362\u4e3a\u5f52\u4e00\u5316\u8303\u56f4\u5728[-1 , 1] \u7684 Tensors \u7c7b\u578b\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='../data/cifar10', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8ba9\u6211\u4eec\u663e\u793a\u4e00\u4e9b\u8bad\u7ec3\u96c6\u4e2d\u7684\u56fe\u50cf, \u73a9\u73a9.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# \u7528\u4e8e\u663e\u793a\u4e00\u5f20\u56fe\u50cf\u7684\u51fd\u6570\ndef imshow(img, title=None):\n    img = img / 2 + 0.5     # \u53bb\u5f52\u4e00\u5316\n    npimg = img.numpy()\n    plt.figure(figsize=[6.5, 2.5])\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.axis('off')\n    if title is not None:\n        plt.title(title)\n    plt.show()\n    plt.pause(0.1)\n\n\n# \u968f\u673a\u83b7\u53d6\u4e00\u4e9b\u8bad\u7ec3\u96c6\u56fe\u7247\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# \u663e\u793a\u56fe\u50cf\nimshow(torchvision.utils.make_grid(images),\"One Batch Train Images\")\n# \u8f93\u51fa\u5bf9\u5e94\u7684\u6807\u7b7e\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. \u5b9a\u4e49\u4e00\u4e2a \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u628a\u6211\u4eec\u4e0a\u4e00\u8282\u5b9a\u4e49\u7684\u795e\u7ecf\u7f51\u7edc\u62f7\u8d1d\u8fc7\u6765\u7136\u540e\u4fee\u6539\uff0c\n\u8ba9\u5b83\u63a5\u53d7 3-\u901a\u9053 \u56fe\u50cf (\u6211\u4eec\u4e0a\u8282\u5b9a\u4e49\u7684\u662f\u5355\u901a\u9053\u7684\u56fe\u50cf\u8f93\u5165)\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u8ba9\u6211\u4eec\u4f7f\u7528 \u5206\u7c7b\u4ea4\u53c9\u71b5\u635f\u5931(Classification Cross-Entropy loss)\u548c\u5e26\u6709\u52a8\u91cf\u9879\u7684SGD\u4f18\u5316\u5668\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. \u8bad\u7ec3\u7f51\u7edc\n^^^^^^^^^^^^^^^^^^^^\n\n\u8fd9\u662f\u4e8b\u60c5\u5f00\u59cb\u53d8\u5f97\u6709\u8da3\u7684\u65f6\u5019\u3002\u6211\u4eec\u53ea\u9700\u5728\u6570\u636e\u8fed\u4ee3\u5668(data iterator)\u4e0a\u5faa\u73af\uff0c\u5e76\u5c06\u8f93\u5165\u63d0\u4f9b\u7ed9\u7f51\u7edc\u5e76\u8fdb\u884c\u4f18\u5316\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # \u5728\u6574\u4e2a\u6570\u636e\u96c6\u4e0a\u8f6e\u756a\u8bad\u7ec3\u591a\u6b21\uff0c\u8f6e\u8bad\u4e00\u6b21\u53eb\u4e00\u4e2a\u56de\u5408(epoch)\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # \u83b7\u5f97\u8f93\u5165\n        inputs, labels = data\n\n        # \u5c06\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u68af\u5ea6\u5168\u90e8\u7f6e\u96f6\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # \u8f93\u51fa\u4e00\u4e9b\u5173\u4e8e\u8bad\u7ec3\u7684\u7edf\u8ba1\u4fe1\u606f\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # \u6bcf 2000 \u4e2a mini-batches \u8f93\u51fa\u4e00\u6b21\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. \u5728\u6d4b\u8bd5\u6570\u636e\u4e0a\u6d4b\u8bd5\u7f51\u7edc\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\u6211\u4eec\u5df2\u7ecf\u5728\u6574\u4e2a\u8bad\u7ec3\u96c6\u4e0a\u8f6e\u756a\u8bad\u7ec3\u4e862\u6b21\u7f51\u7edc\u3002\u4f46\u662f\u6211\u4eec\u9700\u8981\u68c0\u67e5\u4e00\u4e0b\u7f51\u7edc\u6709\u6ca1\u6709\u5b66\u5230\u4efb\u4f55\u4e1c\u897f\u3002\n\n\u6211\u4eec\u5c06\u901a\u8fc7\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684\u7c7b\u6807\u7b7e\u6765\u9a8c\u8bc1\u8fd9\u4e00\u70b9\uff0c\u5e76\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u5bf9\u5176\u8fdb\u884c\u68c0\u67e5\u3002\n\u5982\u679c\u9884\u6d4b\u662f\u6b63\u786e\u7684\uff0c\u6211\u4eec\u5c06\u793a\u4f8b\u6dfb\u52a0\u5230\u6b63\u786e\u7684\u9884\u6d4b\u5217\u8868\u4e2d\u3002\n\n\u597d\u7684\uff0c\u7b2c\u4e00\u6b65\uff0c\u8ba9\u6211\u4eec\u663e\u793a\u6765\u81ea\u6d4b\u8bd5\u96c6\u7684\u56fe\u50cf\u6765\u719f\u6089\u4e00\u4e0b\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# \u8f93\u51fa\u56fe\u50cf\u548c\u6b63\u786e\u7684\u7c7b\u6807\u7b7e\nimshow(torchvision.utils.make_grid(images),\"\u4e00\u4e2a\u6279\u6b21\u6d4b\u8bd5\u6837\u672c\")\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u597d\u4e86\uff0c\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u795e\u7ecf\u7f51\u7edc\u662f\u600e\u4e48\u60f3\u7684\uff0c\u4e0a\u9762\u7684\u4f8b\u5b50\u662f:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "outputs = net(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8f93\u51fa\u662f10\u7c7b\u7684\u80fd\u91cf\u3002\u4e00\u4e2a\u7c7b\u7684\u80fd\u91cf\u8d8a\u9ad8\uff0c\u7f51\u7edc\u5c31\u8d8a\u8ba4\u4e3a\u8be5\u56fe\u50cf\u662f\u7279\u5b9a\u7c7b\u7684\u3002\n\u90a3\u4e48\uff0c\u8ba9\u6211\u4eec\u5f97\u5230\u6700\u9ad8\u80fd\u91cf\u7684\u7d22\u5f15\uff1a\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ed3\u679c\u770b\u8d77\u6765\u76f8\u5f53\u4e0d\u9519.\n\n\u8ba9\u6211\u4eec\u770b\u770b\u7f51\u7edc\u5728\u6574\u4e2a\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u5427\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ed3\u679c\u770b\u8d77\u6765\u6bd4\u968f\u673a\u731c\u6d4b\u597d\u591a\u5566, \u968f\u673a\u731c\u6d4b\u53ea\u6709 10% \u7684\u51c6\u786e\u7387(accuracy) \n(\u968f\u673a\u731c\u6d4b\uff1a randomly picking a class out of 10 classes).\n\u8fd9\u8bf4\u660e\u7f51\u7edc\u4f3c\u4e4e\u5b66\u4e60\u5230\u4e86\u4e00\u4e9b\u4e1c\u897f\u3002\n\n\u90a3\u4e48, \u7f51\u7edc\u5728\u54ea\u4e9b\u7c7b\u4e0a\u8868\u73b0\u7684\u8f83\u597d\uff0c\u800c\u54ea\u4e9b\u7c7b\u4e0a\u8868\u73b0\u7684\u8f83\u5dee\u5462:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u597d\u5566, \u90a3\u6211\u4eec\u63a5\u4e0b\u6765\u5e72\u561b\u5462\uff1f\n\n\u6211\u4eec\u5982\u4f55\u5728GPU\u4e0a\u8bad\u7ec3\u6211\u4eec\u7684\u7f51\u7edc\u5462\uff1f\n\n\u5728GPU\u4e0a\u8bad\u7ec3\n----------------\n\u5c31\u50cf\u6211\u4eec\u5728\u524d\u9762\u628a\u4e00\u4e2a Tensor \u8fc1\u79fb\u5230 GPU \u4e0a\u53bb\u65f6\u6240\u4f5c\u7684\u90a3\u6837, \n\u4f60\u53ef\u4ee5\u7528\u540c\u6837\u7684\u65b9\u5f0f\u628a\u4f60\u7684\u795e\u7ecf\u7f51\u7edc\u4e5f\u8fc1\u79fb\u5230 GPU \u4e0a\u3002\n\n\u5982\u679c\u624b\u5934\u6709\u53ef\u7528\u7684CUDA,\u90a3\u4e48\u6211\u4eec\u9996\u5148\u628a\u6211\u4eec\u7684device\u5b9a\u4e49\u4e3a\u7b2c\u4e00\u4e2a\u53ef\u7528\u7684cuda device:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# \u5047\u5b9a\u6211\u4eec\u5728\u4e00\u4e2a CUDA machine \u4e0a\u8dd1\u8fd9\u4e2a\u4ee3\u7801, \u90a3\u4e48\u8fd9\u5c06\u8f93\u51fa CUDA device:\n\nprint(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u672c\u8282\u5269\u4f59\u7684\u5185\u5bb9\u90fd\u5047\u5b9a `device` \u662f\u4e00\u4e2a CUDA device.\n\n\u7136\u540e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5c06\u9012\u5f52\u904d\u5386\u6240\u6709\u6a21\u5757\u5e76\u5c06\u5176\u53c2\u6570\u548c\u7f13\u51b2\u533a\u8f6c\u6362\u4e3aCUDA tensors:\n\n.. code:: python\n\n    net.to(device)\n\n\n\u8bf7\u8bb0\u4f4f\uff0c\u8fd8\u8981\u5fc5\u987b\u5728\u6bcf\u4e00\u6b65\u5c06\u8f93\u5165\u548c\u5bf9\u5e94\u7684\u76ee\u6807\u503c\u53d1\u9001\u5230GPU:\n\n.. code:: python\n\n        inputs, labels = inputs.to(device), labels.to(device)\n\n\u4e0eCPU\u76f8\u6bd4\uff0c\u6211\u4e3a\u4ec0\u4e48\u6ca1\u6709\u770b\u5230\u5927\u91cf\u7684\u52a0\u901f\u5462\uff1f\u56e0\u4e3a\u4f60\u7684\u7f51\u7edc\u771f\u7684\u5f88\u5c0f\u3002\n\n**\u7ec3\u4e60:** \u5c1d\u8bd5\u589e\u52a0\u7f51\u7edc\u7684\u5bbd\u5ea6(\u8981\u6ce8\u610f \u7b2c\u4e00\u4e2a ``nn.Conv2d`` \u7684\u53c2\u65702\u548c\u7b2c\u4e8c\u4e2a ``nn.Conv2d`` \u7684\u53c2\u65701-\u5b83\u4eec\u9700\u8981\u76f8\u540c\u7684\u6570\u76ee)\uff0c\n\u770b\u770b\u4f60\u5f97\u5230\u4e86\u4ec0\u4e48\u6837\u7684\u52a0\u901f\u3002\n\n**\u76ee\u6807\u987a\u5229\u8fbe\u6210**:\n\n- \u4ece\u9ad8\u5c42\u6b21\u4e0a\u7406\u89e3PyTorch\u5f20\u91cf\u5e93\u548c\u795e\u7ecf\u7f51\u7edc\u3002\n- \u8bad\u7ec3\u4e00\u4e2a\u5c0f\u795e\u7ecf\u7f51\u7edc\u5bf9\u56fe\u50cf\u8fdb\u884c\u5206\u7c7b\n\n\u5728\u591a\u4e2aGPUs\u4e0a\u8bad\u7ec3\u6a21\u578b\n-------------------------\n\u5982\u679c\u4f60\u60f3\u770b\u5230\u66f4\u591a\u7684\u5927\u89c4\u6a21\u52a0\u901f\u4f7f\u7528\u4f60\u7684\u6240\u6709GPU\uff0c\u8bf7\u67e5\u770b  :doc:`data_parallel_tutorial` \u3002\n\n\u4e0b\u4e00\u6b65\u5411\u4f55\u65b9\u53bb?\n-------------------\n\n-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n-  `Train a state-of-the-art ResNet network on imagenet`_\n-  `Train a face generator using Generative Adversarial Networks`_\n-  `Train a word-level language model using Recurrent LSTM networks`_\n-  `More examples`_\n-  `More tutorials`_\n-  `Discuss PyTorch on the Forums`_\n-  `Chat with other users on Slack`_\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\ndel dataiter\n# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}