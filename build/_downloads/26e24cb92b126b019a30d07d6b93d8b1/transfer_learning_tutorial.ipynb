{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u8fc1\u79fb\u5b66\u4e60\u6559\u7a0b\n==========================\n**\u7ffb\u8bd1\u8005:** `Antares <http://wwww.studyai.com/antares>`_\n\n\u5728\u672c\u6559\u7a0b\u4e2d\uff0c\u60a8\u5c06\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60(transfer learning)\u6765\u8bad\u7ec3\u60a8\u7684\u7f51\u7edc\u3002\n\u4f60\u53ef\u4ee5\u5728 `cs231n \u7b14\u8bb0 <http://cs231n.github.io/transfer-learning/>`__ \n\u4e0a\u8bfb\u5230\u66f4\u591a\u5173\u4e8e\u8f6c\u79fb\u5b66\u4e60\u7684\u5185\u5bb9\u3002\n\n\u5f15\u7528\u4e00\u6bb5\u6765\u81ea\u7b14\u8bb0\u7684\u8bdd,\n\n    \u5728\u5b9e\u8df5\u4e2d\uff0c\u5f88\u5c11\u6709\u4eba\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u6574\u4e2a\u5377\u79ef\u7f51\u7edc(\u968f\u673a\u521d\u59cb\u5316)\uff0c\u56e0\u4e3a\u62e5\u6709\u8db3\u591f\u5927\u5c0f\u7684\u6570\u636e\u96c6\u76f8\u5bf9\u8f83\u5c11\u3002\n    \u76f8\u53cd\uff0c\u901a\u5e38\u5728\u975e\u5e38\u5927\u7684\u6570\u636e\u96c6\u4e0a\u5bf9ConvNet\u8fdb\u884c\u9884\u8bad\u7ec3(\u4f8b\u5982ImageNet\uff0c\u5176\u4e2d\u5305\u542b120\u4e07\u5e45\u56fe\u50cf\uff0c\u5305\u542b1000\u4e2a\u7c7b\u522b)\uff0c\n    \u7136\u540e\u4f7f\u7528ConvNet\u4f5c\u4e3a\u521d\u59cb\u5316\u6216\u56fa\u5b9a\u7279\u5f81\u63d0\u53d6\u5668\u6765\u6267\u884c\u611f\u5174\u8da3\u7684\u4efb\u52a1\u3002\n\n\u4e24\u79cd\u4e3b\u8981\u7684\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u5982\u4e0b\u6240\u793a:\n\n-  **\u5fae\u8c03\u5377\u79ef\u7f51\u7edc**: \u6211\u4eec\u7528\u9884\u5148\u8bad\u7ec3\u8fc7\u7684\u7f51\u7edc(\u6bd4\u5982\u5728ImageNet 1000\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u7f51\u7edc)\n   \u6765\u521d\u59cb\u5316\u7f51\u7edc\uff0c\u800c\u4e0d\u662f\u968f\u673a\u521d\u59cb\u5316\u3002 \u521d\u59cb\u5316\u4ee5\u540e\u5176\u4f59\u7684\u8bad\u7ec3\u770b\u8d77\u6765\u50cf\u5f80\u5e38\u4e00\u6837\u3002\n-  **\u628aConvNet\u4f5c\u4e3a\u56fa\u5b9a\u7279\u5f81\u63d0\u53d6\u5668**: \u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5c06\u51bb\u7ed3\u6240\u6709\u7f51\u7edc\u7684\u6743\u91cd\uff0c\u4f46\u6700\u7ec8\u7684\u5b8c\u5168\u8fde\u63a5\u5c42\u9664\u5916\u3002\n   \u6700\u540e\u4e00\u4e2a\u5b8c\u5168\u8fde\u63a5\u7684\u5c42\u88ab\u4e00\u4e2a\u5177\u6709\u968f\u673a\u6743\u91cd\u7684\u65b0\u5c42\u6240\u53d6\u4ee3\uff0c\u5e76\u4e14\u53ea\u6709\u8fd9\u4e2a\u5c42\u88ab\u8bad\u7ec3\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u6570\u636e\n---------\n\n\u6211\u4eec\u5c06\u4f7f\u7528 torchvision \u548c torch.utils.data \u5305\u6765\u52a0\u8f7d\u6570\u636e\u3002\n\n\u6211\u4eec\u4eca\u5929\u8981\u89e3\u51b3\u7684\u95ee\u9898\u662f\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u6765\u5206\u7c7b\u8682\u8681\u548c\u871c\u8702\u3002\n\u6211\u4eec\u6709\u5927\u7ea6120\u5f20\u9488\u5bf9\u8682\u8681\u548c\u871c\u8702\u7684\u8bad\u7ec3\u56fe\u50cf\u3002\u6bcf\u4e2a\u7c7b\u670975\u4e2a\u9a8c\u8bc1\u56fe\u50cf\u3002\n\u901a\u5e38\uff0c\u5982\u679c\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\uff0c\u8fd9\u662f\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684\u6570\u636e\u96c6\u3002\n\u7531\u4e8e\u6211\u4eec\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\uff0c\u6211\u4eec\u5e94\u8be5\u80fd\u591f\u5408\u7406\u5730\u6cdb\u5316\u3002\n\n\u8be5\u6570\u636e\u96c6\u662f imagenet \u7684\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684\u5b50\u96c6.\n\n.. Note ::\n   \u4ece `\u8fd9\u91cc <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_ \n   \u4e0b\u8f7d\u6570\u636e\u5e76\u628a\u5b83\u4eec\u89e3\u538b\u5230\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\n\n\u6570\u636e\u589e\u5e7f\u548c\u5f52\u4e00\u5316\u7528\u4e8e\u8bad\u7ec3\uff1b\n\u53ea\u5f52\u4e00\u5316\u7528\u4e8e\u9a8c\u8bc1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = './data/hymenoptera_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u53ef\u89c6\u5316\u4e00\u4e9b\u56fe\u50cf\n^^^^^^^^^^^^^^^^^^^^^^\n\u8ba9\u6211\u4eec\u53ef\u89c6\u5316\u4e00\u4e9b\u8bad\u7ec3\u56fe\u50cf\uff0c\u4ee5\u4e86\u89e3\u6570\u636e\u589e\u5f3a(data augmentations)\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# \u83b7\u53d6\u8bad\u7ec3\u6570\u636e\u7684\u4e00\u4e2a\u6279\u6b21\ninputs, classes = next(iter(dataloaders['train']))\n\n# \u628a\u4e00\u4e2a\u6279\u6b21\u7684\u56fe\u50cf\u5236\u4f5c\u6210\u56fe\u50cf\u7f51\u683c\nout = torchvision.utils.make_grid(inputs)\n\nplt.figure(figsize=[6.5,2.5])\nimshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u6a21\u578b\n------------------\n\n\u73b0\u5728\uff0c\u8ba9\u6211\u4eec\u7f16\u5199\u4e00\u4e2a\u901a\u7528\u51fd\u6570\u6765\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u3002\u5728\u6b64\uff0c\u6211\u4eec\u5c06\u8bf4\u660e:\n\n-  \u8c03\u5ea6\u5b66\u4e60\u7387\n-  \u4fdd\u5b58\u6700\u4f18\u7684\u6a21\u578b\n\n\u5728\u4e0b\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u53c2\u6570 ``scheduler`` \u662f ``torch.optim.lr_scheduler`` \u4e2d\u7684LR\u8c03\u5ea6\u5668\u5bf9\u8c61\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u53ef\u89c6\u5316\u6a21\u578b\u7684\u9884\u6d4b\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\u663e\u793a\u82e5\u5e72\u56fe\u50cf\u7684\u9884\u6d4b\u7ed3\u679c\u7684\u901a\u7528\u51fd\u6570\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5fae\u8c03\u5377\u79ef\u7f51\u7edc\n----------------------\n\n\u52a0\u8f7d\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684\u6a21\u578b \u5e76\u4e14 \u91cd\u7f6e\u6700\u7ec8\u7684\u5168\u8fde\u63a5\u5c42\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# \u53ef\u4ee5\u770b\u5230 \u7f51\u7edc\u7684\u6240\u6709\u53ef\u8bad\u7ec3\u53c2\u6570\u90fd\u88ab\u4f18\u5316\u5566\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# \u6bcf7\u4e2a\u56de\u5408(epochs)\u8870\u51cf LR, \u8870\u51cf\u56e0\u5b50\u662f 0.1\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3 \u548c \u8bc4\u4f30\n^^^^^^^^^^^^^^^^^^\n\n\u5728CPU\u4e0a\u5b83\u5e94\u8be5\u9700\u898115-25\u5206\u949f\u3002\u4e0d\u8fc7\uff0c\u5728GPU\u4e0a\uff0c\u5b83\u6240\u7528\u7684\u65f6\u95f4\u8fd8\u4e0d\u5230\u4e00\u5206\u949f\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u628aConvNet\u4f5c\u4e3a\u56fa\u5b9a\u7279\u5f81\u63d0\u53d6\u5668\n----------------------------------\n\n\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u9700\u8981\u51bb\u7ed3\u6240\u6709\u7684\u7f51\u7edc\uff0c\u9664\u4e86\u6700\u540e\u4e00\u5c42\u3002\u6211\u4eec\u9700\u8981\u8bbe\u7f6e ``requires_grad == False``  \u6765\u51bb\u7ed3\u53c2\u6570\uff0c\n\u8fd9\u6837\u68af\u5ea6\u5c31\u4e0d\u4f1a\u5728 ``backward()`` \u4e2d\u8ba1\u7b97\u3002\n\n\u4f60\u53ef\u4ee5\u5728\u6587\u6863\u4e2d\u67e5\u770b\u66f4\u591a `\u70b9\u8fd9\u91cc <https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# \u6700\u65b0\u6dfb\u52a0\u7684\u6a21\u5757\u7684\u53c2\u6570\u9ed8\u8ba4\u60c5\u51b5\u4e0b ``requires_grad=True``` \nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# \u6211\u4eec\u770b\u5230 \u53ea\u6709\u6700\u540e\u4e00\u5c42\u7684\u53c2\u6570\u88ab\u4f18\u5316\u4e86\uff0c\u8fd9\u4e0e\u524d\u9762\u7684\u5fae\u8c03\u7f51\u7edc\u662f\u4e0d\u4e00\u6837\u7684\u3002\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# \u6bcf7\u4e2a\u56de\u5408(epoch)\u8870\u51cf LR, \u8870\u51cf\u56e0\u5b50\u662f 0.1\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u548c\u8bc4\u4f30\n^^^^^^^^^^^^^^^^^^\n\n\u5728 CPU \u4e0a\u4e0e\u4e0a\u9762\u7684\u5fae\u8c03\u7f51\u7edc\u76f8\u6bd4\u8fd9\u5c06\u82b1\u8d39\u5927\u7ea6\u4e00\u534a\u7684\u65f6\u95f4\u3002\n\u8fd9\u662f\u9884\u6599\u4e4b\u4e2d\u7684\uff0c\u56e0\u4e3a\u5bf9\u5927\u90e8\u5206\u7f51\u7edc\u5176\u68af\u5ea6\u4e0d\u9700\u8981\u8ba1\u7b97\u3002\u7136\u800c\uff0c\u524d\u5411\u4f20\u64ad\u786e\u5b9e\u9700\u8981\u8ba1\u7b97\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_conv)\n\nplt.ioff()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}