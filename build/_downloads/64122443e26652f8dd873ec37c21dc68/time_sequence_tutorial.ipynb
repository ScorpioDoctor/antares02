{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\n=======================\n**\u4f5c\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`_\n\n\u8fd9\u662f\u4e00\u4e2a\u8ba9\u521d\u5b66\u8005\u4ece\u73a9\u5177\u5f00\u59cb\u7684\u4f8b\u5b50\u3002\u5b83\u6709\u52a9\u4e8e\u5b66\u4e60pytorch\u548c\u65f6\u5e8f\u9884\u6d4b\u3002\n\u672c\u4f8b\u4e2d\u4f7f\u7528\u4e24\u4e2aLSTMCell\u5355\u5143\u6765\u5b66\u4e60\u4ece\u4e0d\u540c\u76f8\u4f4d\u5f00\u59cb\u7684\u4e00\u4e9b\u6b63\u5f26\u6ce2\u4fe1\u53f7\u3002\n\u5728\u5b66\u4e60\u4e86\u6b63\u5f26\u6ce2\u4e4b\u540e\uff0c\u7f51\u7edc\u8bd5\u56fe\u9884\u6d4b\u672a\u6765\u7684\u4fe1\u53f7\u503c\u3002\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5bfc\u5165\u4f9d\u8d56\u5305\n-----------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\nimport argparse\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\n# \u6253\u5f00\u4ea4\u4e92\u6a21\u5f0f\nplt.ion()\n# \u5ffd\u7565 warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4ea7\u751f\u6b63\u5f26\u4fe1\u53f7\n-----------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(2)\n\nT = 20\nL = 1000\nN = 100\n\nx = np.empty((N, L), 'int64')\nx[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\ndata = np.sin(x / 1.0 / T).astype('float64')\ntorch.save(data, open('./data/traindata.pt', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49\u5305\u542bLSTM\u7684\u5e8f\u5217\u6a21\u578b\n-----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Sequence(nn.Module):\n    def __init__(self):\n        super(Sequence, self).__init__()\n        self.lstm1 = nn.LSTMCell(1, 51)\n        self.lstm2 = nn.LSTMCell(51, 51)\n        self.linear = nn.Linear(51, 1)\n\n    def forward(self, input, future = 0):\n        outputs = []\n        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n\n        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n            output = self.linear(h_t2)\n            outputs += [output]\n        for i in range(future):# if we should predict the future\n            h_t, c_t = self.lstm1(output, (h_t, c_t))\n            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n            output = self.linear(h_t2)\n            outputs += [output]\n        outputs = torch.stack(outputs, 1).squeeze(2)\n        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd0\u884c\u8bad\u7ec3\u8fc7\u7a0b\n-----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n    # set random seed to 0\n    np.random.seed(0)\n    torch.manual_seed(0)\n    # load data and make training set\n    data = torch.load('./data/traindata.pt')\n    input = torch.from_numpy(data[3:, :-1])\n    target = torch.from_numpy(data[3:, 1:])\n    test_input = torch.from_numpy(data[:3, :-1])\n    test_target = torch.from_numpy(data[:3, 1:])\n    # build the model\n    seq = Sequence()\n    seq.double()\n    criterion = nn.MSELoss()\n    # use LBFGS as optimizer since we can load the whole data to train\n    optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n    #begin to train\n    for i in range(15):\n        print('STEP: ', i)\n        def closure():\n            optimizer.zero_grad()\n            out = seq(input)\n            loss = criterion(out, target)\n            print('loss:', loss.item())\n            loss.backward()\n            return loss\n        optimizer.step(closure)\n        # begin to predict, no need to track gradient here\n        with torch.no_grad():\n            future = 1000\n            pred = seq(test_input, future=future)\n            loss = criterion(pred[:, :-future], test_target)\n            print('test loss:', loss.item())\n            y = pred.detach().numpy()\n        # draw the result\n        plt.figure(figsize=(30,10))\n        plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n        plt.xlabel('x', fontsize=20)\n        plt.ylabel('y', fontsize=20)\n        plt.xticks(fontsize=20)\n        plt.yticks(fontsize=20)\n        def draw(yi, color):\n            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n            plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n        draw(y[0], 'r')\n        draw(y[1], 'g')\n        draw(y[2], 'b')\n        # plt.show(block=False)\n        # plt.pause(0.1)\n        plt.savefig('predict%d.pdf'%i)\n        plt.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}