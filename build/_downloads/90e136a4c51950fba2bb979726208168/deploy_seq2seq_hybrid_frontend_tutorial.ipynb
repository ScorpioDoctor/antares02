{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u4f7f\u7528\u6df7\u5408\u524d\u7aef\u90e8\u7f72seq2seq\u6a21\u578b\n==================================================\n**\u7ffb\u8bd1\u8005:** `Antares <http://wwww.studyai.com/antares>`_\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u672c\u6559\u7a0b\u5c06\u4ecb\u7ecd\u4f7f\u7528PyTorch\u7684\u6df7\u5408\u524d\u7aef(Hybrid Frontend)\u5c06\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b(seq2seq model)\n \u8f6c\u6362\u4e3aTorch Script\u7684\u8fc7\u7a0b\u3002\u6211\u4eec\u5c06\u8f6c\u6362\u7684\u6a21\u578b\u662f `Chatbot \u6559\u7a0b <https://pytorch.org/tutorials/beginner/chatbot_tutorial.html>`__ \u7684Chatbot\u6a21\u578b\u3002\n \u60a8\u53ef\u4ee5\u5c06\u672c\u6559\u7a0b\u89c6\u4e3aChatbot\u6559\u7a0b\u7684\u201c\u7b2c2\u90e8\u5206\u201d\uff0c\u5e76\u90e8\u7f72\u60a8\u81ea\u5df1\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\n \u4e5f\u53ef\u4ee5\u4ece\u672c\u6587\u6863\u5f00\u59cb\uff0c\u5e76\u4f7f\u7528\u6211\u4eec\u63d0\u4f9b\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u5728\u540e\u4e00\u79cd\u60c5\u51b5\u4e0b\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u539f\u59cb\u7684Chatbot\u6559\u7a0b\uff0c\n \u4e86\u89e3\u6709\u5173\u6570\u636e\u9884\u5904\u7406\u3001\u6a21\u578b\u7406\u8bba\u548c\u5b9a\u4e49\u4ee5\u53ca\u6a21\u578b\u8bad\u7ec3\u7684\u8be6\u7ec6\u4fe1\u606f\u3002\n\n\u4ec0\u4e48\u662f\u6df7\u5408\u524d\u7aef(Hybrid Frontend)?\n -----------------------------------\n\n \u5728\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u9879\u76ee\u7684\u7814\u7a76\u548c\u5f00\u53d1\u9636\u6bb5\uff0c\u4e0e\u50cfPyTorch\u8fd9\u6837\u7684(**\u6025\u5207\u7684,eager**)\u3001\n \u547d\u4ee4\u5f0f\u7684(imperative)\u754c\u9762\u8fdb\u884c\u4ea4\u4e92\u662f\u6709\u5229\u7684\u3002\n \u8fd9\u4f7f\u7528\u6237\u80fd\u591f\u7f16\u5199\u719f\u6089\u7684\u3001\u60ef\u7528\u7684Python\uff0c\u5141\u8bb8\u4f7f\u7528Python\u6570\u636e\u7ed3\u6784\u3001\u63a7\u5236\u6d41\u64cd\u4f5c\u3001\u6253\u5370\u8bed\u53e5\u548c\u8c03\u8bd5\u5b9e\u7528\u7a0b\u5e8f\u3002\n \u867d\u7136\u6025\u5207\u7684\u63a5\u53e3(eager interface)\u5bf9\u4e8e\u7814\u7a76\u548c\u5b9e\u9a8c\u5e94\u7528\u7a0b\u5e8f\u662f\u4e00\u4e2a\u6709\u76ca\u7684\u5de5\u5177\uff0c\u4f46\u662f\u5f53\u6d89\u53ca\u5230\u5728\u751f\u4ea7\u73af\u5883(production environment)\u4e2d\n \u90e8\u7f72\u6a21\u578b\u65f6\uff0c\u57fa\u4e8e\u56fe\u5f62\u7684\u6a21\u578b\u8868\u793a(**graph**-based model representation)\u662f\u975e\u5e38\u6709\u76ca\u7684\u3002\n \u63a8\u8fdf\u7684\u56fe\u5f62\u8868\u793a(deferred graph representation)\u5141\u8bb8\u4f18\u5316\uff0c\u4f8b\u5982\u65e0\u5e8f\u6267\u884c\uff0c\n \u4ee5\u53ca\u9488\u5bf9\u786c\u4ef6\u4f53\u7cfb\u7ed3\u6784\u8fdb\u884c\u9ad8\u5ea6\u4f18\u5316\u7684\u80fd\u529b\u3002\n \u6b64\u5916\uff0c\u57fa\u4e8e\u56fe\u5f62\u7684\u6a21\u578b\u8868\u793a\u652f\u6301\u4e0e\u6846\u67b6\u65e0\u5173\u7684\u6a21\u578b\u5bfc\u51fa.\n\n PyTorch\u63d0\u4f9b\u4e86\u5c06\u6025\u5207\u6a21\u5f0f\u4ee3\u7801(eager-mode code)\u9010\u6b65\u8f6c\u6362\u4e3aTorch Script\u7684\u673a\u5236\uff0c\n \u8fd9\u662fPython\u7684\u4e00\u4e2a\u9759\u6001\u53ef\u5206\u6790\u548c\u53ef\u4f18\u5316\u7684\u5b50\u96c6\uff0cTorch\u4f7f\u7528\u5b83\u6765\u8868\u793a\u72ec\u7acb\u4e8ePython\u8fd0\u884c\u65f6\u7684\u6df1\u5ea6\u5b66\u4e60\u7a0b\u5e8f\u3002\n\n \u7528\u4e8e\u5c06\u6025\u5207\u6a21\u5f0f\u4e0bPyTorch\u7a0b\u5e8f\u8f6c\u6362\u4e3aTorch Script\u7684API\u4f4d\u4e8etorch.jit\u6a21\u5757\u4e2d\u3002\n \u8be5\u6a21\u5757\u6709\u4e24\u79cd\u6838\u5fc3\u6a21\u5f0f\uff0c\u7528\u4e8e\u5c06\u6025\u5207\u6a21\u5f0f\u6a21\u578b\u8f6c\u6362\u4e3aTorch Script\u56fe\u5f62\u8868\u793a\uff1a **\u8ddf\u8e2a(tracing)** \u548c\n **\u811a\u672c(scripting)**\u3002\n ``torch.jit.trace`` \u51fd\u6570\u63a5\u53d7\u4e00\u4e2a\u6a21\u5757\u6216\u51fd\u6570\u4ee5\u53ca\u4e00\u7ec4\u6837\u4f8b\u8f93\u5165\u3002\u7136\u540e\uff0c\u5b83\u901a\u8fc7\u51fd\u6570\u6216\u6a21\u5757\u8fd0\u884c\u6837\u4f8b\u8f93\u5165\uff0c\n \u540c\u65f6\u8ddf\u8e2a\u6240\u9047\u5230\u7684\u8ba1\u7b97\u6b65\u9aa4\uff0c\u5e76\u8f93\u51fa\u6267\u884c\u8ddf\u8e2a\u64cd\u4f5c\u7684\u57fa\u4e8e\u56fe\u5f62\u7684\u51fd\u6570\u3002\n **Tracing** \u5bf9\u4e8e\u4e0d\u6d89\u53ca\u6570\u636e\u4f9d\u8d56\u7684\u63a7\u5236\u6d41\u7684\u7b80\u5355\u6a21\u5757\u548c\u51fd\u6570\u662f\u5f88\u597d\u7684\uff0c\u4f8b\u5982\u6807\u51c6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3002\n \u4f46\u662f\uff0c\u5982\u679c\u8ddf\u8e2a\u5177\u6709\u6570\u636e\u4f9d\u8d56\u7684if\u8bed\u53e5\u548c\u5faa\u73af\u7684\u51fd\u6570\uff0c\u5219\u53ea\u8bb0\u5f55\u6837\u4f8b\u8f93\u5165\u6cbf\u6267\u884c\u8def\u5f84\u8c03\u7528\u7684\u64cd\u4f5c\u3002\n \u6362\u53e5\u8bdd\u8bf4\uff0c\u63a7\u5236\u6d41\u672c\u8eab\u4e0d\u4f1a\u88ab\u6355\u83b7\u3002\u4e3a\u4e86\u8f6c\u6362\u5305\u542b\u6570\u636e\u4f9d\u8d56\u63a7\u5236\u6d41\u7684\u6a21\u5757\u548c\u51fd\u6570\uff0cPyTorch\u8fd8\u63d0\u4f9b\u4e86\n \u4e00\u79cd\u811a\u672c(**scripting**)\u673a\u5236\u3002Scripting\u663e\u5f0f\u5730\u5c06\u6a21\u5757\u6216\u51fd\u6570\u4ee3\u7801\u8f6c\u6362\u4e3aTorch Script\uff0c\n \u5305\u62ec\u6240\u6709\u53ef\u80fd\u7684\u63a7\u5236\u6d41\u8def\u5f84\u3002\n \u8981\u4f7f\u7528\u811a\u672c\u6a21\u5f0f\uff0c\u8bf7\u786e\u4fdd\u4ece ``torch.jit.ScriptModule`` \u57fa\u7c7b(\u800c\u4e0d\u662f ``torch.nn.Module`` )\u7ee7\u627f\uff0c\n \u5e76\u5c06 ``torch.jit.script`` \u88c5\u9970\u5668\u6dfb\u52a0\u5230Python\u51fd\u6570\u6216\u5c06 ``torch.jit.script_method`` \n \u88c5\u9970\u5668\u6dfb\u52a0\u5230\u6a21\u5757\u7684\u65b9\u6cd5(module\u2019s methods)\u4e2d\u3002\n \u4f7f\u7528scripting\u65f6\u8981\u6ce8\u610f\u7684\u4e00\u70b9\u662f\uff0c\u5b83\u53ea\u652f\u6301Python\u7684\u4e00\u4e2a\u53d7\u9650\u5b50\u96c6\u3002\u6709\u5173\u652f\u6301\u7279\u6027\u7684\u6240\u6709\u7ec6\u8282\uff0c\n \u8bf7\u53c2\u9605 Torch Script `\u8bed\u8a00\u53c2\u8003 <https://pytorch.org/docs/master/jit.html>`__ \u3002\n \u4e3a\u4e86\u63d0\u4f9b\u6700\u5927\u7684\u7075\u6d3b\u6027\uff0c\n \u53ef\u4ee5\u7ec4\u5408Torch Script\u7684\u6a21\u5f0f\u6765\u8868\u793a\u6574\u4e2a\u7a0b\u5e8f\uff0c\u5e76\u4e14\u8fd9\u4e9b\u6280\u672f\u53ef\u4ee5\u9010\u6b65\u5e94\u7528\u3002\n\n .. figure:: /_static/img/chatbot/pytorch_workflow.png\n    :align: center\n    :alt: workflow\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u9e23\u8c22\n----------------\n\n\u8be5\u6559\u7a0b\u7684\u5199\u4f5c\u53d7\u5230\u4e86\u4ee5\u4e0b\u8fd9\u4e9b\u4ee3\u7801\u7684\u542f\u53d1:\n\n1) Yuan-Kuei Wu \u7684 Pytorch \u804a\u5929\u673a\u5668\u4eba\u5b9e\u73b0:\n   https://github.com/ywk991112/pytorch-chatbot\n\n2) Sean Robertson\u2019s \u5b9e\u64cdPyTorch\u4e4bseq2seq\u7ffb\u8bd1\u7684\u5b9e\u73b0:\n   https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation\n\n3) FloydHub \u7684\u9999\u5948\u513f\u7535\u5f71\u8bed\u6599\u5e93\u9884\u5904\u7406\u4ee3\u7801:\n   https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u51c6\u5907\u73af\u5883\n-------------------\n\n\u9996\u5148\uff0c\u6211\u4eec\u5c06\u5bfc\u5165\u6240\u9700\u7684\u6a21\u5757\u5e76\u8bbe\u7f6e\u4e00\u4e9b\u5e38\u91cf\u3002\u5982\u679c\u60a8\u8ba1\u5212\u4f7f\u7528\u81ea\u5df1\u7684\u6a21\u578b\uff0c\n\u8bf7\u786e\u4fdd ``MAX_LENGTH`` \u5e38\u91cf\u8bbe\u7f6e\u6b63\u786e\u3002\n\u4f5c\u4e3a\u63d0\u9192\uff0c\u8fd9\u4e2a\u5e38\u91cf\u5b9a\u4e49\u4e86\u8bad\u7ec3\u671f\u95f4\u5141\u8bb8\u7684\u6700\u5927\u53e5\u5b50\u957f\u5ea6\u548c\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u7684\u6700\u5927\u957f\u5ea6\u8f93\u51fa\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport re\nimport os\nimport unicodedata\nimport numpy as np\n\ndevice = torch.device(\"cpu\")\n\n\nMAX_LENGTH = 10  # Maximum sentence length\n\n# Default word tokens\nPAD_token = 0  # Used for padding short sentences\nSOS_token = 1  # Start-of-sentence token\nEOS_token = 2  # End-of-sentence token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model \u9884\u89c8\n--------------\n\n\u5982\u524d\u6240\u8ff0\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u6a21\u578b\u662f `\u5e8f\u5217\u5230\u5e8f\u5217(Seq2seq)\u6a21\u578b <https://arxiv.org/abs/1409.3215>`__ \u3002\n\u5f53\u6211\u4eec\u7684\u8f93\u5165\u662f\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\uff0c\u800c\u4e14\u8f93\u51fa\u4e5f\u662f\u4e00\u4e2a\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\uff0c\u4f46\u4e0d\u4e00\u5b9a\u662f\u8f93\u5165\u7684\u4e00\u5bf9\u4e00\u6620\u5c04 \u7684\u65f6\u5019\uff0c\n\u8fd9\u79cdSeq2seq\u6a21\u578b\u7ecf\u5e38\u88ab\u4f7f\u7528\u3002\n\u4e00\u4e2aseq2seq\u6a21\u578b\u7531\u4e24\u4e2a\u534f\u540c\u5de5\u4f5c\u7684\u9012\u5f52\u795e\u7ecf\u7f51\u7edc(RNNs)\u7ec4\u6210\uff1a\n\u4e00\u4e2a\u7f16\u7801\u5668(**encoder**)\u548c\u4e00\u4e2a\u89e3\u7801\u5668(decoder)\u3002\n\n.. figure:: /_static/img/chatbot/seq2seq_ts.png\n   :align: center\n   :alt: model\n\n\n\u56fe\u7247\u6765\u6e90:\nhttps://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/\n\n\u7f16\u7801\u5668(Encoder)\n~~~~~~~~~~~~~~~~~~~~~\n\n\u7f16\u7801\u5668RNN\u4e00\u6b21\u8fed\u4ee3\u8f93\u5165\u53e5\u5b50\u7684\u4e00\u4e2atoken(e.g.\u00a0word)\uff0c\u5728\u6bcf\u4e00\u65f6\u95f4\u6b65\u8f93\u51fa \u201coutput\u201d\u5411\u91cf \n\u548c \u201chidden state\u201d\u5411\u91cf\u3002\n\u7136\u540e\u5c06\u9690\u85cf\u72b6\u6001\u5411\u91cf\u4f20\u9012\u5230\u4e0b\u4e00\u65f6\u95f4\u6b65\uff0c\u540c\u65f6\u8bb0\u5f55\u8f93\u51fa\u5411\u91cf\u3002\u7f16\u7801\u5668\u628a\u5728\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e00\u70b9\u4e0a\u770b\u5230\n\u7684\u4e0a\u4e0b\u6587\u8f6c\u6362\u4e3a\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u4e00\u7ec4\u70b9\uff0c\u89e3\u7801\u5668\u5c06\u4f7f\u7528\u8fd9\u4e9b\u70b9\u4e3a\u7ed9\u5b9a\u4efb\u52a1\u751f\u6210\u6709\u610f\u4e49\u7684\u8f93\u51fa\u3002\n\n\u89e3\u7801\u5668(Decoder)\n~~~~~~~~~~~~~~~~~~~\n\n\u89e3\u7801\u5668RNN\u4ee5token-by-token\u7684\u65b9\u5f0f\u751f\u6210\u54cd\u5e94\u8bed\u53e5\u3002\u5b83\u4f7f\u7528\u7f16\u7801\u5668\u7684\u4e0a\u4e0b\u6587\u5411\u91cf\u548c\u81ea\u8eab\u5185\u90e8\u9690\u85cf\u72b6\u6001\n\u6765\u751f\u6210\u5e8f\u5217\u4e2d\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\u3002\u5b83\u8fde\u7eed\u751f\u6210\u5355\u8bcd\uff0c\u76f4\u5230\u8f93\u51fa *EOS_token* \uff0c\u8868\u793a\u53e5\u5b50\u7684\u7ed3\u5c3e\u3002\n\u5728\u4ea7\u751f\u8f93\u51fa\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u89e3\u7801\u5668\u4e2d\u7684\u6ce8\u610f\u673a\u5236(`attention mechanism <https://arxiv.org/abs/1409.0473>`__)\n\u6765\u5e2e\u52a9\u5b83\u201c\u6ce8\u610f(pay attention)\u201d\u8f93\u5165\u7684\u67d0\u4e9b\u90e8\u5206\u3002\n\u5bf9\u4e8e\u6211\u4eec\u7684\u6a21\u578b\uff0c\u6211\u4eec\u5b9e\u73b0\u4e86 `Luong \u7b49\u4eba\u7684 <https://arxiv.org/abs/1508.04025>`__ \u201c\u5168\u5c40\u6ce8\u610f\u201d\u6a21\u5757\uff0c\n\u5e76\u5c06\u5176\u7528\u4f5c\u89e3\u7801\u6a21\u578b\u4e2d\u7684\u5b50\u6a21\u5757\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6570\u636e\u5904\u7406\n-------------\n\n\u867d\u7136\u6211\u4eec\u7684\u6a21\u578b\u6982\u5ff5\u4e0a\u6765\u8bf4\u5904\u7406\u7684\u662f\u6807\u8bb0\u5e8f\u5217(sequences of tokens)\uff0c\u4f46\u5728\u73b0\u5b9e\u4e2d\uff0c\n\u5b83\u4eec\u548c\u6240\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e00\u6837\u5904\u7406\u6570\u5b57\u3002\n\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5728\u8bad\u7ec3\u524d\u5efa\u7acb\u7684\u6a21\u578b\u8bcd\u6c47\u8868\u4e2d\u7684\u6bcf\u4e2a\u5355\u8bcd\u90fd\u6620\u5c04\u5230\u4e00\u4e2a\u6574\u6570\u7d22\u5f15\u3002\n\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a ``Voc`` \u5bf9\u8c61\u6765\u5305\u542b\u4ece\u5355\u8bcd(Word)\u5230\u7d22\u5f15(index)\u7684\u6620\u5c04\uff0c\u4ee5\u53ca\u8bcd\u6c47\u8868\u4e2d\u7684\u5355\u8bcd\u603b\u6570\u3002\n\u5728\u8fd0\u884c\u6a21\u578b\u4e4b\u524d\uff0c\u6211\u4eec\u5c06\u52a0\u8f7d ``Voc`` \u5bf9\u8c61\u3002\n\n\u6b64\u5916\uff0c\u4e3a\u4e86\u80fd\u591f\u8fd0\u884c\u8bc4\u4f30\uff0c\u6211\u4eec\u5fc5\u987b\u63d0\u4f9b\u4e00\u4e2a\u5904\u7406\u6211\u4eec\u8f93\u5165\u7684\u5b57\u7b26\u4e32\u7684\u5de5\u5177\u3002\n``normalizeString`` \u51fd\u6570\u5c06\u5b57\u7b26\u4e32\u4e2d\u7684\u6240\u6709\u5b57\u7b26\u8f6c\u6362\u4e3a\u5c0f\u5199\uff0c\u5e76\u5220\u9664\u6240\u6709\u975e\u5b57\u6bcd\u5b57\u7b26\n(non-letter characters)\u3002``indexesFromSentence`` \u51fd\u6570\u63a5\u53d7\u4e00\u4e2a\u6709\u82e5\u5e72\u5355\u8bcd\u7684\u53e5\u5b50\n\u5e76\u8fd4\u56de\u76f8\u5e94\u7684\u5355\u8bcd\u7d22\u5f15\u7684\u5e8f\u5217(sequence of word indexes)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Voc:\n    def __init__(self, name):\n        self.name = name\n        self.trimmed = False\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n        self.num_words = 3  # Count SOS, EOS, PAD\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.num_words\n            self.word2count[word] = 1\n            self.index2word[self.num_words] = word\n            self.num_words += 1\n        else:\n            self.word2count[word] += 1\n\n    # Remove words below a certain count threshold\n    def trim(self, min_count):\n        if self.trimmed:\n            return\n        self.trimmed = True\n        keep_words = []\n        for k, v in self.word2count.items():\n            if v >= min_count:\n                keep_words.append(k)\n\n        print('keep_words {} / {} = {:.4f}'.format(\n            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n        ))\n        # Reinitialize dictionaries\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n        self.num_words = 3 # Count default tokens\n        for word in keep_words:\n            self.addWord(word)\n\n\n# Lowercase and remove non-letter characters\ndef normalizeString(s):\n    s = s.lower()\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s\n\n\n# Takes string sentence, returns sentence of word indexes\ndef indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49 \u7f16\u7801\u5668\n--------------\n\n\u6211\u4eec\u7528 ``torch.nn.GRU`` \u6a21\u5757\u5b9e\u73b0\u7f16\u7801\u5668\u7684RNN\uff0c\n\u6211\u4eec\u7ed9\u8be5\u6a21\u5757\u63d0\u4f9b\u4e00\u4e2a\u6279\u6b21\u7684\u53e5\u5b50(\u8bcd\u5d4c\u5165\u7684\u5411\u91cf,vectors of word embeddings)\uff0c\n\u5b83\u4f1a\u5728\u5185\u90e8\u8fed\u4ee3\u53e5\u5b50\uff0c\u4e00\u6b21\u4e00\u4e2a\u6807\u8bb0(token)\u7684\u8ba1\u7b97\u9690\u85cf\u72b6\u6001\u3002\u6211\u4eec\u5c06\u8fd9\u4e2a\u6a21\u5757\u521d\u59cb\u5316\u4e3a\u53cc\u5411\u7684(bidirectional)\uff0c\n\u8fd9\u610f\u5473\u7740\u6211\u4eec\u6709\u4e24\u4e2a\u72ec\u7acb\u7684GRUs\uff1a\u4e00\u4e2a\u6309\u65f6\u95f4\u987a\u5e8f\u8fed\u4ee3\u5e8f\u5217\uff0c\u53e6\u4e00\u4e2a\u53cd\u5411\u8fed\u4ee3\u3002\n\u6211\u4eec\u6700\u7ec8\u8fd4\u56de\u8fd9\u4e24\u4e2aGRUs\u7684\u8f93\u51fa\u7684\u548c\u3002\u7531\u4e8e\u6211\u4eec\u7684\u6a21\u578b\u662f\u4f7f\u7528batch\u8bad\u7ec3\u7684\uff0c\n\u6240\u4ee5\u6211\u4eec\u7684 ``EncoderRNN`` \u6a21\u578b\u7684 ``forward`` \u51fd\u6570\u5e0c\u671b\u63a5\u6536\u4e00\u4e2a\u586b\u5145\u8fc7\u7684\u8f93\u5165\u6279\u6b21(a padded input batch)\u3002\n\u4e3a\u4e86\u628a\u53ef\u53d8\u957f\u5ea6\u7684\u53e5\u5b50\u6253\u5305\u5230\u540c\u4e00\u4e2abatch\uff0c\u6211\u4eec\u5141\u8bb8\u4e00\u4e2a\u53e5\u5b50\u4e2d\u6709\u6700\u5927\u7684 *MAX_LENGTH* tokens\uff0c\n\u5e76\u4e14batch\u4e2d\u6240\u6709\u5c0f\u4e8e *MAX_LENGTH* tokens \u7684\u8bed\u53e5\u5728\u5176\u7ed3\u5c3e\u5904\u90fd\u4f1a\u7528\u6211\u4eec\u4e13\u7528\u7684 *PAD_token* tokens \u8fdb\u884c\u586b\u5145\u3002\n\n\u82e5\u8981\u5728PyTorch RNN\u6a21\u5757\u4e2d\u4f7f\u7528 padded batches\uff0c\u6211\u4eec\u5fc5\u987b\u7528 \n``torch.nn.utils.rnn.pack_padded_sequence`` \n\u548c ``torch.nn.utils.rnn.pad_packed_sequence`` \u6570\u636e\u8f6c\u6362\u5668 \u5c01\u88c5\u6211\u4eec\u7684\u524d\u5411\u4f20\u9012\u8fc7\u7a0b\u3002\n\u6ce8\u610f\uff0c ``forward`` \u51fd\u6570\u8fd8\u63a5\u53d7\u4e00\u4e2a ``input_lengths`` \u5217\u8868\uff0c\n\u5176\u4e2d\u5305\u542bbatch\u4e2d\u6bcf\u4e2a\u53e5\u5b50\u7684\u957f\u5ea6\u3002\u8fd9\u4e2a\u8f93\u5165\u5728\u8fdb\u884c\u586b\u5145(padding)\u65f6\u7531 \n``torch.nn.utils.rnn.pack_padded_sequence`` \u51fd\u6570\u4f7f\u7528\u3002\n\nHybrid Frontend Notes:\n~~~~~~~~~~~~~~~~~~~~~~\n\n\u7531\u4e8e\u7f16\u7801\u5668\u7684 ``forward`` \u51fd\u6570\u4e0d\u5305\u542b\u4efb\u4f55\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u63a7\u5236\u6d41\uff0c\u6211\u4eec\u5c06\u4f7f\u7528 **tracing** \u5c06\u5176\u8f6c\u6362\u4e3a\u811a\u672c\u6a21\u5f0f\u3002\n\u5f53\u8ddf\u8e2a\u6a21\u5757\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba9\u6a21\u5757\u5b9a\u4e49\u4fdd\u6301\u539f\u6837\u3002\u6211\u4eec\u5c06\u5728\u672c\u6587\u6863\u672b\u5c3e\u5728\u8fd0\u884c\u8bc4\u4f30\u4e4b\u524d\u521d\u59cb\u5316\u6240\u6709\u6a21\u578b\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n        super(EncoderRNN, self).__init__()\n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        self.embedding = embedding\n\n        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n        #   because our input size is a word embedding with number of features == hidden_size\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n\n    def forward(self, input_seq, input_lengths, hidden=None):\n        # Convert word indexes to embeddings\n        embedded = self.embedding(input_seq)\n        # Pack padded batch of sequences for RNN module\n        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n        # Forward pass through GRU\n        outputs, hidden = self.gru(packed, hidden)\n        # Unpack padding\n        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n        # Sum bidirectional GRU outputs\n        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n        # Return output and final hidden state\n        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49\u89e3\u7801\u5668\u7684\u6ce8\u610f\u529b\u6a21\u5757\n---------------------------------\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u5b9a\u4e49\u6211\u4eec\u7684attention\u6a21\u5757 (``Attn``)\u3002\n\u8bf7\u6ce8\u610f\uff0c\u6b64\u6a21\u5757\u5c06\u7528\u4f5c\u6211\u4eec\u7684\u89e3\u7801\u5668\u6a21\u578b\u4e2d\u7684\u5b50\u6a21\u5757\u3002Luong\u7b49\u4eba\u8003\u8651\u4e86\u5404\u79cd \u201cscore functions\u201d\uff0c\n\u5373\u63a5\u6536\u5f53\u524d\u89e3\u7801\u5668RNN\u7684\u8f93\u51fa\u548c\u6574\u4e2a\u7f16\u7801\u5668\u7684\u8f93\u51fa\uff0c\u5e76\u8fd4\u56de\u6ce8\u610f\u529b\u201c\u80fd\u91cf\u201d\u3002\n\u8fd9\u4e2a\u6ce8\u610f\u529b\u80fd\u91cf\u5f20\u91cf\u4e0e\u7f16\u7801\u5668\u7684\u8f93\u51fa\u5927\u5c0f\u76f8\u540c\uff0c\u4e24\u8005\u6700\u7ec8\u88ab\u4e58\u8d77\u6765\uff0c\u4ece\u800c\u5f97\u5230\u4e00\u4e2a\u52a0\u6743\u5f20\u91cf\uff0c\n\u5176\u6700\u5927\u503c\u4ee3\u8868\u5728\u7279\u5b9a\u89e3\u7801\u65f6\u95f4\u6b65\u7684\u67e5\u8be2\u8bed\u53e5\u4e2d\u6700\u91cd\u8981\u7684\u90e8\u5206\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Luong attention layer\nclass Attn(torch.nn.Module):\n    def __init__(self, method, hidden_size):\n        super(Attn, self).__init__()\n        self.method = method\n        if self.method not in ['dot', 'general', 'concat']:\n            raise ValueError(self.method, \"is not an appropriate attention method.\")\n        self.hidden_size = hidden_size\n        if self.method == 'general':\n            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n        elif self.method == 'concat':\n            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n\n    def dot_score(self, hidden, encoder_output):\n        return torch.sum(hidden * encoder_output, dim=2)\n\n    def general_score(self, hidden, encoder_output):\n        energy = self.attn(encoder_output)\n        return torch.sum(hidden * energy, dim=2)\n\n    def concat_score(self, hidden, encoder_output):\n        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n        return torch.sum(self.v * energy, dim=2)\n\n    def forward(self, hidden, encoder_outputs):\n        # Calculate the attention weights (energies) based on the given method\n        if self.method == 'general':\n            attn_energies = self.general_score(hidden, encoder_outputs)\n        elif self.method == 'concat':\n            attn_energies = self.concat_score(hidden, encoder_outputs)\n        elif self.method == 'dot':\n            attn_energies = self.dot_score(hidden, encoder_outputs)\n\n        # Transpose max_length and batch_size dimensions\n        attn_energies = attn_energies.t()\n\n        # Return the softmax normalized probability scores (with added dimension)\n        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49\u89e3\u7801\u5668\n--------------\n\n\u7c7b\u4f3c\u4e8e ``EncoderRNN`` \uff0c\u6211\u4eec\u4f7f\u7528 ``torch.nn.GRU`` \u6a21\u5757\u4f5c\u4e3a\u89e3\u7801\u5668\u7684RNN\u3002\n\u7136\u800c\uff0c\u8fd9\u4e00\u6b21\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u5355\u5411(unidirectional) GRU\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0e\u7f16\u7801\u5668\u4e0d\u540c\u7684\u662f\uff0c\n\u6211\u4eec\u5c06\u7ed9\u89e3\u7801\u5668RNN\u4e00\u6b21\u5582\u4e00\u4e2a\u5355\u8bcd(word)\u3002\n\u6211\u4eec\u4ece\u83b7\u53d6\u5f53\u524d\u5355\u8bcd\u7684\u5d4c\u5165(embedding)\u5f00\u59cb\uff0c\u5e76\u5e94\u7528\u4e00\u4e2a `dropout <https://pytorch.org/docs/stable/nn.html?highlight=dropout#torch.nn.Dropout>`__ \u3002\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u5d4c\u5165(embedding)\u548c\u6700\u540e\u9690\u85cf\u72b6\u6001 \u5411\u524d\u4f20\u9001\u5230GRU\uff0c\u5e76\u83b7\u5f97\u5f53\u524dGRU\u8f93\u51fa\u548c\u9690\u85cf\u72b6\u6001\u3002\n\u7136\u540e\uff0c\u6211\u4eec\u4f7f\u7528\u6211\u4eec\u7684 ``Attn`` \u6a21\u5757\u4f5c\u4e3a\u4e00\u4e2a\u5c42\u6765\u83b7\u5f97\u6ce8\u610f\u529b\u6743\u503c\uff0c\n\u7136\u540e\u4e58\u4ee5\u7f16\u7801\u5668\u7684\u8f93\u51fa\u6765\u83b7\u5f97\u88ab\u6ce8\u610f\u529b\u52a0\u6743\u8fc7\u7684\u7f16\u7801\u5668\u8f93\u51fa\u3002\n\u6211\u4eec\u4f7f\u7528\u8fd9\u4e2a\u6ce8\u610f\u529b\u52a0\u6743\u7f16\u7801\u5668\u8f93\u51fa\u4f5c\u4e3a ``context`` \u5f20\u91cf\uff0c\u5b83\u8868\u793a\u4e00\u4e2a\u52a0\u6743\u548c\uff0c\n\u6307\u793a\u7f16\u7801\u5668\u8f93\u51fa\u7684\u54ea\u4e9b\u90e8\u5206\u9700\u8981\u88ab\u6ce8\u610f\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u4f7f\u7528\u7ebf\u6027\u5c42\u548cSoftmax\u5f52\u4e00\u5316\u6765\n\u9009\u62e9\u8f93\u51fa\u5e8f\u5217\u4e2d\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\u3002\n\nHybrid Frontend Notes:\n~~~~~~~~~~~~~~~~~~~~~~\n\n\u4e0e ``EncoderRNN`` \u7c7b\u4f3c\uff0c\u6b64\u6a21\u5757\u4e0d\u5305\u542b\u4efb\u4f55\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u63a7\u5236\u6d41\u3002 \u56e0\u6b64\uff0c\u5728\u521d\u59cb\u5316\u8be5\u6a21\u578b\u5e76\u52a0\u8f7d\u5176\u53c2\u6570\u4e4b\u540e\uff0c\n\u6211\u4eec\u53ef\u4ee5\u518d\u6b21\u4f7f\u7528 **tracing** \u5c06\u8be5\u6a21\u578b\u8f6c\u6362\u4e3a Torch Script \u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n        super(LuongAttnDecoderRNN, self).__init__()\n\n        # Keep for reference\n        self.attn_model = attn_model\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.dropout = dropout\n\n        # Define layers\n        self.embedding = embedding\n        self.embedding_dropout = nn.Dropout(dropout)\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n\n        self.attn = Attn(attn_model, hidden_size)\n\n    def forward(self, input_step, last_hidden, encoder_outputs):\n        # Note: we run this one step (word) at a time\n        # Get embedding of current input word\n        embedded = self.embedding(input_step)\n        embedded = self.embedding_dropout(embedded)\n        # Forward through unidirectional GRU\n        rnn_output, hidden = self.gru(embedded, last_hidden)\n        # Calculate attention weights from the current GRU output\n        attn_weights = self.attn(rnn_output, encoder_outputs)\n        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n        # Concatenate weighted context vector and GRU output using Luong eq. 5\n        rnn_output = rnn_output.squeeze(0)\n        context = context.squeeze(1)\n        concat_input = torch.cat((rnn_output, context), 1)\n        concat_output = torch.tanh(self.concat(concat_input))\n        # Predict next word using Luong eq. 6\n        output = self.out(concat_output)\n        output = F.softmax(output, dim=1)\n        # Return output and final hidden state\n        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49\u8bc4\u4f30\n-----------------\n\n\u8d2a\u5a6a\u641c\u7d22\u89e3\u7801\u5668\n~~~~~~~~~~~~~~~~~~~~~\n\n\u5728\u804a\u5929\u673a\u5668\u4eba\u6559\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528 ``GreedySearchDecoder`` \u6a21\u5757\u6765\u7b80\u5316\u5b9e\u9645\u7684\u89e3\u7801\u8fc7\u7a0b\u3002\n\u8be5\u6a21\u5757\u628a\u7ecf\u8fc7\u8bad\u7ec3\u7684\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u6a21\u578b\u4f5c\u4e3a\u5176\u5c5e\u6027\uff0c\u9a71\u52a8\u7f16\u7801\u5668\u5bf9\u8f93\u5165\u8bed\u53e5(a vector of word indexes)\n\u8fdb\u884c\u7f16\u7801\uff0c\u5e76\u4e00\u6b21\u4e00\u4e2a\u5355\u8bcd(word index)\u7684\u8fed\u4ee3\u5f0f\u7684\u89e3\u7801\u4e00\u4e2a\u8f93\u51fa\u54cd\u5e94\u5e8f\u5217\u3002\n\n\u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u7f16\u7801\u662f\u7b80\u5355\u76f4\u63a5\u7684\uff1a\u53ea\u9700\u5c06\u6574\u4e2a\u5e8f\u5217\u5f20\u91cf\u53ca\u5176\u5bf9\u5e94\u7684\u957f\u5ea6\u5411\u91cf\u5411\u524d\u9988\u9001\u7ed9\u7f16\u7801\u5668 ``encoder`` \u3002\n\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u4e2a\u6a21\u5757\u4e00\u6b21\u53ea\u5904\u7406\u4e00\u4e2a\u8f93\u5165\u5e8f\u5217\uff0c\u800c **\u4e0d\u662f** \u4e00\u6279\u5e8f\u5217(batches of sequences)\u3002\n\u56e0\u6b64\uff0c\u5f53\u5e38\u6570  **1** \u7528\u4e8e\u58f0\u660e\u5f20\u91cf\u5927\u5c0f\u65f6\uff0c\u8fd9\u5bf9\u5e94\u4e8ebatch size\u4e3a 1\u3002\u4e3a\u4e86\u89e3\u7801\u4e00\u4e2a\u7ed9\u5b9a\u7684\u89e3\u7801\u5668\u8f93\u51fa\uff0c\n\u6211\u4eec\u5fc5\u987b\u8fed\u4ee3\u5730\u5411\u524d\u904d\u5386\u6211\u4eec\u7684\u89e3\u7801\u5668\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4f1a\u8f93\u51fa \u5bf9\u5e94\u4e8e\u6bcf\u4e2a\u5355\u8bcd\u6210\u4e3a\u89e3\u7801\u5e8f\u5217\u4e2d\u6b63\u786e\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\n\u7684\u6982\u7387\u7684 Softmax\u5206\u6570\u3002\u6211\u4eec\u628a ``decoder_input``  \u521d\u59cb\u5316\u4e3a\u5305\u542b *SOS_token* \u7684\u5f20\u91cf\u3002\n\u5728\u6bcf\u6b21\u901a\u8fc7\u89e3\u7801\u5668 ``decoder`` \u540e\uff0c\u6211\u4eec\u8d2a\u5a6a\u5730(*greedily*)\u5c06\u5177\u6709\u6700\u9ad8Softmax\u6982\u7387\u7684\u5355\u8bcd\u9644\u52a0\n\u5230 ``decoded_words`` \u5217\u8868\u4e2d\u3002\n\u6211\u4eec\u8fd8\u4f7f\u7528\u8fd9\u4e2a\u8bcd\u4f5c\u4e3a\u4e0b\u4e00\u6b21\u8fed\u4ee3\u7684 ``decoder_input`` \u3002\u5982\u679c ``decoded_words`` \u5217\u8868\u7684\u957f\u5ea6\u8fbe\u5230\n*MAX_LENGTH* \uff0c\u6216\u8005\u5982\u679c\u9884\u6d4b\u7684\u5355\u8bcd\u662f *EOS_token*\uff0c\u5219\u89e3\u7801\u8fc7\u7a0b\u7ec8\u6b62\u3002\n\n\nHybrid Frontend Notes:\n~~~~~~~~~~~~~~~~~~~~~~\n\n\u8be5\u6a21\u5757\u7684 ``forward`` \u65b9\u6cd5\u5728\u4e00\u6b21\u4e00\u4e2a\u5355\u8bcd\u7684\u89e3\u7801\u4e00\u4e2a\u8f93\u51fa\u5e8f\u5217\u65f6\u6d89\u53ca\u5230\u5728 $[0, max\\_length)$ \n\u8303\u56f4\u4e0a\u8fdb\u884c\u8fed\u4ee3 \u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528 **scripting** \u5c06\u8fd9\u4e2a\u6a21\u5757\u8f6c\u6362\u4e3aTorch Script\u3002\n\u4e0e\u6211\u4eec\u53ef\u4ee5\u8ddf\u8e2a(trace)\u7684\u7f16\u7801\u3001\u89e3\u7801\u6a21\u578b\u4e0d\u540c\uff0c\n\u6211\u4eec\u5fc5\u987b\u5bf9 ``GreedySearchDecoder`` \u6a21\u5757\u8fdb\u884c\u4e00\u4e9b\u5fc5\u8981\u7684\u66f4\u6539\uff0c\u4ee5\u4fbf\u5728\u6ca1\u6709\u9519\u8bef\u7684\u60c5\u51b5\u4e0b\u521d\u59cb\u5316\u4e00\u4e2a\u5bf9\u8c61\u3002\n\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u5fc5\u987b\u786e\u4fdd\u6211\u4eec\u7684\u6a21\u5757\u9075\u5b88\u811a\u672c\u673a\u5236\u7684\u89c4\u5219(rules of the scripting mechanism)\uff0c\n\u5e76\u4e14\u4e0d\u4f7f\u7528Torch Script\u6240\u5305\u542b\u7684Python\u5b50\u96c6\u4e4b\u5916\u7684\u4efb\u4f55\u8bed\u8a00\u7279\u6027\u3002\n\n\u4e3a\u4e86\u4e86\u89e3\u53ef\u80fd\u9700\u8981\u7684\u4e00\u4e9b\u64cd\u4f5c\uff0c\u6211\u4eec\u5c06\u4ece\u804a\u5929\u673a\u5668\u4eba\u6559\u7a0b\u4e2d\u7684 ``GreedySearchDecoder`` \u5b9e\u73b0\n\u4e0e\u6211\u4eec\u5728\u4e0b\u9762\u7684\u5355\u5143\u683c\u4e2d\u4f7f\u7528\u7684\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u8bf7\u6ce8\u610f\uff0c\u4ee5\u7ea2\u8272\u7a81\u51fa\u663e\u793a\u7684\u884c\u662f\u4ece\u539f\u59cb\u5b9e\u73b0\u4e2d\u5220\u9664\u7684\u884c\uff0c\n\u4ee5\u7eff\u8272\u7a81\u51fa\u663e\u793a\u7684\u884c\u662f\u65b0\u589e\u52a0\u7684\u3002\u8fd9\u4e48\u505a\u53ef\u4ee5\u5f88\u660e\u663e\u7684\u770b\u51fa\u6211\u4eec\u5bf9\u539f\u59cb\u7684 ``GreedySearchDecoder`` \u7c7b\u505a\u4e86\u54ea\u4e9b\n\u6539\u53d8\u3002\n\n.. figure:: /_static/img/chatbot/diff.png\n   :align: center\n   :alt: diff\n\n\u6539\u52a8\u7684\u5730\u65b9:\n^^^^^^^^^^^^^\n\n-  ``nn.Module`` -> ``torch.jit.ScriptModule``\n\n   -  \u4e3a\u4e86\u5728\u6a21\u5757\u4e0a\u4f7f\u7528PyTorch\u7684\u811a\u672c\u673a\u5236\uff0c\u8be5\u6a21\u5757\u5fc5\u987b\u7ee7\u627f ``torch.jit.ScriptModule`` \u3002\n\n\n-  \u628a ``decoder_n_layers`` \u6dfb\u52a0\u5230\u6784\u9020\u5668\u53c2\u6570\n\n   -  \u8fd9\u4e00\u53d8\u5316\u6e90\u4e8e\u8fd9\u6837\u4e00\u4e2a\u4e8b\u5b9e\uff1a\u6211\u4eec\u4f20\u9012\u7ed9\u8fd9\u4e2a\u6a21\u5757(module)\u7684\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u6a21\u578b\u5c06\u662f\n      ``TracedModule`` (not ``Module``) \u7684\u5b50\u6a21\u5757\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4e0d\u80fd\u4f7f\u7528 ``decoder.n_layers`` \n      \u8bbf\u95ee\u89e3\u7801\u5668\u7684\u5c42\u6570\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u5bf9\u6b64\u8fdb\u884c\u89c4\u5212\uff0c\u5e76\u5728\u6a21\u5757\u6784\u9020\u671f\u95f4\u4f20\u9012\u6b64\u503c\u3002\n\n\n-  \u5c06\u65b0\u5c5e\u6027\u5b58\u50a8\u4e3a\u5e38\u91cf\n\n   -  \u5728\u6700\u521d\u7684\u5b9e\u73b0\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u5728 ``GreedySearchDecoder`` \u7684 ``forward`` \u65b9\u6cd5\u4e2d\u81ea\u7531\u5730\u4f7f\u7528\u6765\u81ea\n      \u5468\u56f4(\u5168\u5c40)\u8303\u56f4\u7684\u53d8\u91cf\u3002\u4f46\u662f\uff0c\u65e2\u7136\u6211\u4eec\u4f7f\u7528\u7684\u662f\u811a\u672c(scripting)\uff0c\u6211\u4eec\u5c31\u6ca1\u6709\u8fd9\u79cd\u81ea\u7531\uff0c\n      \u56e0\u4e3a\u811a\u672c\u7684\u5047\u8bbe\u662f\uff0c\u6211\u4eec\u4e0d\u4e00\u5b9a\u8981\u4fdd\u7559Python\u5bf9\u8c61\uff0c\u5c24\u5176\u662f\u5728\u5bfc\u51fa\u65f6\u3002\n      \u5bf9\u6b64\uff0c\u4e00\u4e2a\u7b80\u5355\u7684\u89e3\u51b3\u65b9\u6848\u662f\u5c06\u8fd9\u4e9b\u503c\u4ece\u5168\u5c40\u8303\u56f4\u5b58\u50a8\u4e3a\u6784\u9020\u51fd\u6570\u4e2d\u7684\u6a21\u5757\u7684\u5c5e\u6027\uff0c\n      \u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230\u4e00\u4e2a\u540d\u4e3a ``__constants__`` \u7684\u7279\u6b8a\u5217\u8868\u4e2d\uff0c\n      \u4ee5\u4fbf\u5728 ``forward`` \u65b9\u6cd5\u4e2d\u6784\u9020\u56fe\u65f6\u53ef\u4ee5\u5c06\u5b83\u4eec\u7528\u4f5c\u6587\u5b57\u503c(literal values)\u3002\n      \u8fd9\u79cd\u7528\u6cd5\u7684\u4e00\u4e2a\u4f8b\u5b50\u662f\u5728 **\u65b0** \u7684\u7b2c19\u884c\u4e2d\uff0c\u6211\u4eec\u6ca1\u6709\u4f7f\u7528  ``device`` \u548c ``SOS_token`` \n      \u5168\u5c40\u503c\uff0c\u800c\u662f\u4f7f\u7528\u5e38\u91cf\u5c5e\u6027 ``self._device`` \u548c ``self._SOS_token`` \u3002\n\n\n-  \u628a ``torch.jit.script_method`` \u88c5\u9970\u5668\u6dfb\u52a0\u5230 ``forward`` \u65b9\u6cd5\n\n   -  \u6dfb\u52a0\u8fd9\u4e2a\u88c5\u9970\u5668\u8ba9JIT\u7f16\u8bd1\u5668\u77e5\u9053\u5b83\u6b63\u5728\u4fee\u9970\u7684\u51fd\u6570\u5e94\u8be5\u662f\u811a\u672c\u5316\u7684\u3002\n\n\n-  \u5f3a\u5236\u8f6c\u6362 ``forward`` \u65b9\u6cd5\u53c2\u6570\u7684\u7c7b\u578b\n\n   -  \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cTorch Script \u51fd\u6570\u7684\u6240\u6709\u53c2\u6570\u90fd\u5047\u5b9a\u4e3a\u5f20\u91cf(Tensor)\u3002\n      \u5982\u679c\u6211\u4eec\u9700\u8981\u4f20\u9012\u4e00\u4e2a\u4e0d\u540c\u7c7b\u578b\u7684\u53c2\u6570\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 \n      `PEP 3107 <https://www.python.org/dev/peps/pep-3107/>`__ \n      \u4e2d\u5f15\u5165\u7684\u51fd\u6570\u7c7b\u578b\u6ce8\u91ca\u3002\n      \u6b64\u5916\uff0c\u53ef\u4ee5\u4f7f\u7528MyPy\u6837\u5f0f\u7684\u7c7b\u578b\u6ce8\u91ca\u58f0\u660e\u4e0d\u540c\u7c7b\u578b\u7684\u53c2\u6570\n      (\u53c2\u89c1 `doc <https://pytorch.org/docs/master/jit.html#types>`__)\u3002\n\n\n-  \u4fee\u6539 ``decoder_input`` \u7684\u521d\u59cb\u5316\n\n   -  \u5728\u6700\u521d\u7684\u5b9e\u73b0\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528 ``torch.LongTensor([[SOS_token]])`` \n      \u521d\u59cb\u5316\u4e86 ``decoder_input`` \u5f20\u91cf\u3002\u5728\u7f16\u5199\u811a\u672c\u65f6\uff0c\n      \u4e0d\u5141\u8bb8\u6211\u4eec\u4ee5\u8fd9\u6837\u7684\u6587\u5b57\u65b9\u5f0f(literal fashion)\u521d\u59cb\u5316\u5f20\u91cf\u3002\n      \u76f8\u53cd\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u4e00\u4e2a\u663e\u5f0f\u7684torch\u51fd\u6570(\u5982  ``torch.ones`` )\u521d\u59cb\u5316\u5f20\u91cf\u3002\n      \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u590d\u5236\u6807\u91cf ``decoder_input`` \u5f20\u91cf\uff0c\n      \u65b9\u6cd5\u662f\u5c06 1 \u4e58\u4ee5\u5b58\u50a8\u5728\u5e38\u91cf ``self._SOS_token`` \u4e2d\u7684SOS_token\u503c\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class GreedySearchDecoder(torch.jit.ScriptModule):\n    def __init__(self, encoder, decoder, decoder_n_layers):\n        super(GreedySearchDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self._device = device\n        self._SOS_token = SOS_token\n        self._decoder_n_layers = decoder_n_layers\n\n    __constants__ = ['_device', '_SOS_token', '_decoder_n_layers']\n\n    @torch.jit.script_method\n    def forward(self, input_seq : torch.Tensor, input_length : torch.Tensor, max_length : int):\n        # Forward input through encoder model\n        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n        decoder_hidden = encoder_hidden[:self._decoder_n_layers]\n        # Initialize decoder input with SOS_token\n        decoder_input = torch.ones(1, 1, device=self._device, dtype=torch.long) * self._SOS_token\n        # Initialize tensors to append decoded words to\n        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long)\n        all_scores = torch.zeros([0], device=self._device)\n        # Iteratively decode one word token at a time\n        for _ in range(max_length):\n            # Forward pass through decoder\n            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n            # Obtain most likely word token and its softmax score\n            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n            # Record token and score\n            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n            # Prepare current token to be next decoder input (add a dimension)\n            decoder_input = torch.unsqueeze(decoder_input, 0)\n        # Return collections of word tokens and scores\n        return all_tokens, all_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bc4\u4f30\u4e00\u4e2a\u8f93\u5165\n~~~~~~~~~~~~~~~~~~~\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e9b\u7528\u4e8e\u8bc4\u4f30\u8f93\u5165\u7684\u51fd\u6570\u3002``evaluate`` \u51fd\u6570\u63a5\u53d7\u89c4\u8303\u5316\u7684\u5b57\u7b26\u4e32\u8bed\u53e5\uff0c\n\u5c06\u5176\u5904\u7406\u4e3a\u76f8\u5e94\u7684\u5355\u8bcd\u7d22\u5f15(batch size\u4e3a1)\u7684\u5f20\u91cf\uff0c\u5e76\u5c06\u6b64\u5f20\u91cf\u4f20\u9012\u7ed9\u540d\u4e3a ``searcher`` \n\u7684 ``GreedySearchDecoder`` \u5bf9\u8c61\u7684\u5b9e\u4f8b\uff0c\u4ee5\u5904\u7406\u7f16\u7801/\u89e3\u7801\u8fc7\u7a0b\u3002 ``searcher`` \n\u8fd4\u56de \u8f93\u51fa\u5355\u8bcd\u7d22\u5f15\u5411\u91cf \u548c\u5bf9\u5e94\u4e8e\u6bcf\u4e2a\u89e3\u7801\u5355\u8bcd\u6807\u8bb0\u7684Softmax\u5206\u6570\u7684\u5206\u6570\u5f20\u91cf\u3002\n\u6700\u540e\u4e00\u6b65\u662f\u4f7f\u7528 ``voc.index2word`` \u5c06\u6bcf\u4e2a\u5355\u8bcd\u7d22\u5f15\u8f6c\u6362\u56de\u5176\u5b57\u7b26\u4e32\u8868\u793a\u5f62\u5f0f\u3002\n\n\u6211\u4eec\u8fd8\u5b9a\u4e49\u4e86\u8bc4\u4f30\u8f93\u5165\u53e5\u5b50\u7684\u4e24\u4e2a\u51fd\u6570\u3002``evaluateInput`` \u51fd\u6570\u63d0\u793a\u7528\u6237\u8f93\u5165\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u8ba1\u7b97\u3002\n\u5b83\u5c06\u7ee7\u7eed\u8981\u6c42\u53e6\u4e00\u4e2a\u8f93\u5165\uff0c\u76f4\u5230\u7528\u6237\u8f93\u5165\u2018q\u2019\u6216\u2018\u9000\u51fa\u2019\u3002\n\n``evaluateExample`` \u51fd\u6570\u7b80\u5355\u5730\u5c06\u5b57\u7b26\u4e32\u8f93\u5165\u8bed\u53e5\u4f5c\u4e3a\u53c2\u6570\uff0c\u5bf9\u5176\u8fdb\u884c\u89c4\u8303\u5316\u3001\u8ba1\u7b97\u5e76\u6253\u5370\u54cd\u5e94\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n    ### Format input sentence as a batch\n    # words -> indexes\n    indexes_batch = [indexesFromSentence(voc, sentence)]\n    # Create lengths tensor\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    # Transpose dimensions of batch to match models' expectations\n    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n    # Use appropriate device\n    input_batch = input_batch.to(device)\n    lengths = lengths.to(device)\n    # Decode sentence with searcher\n    tokens, scores = searcher(input_batch, lengths, max_length)\n    # indexes -> words\n    decoded_words = [voc.index2word[token.item()] for token in tokens]\n    return decoded_words\n\n\n# Evaluate inputs from user input (stdin)\ndef evaluateInput(encoder, decoder, searcher, voc):\n    input_sentence = ''\n    while(1):\n        try:\n            # Get input sentence\n            input_sentence = input('> ')\n            # Check if it is quit case\n            if input_sentence == 'q' or input_sentence == 'quit': break\n            # Normalize sentence\n            input_sentence = normalizeString(input_sentence)\n            # Evaluate sentence\n            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n            # Format and print response sentence\n            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n            print('Bot:', ' '.join(output_words))\n\n        except KeyError:\n            print(\"Error: Encountered unknown word.\")\n\n# Normalize input sentence and call evaluate()\ndef evaluateExample(sentence, encoder, decoder, searcher, voc):\n    print(\"> \" + sentence)\n    # Normalize sentence\n    input_sentence = normalizeString(sentence)\n    # Evaluate sentence\n    output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n    print('Bot:', ' '.join(output_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u9884\u5148\u8bad\u7ec3\u7684\u53c2\u6570\n--------------------------\n\n\u597d! \u662f\u65f6\u5019\u52a0\u8f7d\u6211\u4eec\u7684\u6a21\u578b\u4e86\uff01\uff01\uff01\n\n\u4f7f\u7528\u522b\u4eba\u8bad\u7ec3\u597d\u7684\u6a21\u578b\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n\u8981\u52a0\u8f7d\u522b\u4eba\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff08hosted model\uff09:\n\n1) \u4e0b\u8f7d\u6a21\u578b\u5728 `\u8fd9\u91cc <https://download.pytorch.org/models/tutorials/4000_checkpoint.tar>`__.\n\n2) \u8bbe\u7f6e ``loadFilename`` \u53d8\u91cf\uff0c\u6307\u5411\u4e0b\u8f7d\u4e0b\u6765\u7684\u68c0\u67e5\u70b9\u6587\u4ef6(checkpoint file)\u7684\u8def\u5f84\n\n3) \u53d6\u6d88\u5bf9 ``checkpoint = torch.load(loadFilename)`` \u884c\u7684\u6ce8\u91ca, \u56e0\u4e3a hosted model \u662f\u7528CPU\u8bad\u7ec3\u7684\u3002\n\n\u4f7f\u7528\u81ea\u5df1\u7684\u6a21\u578b\n~~~~~~~~~~~~~~~~~~\n\n\u8981\u52a0\u8f7d\u81ea\u5df1\u9884\u5148\u8bad\u7ec3\u7684\u6a21\u578b:\n\n1) \u8bbe\u7f6e ``loadFilename`` \u53d8\u91cf\uff0c\u6307\u5411\u4f60\u81ea\u5df1\u7684\u68c0\u67e5\u70b9\u6587\u4ef6(checkpoint file)\u7684\u8def\u5f84\u3002\n   \u8bf7\u6ce8\u610f\u5982\u679c\u4f60\u6839\u636e\u804a\u5929\u673a\u5668\u4eba\u6559\u7a0b\u7684\u7ea6\u5b9a\u89c4\u8303\u4fdd\u5b58\u4e86\u6a21\u578b\uff0c\u4f60\u5c31\u5f97\u505a\u4e00\u4e9b\u6539\u52a8\uff1a\n   ``model_name``, ``encoder_n_layers``, ``decoder_n_layers``,\n   ``hidden_size``, \u548c ``checkpoint_iter`` \n   (\u56e0\u4e3a\u8fd9\u4e9b\u503c\u88ab\u7528\u5230\u4e86\u6a21\u578b\u7684\u8def\u5f84\u4e2d\u4e86)\u3002\n\n2) \u5982\u679c\u4f60\u662f\u5728CPU\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b, \u8bf7\u786e\u4fdd\u4f60\u6253\u5f00\u68c0\u67e5\u70b9\u6587\u4ef6\u7684\u65f6\u5019\u4f7f\u7528 \n   ``checkpoint = torch.load(loadFilename)`` \u3002\n   \u5982\u679c\u4f60\u662f\u5728GPU\u4e0a\u8bad\u7ec3\u7684\u6a21\u578bGPU\u4f46\u662f\u5728CPU\u4e0a\u8fd0\u884c\u7684\u6b64\u6559\u7a0b, \u8bf7\u53d6\u6d88 \n   ``checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))`` \n   \u884c\u7684\u6ce8\u91ca\u3002\n\nHybrid Frontend Notes:\n~~~~~~~~~~~~~~~~~~~~~~\n\n\u6ce8\u610f\uff0c\u6211\u4eec\u50cf\u5f80\u5e38\u4e00\u6837\u521d\u59cb\u5316\u53c2\u6570\u5e76\u5c06\u53c2\u6570\u52a0\u8f7d\u5230\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u6a21\u578b\u4e2d\u3002\n\u6b64\u5916\uff0c\u5728\u8ddf\u8e2a\u6a21\u578b\u4e4b\u524d\uff0c\u6211\u4eec\u5fc5\u987b\u8c03\u7528 ``.to(device)`` \u6765\u8bbe\u7f6e\u6a21\u578b\u7684\u8bbe\u5907\u9009\u9879\uff0c\n\u5e76\u8c03\u7528 ``.eval()`` \u6765\u5c06dropout layers\u8bbe\u7f6e\u4e3a\u6d4b\u8bd5\u6a21\u5f0f\u3002\n``TracedModule`` \u5bf9\u8c61\u4e0d\u7ee7\u627f ``to`` \u6216 ``eval`` \u65b9\u6cd5\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "save_dir = os.path.join(\"data\", \"save\")\ncorpus_name = \"cornell movie-dialogs corpus\"\n\n# Configure models\nmodel_name = 'cb_model'\nattn_model = 'dot'\n#attn_model = 'general'\n#attn_model = 'concat'\nhidden_size = 500\nencoder_n_layers = 2\ndecoder_n_layers = 2\ndropout = 0.1\nbatch_size = 64\n\n# If you're loading your own model\n# Set checkpoint to load from\ncheckpoint_iter = 4000\n# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n#                             '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n#                             '{}_checkpoint.tar'.format(checkpoint_iter))\n\n# If you're loading the hosted model\nloadFilename = 'data/4000_checkpoint.tar'\n\n# Load model\n# Force CPU device options (to match tensors in this tutorial)\ncheckpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\nencoder_sd = checkpoint['en']\ndecoder_sd = checkpoint['de']\nencoder_optimizer_sd = checkpoint['en_opt']\ndecoder_optimizer_sd = checkpoint['de_opt']\nembedding_sd = checkpoint['embedding']\nvoc = Voc(corpus_name)\nvoc.__dict__ = checkpoint['voc_dict']\n\n\nprint('Building encoder and decoder ...')\n# Initialize word embeddings\nembedding = nn.Embedding(voc.num_words, hidden_size)\nembedding.load_state_dict(embedding_sd)\n# Initialize encoder & decoder models\nencoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\ndecoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n# Load trained model params\nencoder.load_state_dict(encoder_sd)\ndecoder.load_state_dict(decoder_sd)\n# Use appropriate device\nencoder = encoder.to(device)\ndecoder = decoder.to(device)\n# Set dropout layers to eval mode\nencoder.eval()\ndecoder.eval()\nprint('Models built and ready to go!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u628a\u6a21\u578b\u8f6c\u6362\u4e3aTorch Script\n-----------------------------\n\n\u7f16\u7801\u5668(Encoder)\n~~~~~~~~~~~~~~~~~\n\n\u5982\u524d\u6240\u8ff0\uff0c\u4e3a\u4e86\u5c06\u7f16\u7801\u5668\u6a21\u578b\u8f6c\u6362\u4e3a Torch Script\uff0c\u6211\u4eec\u4f7f\u7528 **tracing** \u3002\u8ddf\u8e2a\u4efb\u4f55\u6a21\u5757\u90fd\u9700\u8981\n\u901a\u8fc7\u6a21\u578b\u7684 ``forward`` \u65b9\u6cd5\u8fd0\u884c\u6837\u4f8b\u8f93\u5165\uff0c\u5e76\u8ddf\u8e2a\u6570\u636e\u9047\u5230\u7684\u8ba1\u7b97\u56fe\u3002\u7f16\u7801\u5668\u6a21\u578b\u63a5\u53d7\u8f93\u5165\u5e8f\u5217\n\u548c\u5bf9\u5e94\u7684\u957f\u5ea6\u5f20\u91cf\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u6837\u4f8b\u8f93\u5165\u5e8f\u5217\u5f20\u91cf ``test_seq`` \uff0c\n\u5b83\u5177\u6709\u9002\u5f53\u7684\u5927\u5c0f(MAX_LENGTH, 1)\uff0c \u5305\u542b\u9002\u5f53\u8303\u56f4 $[0, voc.num\\_words)$ \u5185\u7684\u6570\u5b57\uff0c\n\u5e76\u4e14\u5177\u6709\u9002\u5f53\u7684\u7c7b\u578b(int64)\u3002\n\u6211\u4eec\u8fd8\u521b\u5efa\u4e86\u4e00\u4e2a ``test_seq_length`` \u6807\u91cf\uff0c\u8be5\u6807\u91cf\u5b9e\u9645\u4e0a\u5305\u542b\u4e86\u4e0e ``test_seq`` \u4e2d\u7684\u5355\u8bcd\u6570\u91cf\u76f8\u5bf9\u5e94\u7684\u503c\u3002\n\u4e0b\u4e00\u6b65\u662f\u4f7f\u7528 ``torch.jit.trace`` \u51fd\u6570\u6765\u8ddf\u8e2a\u6a21\u578b\u3002\u8bf7\u6ce8\u610f\uff0c\u6211\u4eec\u4f20\u9012\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u8981\u8ddf\u8e2a\u7684\u6a21\u5757(module)\uff0c\n\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u6a21\u5757\u7684 ``forward`` \u65b9\u6cd5\u7684\u53c2\u6570\u5143\u7ec4\u3002\n\n\u89e3\u7801\u5668(Decoder)\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n\u6211\u4eec\u5bf9\u89e3\u7801\u5668\u8fdb\u884c\u8ddf\u8e2a\u7684\u8fc7\u7a0b\u4e0e\u5bf9\u7f16\u7801\u5668\u7684\u8ddf\u8e2a\u8fc7\u7a0b\u76f8\u540c\u3002\n\u8bf7\u6ce8\u610f\uff0c\u9488\u5bf9\u4e00\u7ec4\u968f\u673a\u8f93\u5165\uff0c\u6211\u4eec\u8c03\u7528 traced_encoder \u7684 \n``forward`` \u65b9\u6cd5\uff0c\u4ee5\u83b7\u5f97\u89e3\u7801\u5668\u6240\u9700\u7684\u8f93\u51fa\u3002\n\u8fd9\u4e0d\u662f\u5fc5\u9700\u7684\uff0c\u56e0\u4e3a\u6211\u4eec\u4e5f\u53ef\u4ee5\u7b80\u5355\u5730\u5236\u9020\u4e00\u4e2a\u5f62\u72b6\u3001\u7c7b\u578b\u548c\u53d6\u503c\u8303\u56f4\u6b63\u786e\u7684\u5f20\u91cf\u3002\n\u8fd9\u79cd\u65b9\u6cd5\u662f\u53ef\u80fd\u7684\uff0c\u5728\u6211\u4eec\u5efa\u7acb\u7684\u6a21\u578b\u8303\u4f8b\u4e2d\uff0c\u5bf9\u5f20\u91cf\u7684\u503c\u6ca1\u6709\u4efb\u4f55\u9650\u5236\uff0c\n\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u4efb\u4f55\u53ef\u80fd\u5bf9\u8d85\u51fa\u8303\u56f4\u7684\u8f93\u5165\u4ea7\u751f\u6545\u969c\u7684\u64cd\u4f5c\u3002\n\n\u8d2a\u5a6a\u641c\u7d22\u89e3\u7801\u5668(GreedySearchDecoder)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\u56de\u60f3\u4e00\u4e0b\uff0c\u7531\u4e8e\u5b58\u5728\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u63a7\u5236\u6d41\uff0c\u6211\u4eec\u7f16\u5199\u4e86\u641c\u7d22\u6a21\u5757\u7684\u811a\u672c\u3002\n\u5728\u811a\u672c\u5316(scripting)\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u901a\u8fc7\u6dfb\u52a0\u88c5\u9970\u5668(decorator)\u5e76\u786e\u4fdd\u5b9e\u73b0\n\u7b26\u5408\u811a\u672c\u5316\u89c4\u5219\u6765\u9884\u5148\u5b8c\u6210\u8f6c\u6362\u5de5\u4f5c\u3002\n\u6211\u4eec\u521d\u59cb\u5316\u811a\u672c\u641c\u7d22\u7a0b\u5e8f\uff0c\u5c31\u50cf\u521d\u59cb\u5316\u4e00\u4e2a\u975e\u811a\u672c\u53d8\u91cf(un-scripted variant)\u4e00\u6837\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "### Convert encoder model\n# Create artificial inputs\ntest_seq = torch.LongTensor(MAX_LENGTH, 1).random_(0, voc.num_words)\ntest_seq_length = torch.LongTensor([test_seq.size()[0]])\n# Trace the model\ntraced_encoder = torch.jit.trace(encoder, (test_seq, test_seq_length))\n\n### Convert decoder model\n# Create and generate artificial inputs\ntest_encoder_outputs, test_encoder_hidden = traced_encoder(test_seq, test_seq_length)\ntest_decoder_hidden = test_encoder_hidden[:decoder.n_layers]\ntest_decoder_input = torch.LongTensor(1, 1).random_(0, voc.num_words)\n# Trace the model\ntraced_decoder = torch.jit.trace(decoder, (test_decoder_input, test_decoder_hidden, test_encoder_outputs))\n\n### Initialize searcher module\nscripted_searcher = GreedySearchDecoder(traced_encoder, traced_decoder, decoder.n_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8f93\u51fa\u8ba1\u7b97\u56fe\n------------\n\n\u73b0\u5728\u6211\u4eec\u7684\u6a21\u578b\u4ee5Torch Script\u5f62\u5f0f\u51fa\u73b0\uff0c\u6211\u4eec\u53ef\u4ee5\u6253\u5370\u6bcf\u4e2a\u6a21\u578b\u7684\u56fe\u8868\uff0c\n\u4ee5\u786e\u4fdd\u6211\u4eec\u9002\u5f53\u5730\u6355\u83b7\u4e86\u8ba1\u7b97\u56fe\u3002\u7531\u4e8e\u6211\u4eec\u7684 ``scripted_searcher`` \u5305\u542b\n\u6211\u4eec\u7684 ``traced_encoder`` \u548c ``traced_decoder`` \uff0c\u8fd9\u4e9b\u56fe\u8868\u5c06\u4f1a\u5185\u8054\u6253\u5370\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('scripted_searcher graph:\\n', scripted_searcher.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd0\u884c\u8bc4\u4f30\n--------------\n\n\u6700\u540e\uff0c\u6211\u4eec\u5c06\u4f7f\u7528Torch Script\u6a21\u578b\u5bf9Chatbot\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002\u5982\u679c\u8f6c\u6362\u6b63\u786e\uff0c\n\u5219\u6a21\u578b\u7684\u884c\u4e3a\u5c06\u4e0e\u5176\u6025\u5207\u6a21\u5f0f(eager-mode)\u8868\u793a\u4e2d\u7684\u884c\u4e3a\u5b8c\u5168\u76f8\u540c\u3002\n\n\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u8ba1\u7b97\u51e0\u4e2a\u5e38\u89c1\u7684\u67e5\u8be2\u8bed\u53e5\u3002\n\u5982\u679c\u4f60\u60f3\u81ea\u5df1\u548c\u673a\u5668\u4eba\u804a\u5929\uff0c\u53d6\u6d88\u6ce8\u91ca\u8ba1\u7b97\u8f93\u5165\u884c.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Evaluate examples\nsentences = [\"hello\", \"what's up?\", \"who are you?\", \"where am I?\", \"where are you from?\"]\nfor s in sentences:\n    evaluateExample(s, traced_encoder, traced_decoder, scripted_searcher, voc)\n\n# \u53d6\u6d88\u4e0b\u9762\u7684\u6ce8\u91ca\u6765\u8bc4\u4f30\u4f60\u7684\u8f93\u5165\n#evaluateInput(traced_encoder, traced_decoder, scripted_searcher, voc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4fdd\u5b58\u6a21\u578b\n----------\n\n\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u6210\u529f\u5730\u5c06\u6a21\u578b\u8f6c\u6362\u4e3aTorch Script\uff0c\u6211\u4eec\u5c06\u5e8f\u5217\u5316\u5b83\uff0c\u4ee5\u4fbf\u5728\u975ePython\u90e8\u7f72\u73af\u5883\u4e2d\u4f7f\u7528\u3002\n\u8981\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u4fdd\u5b58\u6211\u4eec\u7684 ``scripted_searcher`` \u6a21\u5757\uff0c\n\u56e0\u4e3a\u8fd9\u662f\u9488\u5bf9\u804a\u5929\u673a\u5668\u4eba(chatbot)\u6a21\u578b\u8fd0\u884c\u63a8\u7406\u7684\u9762\u5411\u7528\u6237\u7684\u754c\u9762\u3002\u5728\u4fdd\u5b58Script\u6a21\u5757\u65f6\uff0c\n\u4f7f\u7528 script_module.save(PATH) \u800c\u4e0d\u662f torch.save(model, PATH)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scripted_searcher.save(\"scripted_chatbot.pth\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}