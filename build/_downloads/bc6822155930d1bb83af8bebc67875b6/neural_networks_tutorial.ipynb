{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u795e\u7ecf\u7f51\u7edc\n===============\n**\u7ffb\u8bd1\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`_\n\n\u795e\u7ecf\u7f51\u7edc(Neural networks)\u53ef\u4ee5\u4f7f\u7528 ``torch.nn`` package \u6784\u5efa\u3002\n\n\u73b0\u5728\u4f60\u5df2\u7ecf\u4e86\u89e3\u4e86\u81ea\u52a8\u68af\u5ea6 ``autograd``, ``nn`` \u4f9d\u8d56\u4e8e \n``autograd`` \u6765\u5b9a\u4e49\u6a21\u578b\u5e76\u5bf9\u5b83\u4eec\u6c42\u5fae\u5206\u3002\n\u4e00\u4e2a ``nn.Module`` \u5305\u542b\u82e5\u5e72 layers, \u548c\u4e00\u4e2a\u65b9\u6cd5 ``forward(input)``,\n\u8be5\u65b9\u6cd5\u8fd4\u56de ``output`` \u3002\n\n\u4e3e\u4e2a\u6817\u5b50, \u8bf7\u770b\u4e0b\u9762\u8fd9\u4e2a\u7528\u6765\u5206\u7c7b\u624b\u5199\u6570\u5b57\u7684\u7f51\u7edc:\n\n.. figure:: /_static/img/mnist.png\n   :alt: convnet\n\n   convnet\n\n\u5b83\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u524d\u9988\u7f51\u7edc(feed-forward network)\u3002 \u5b83\u63a5\u53d7\u8f93\u5165(input)\uff0c\u5e76\u628a\u5b83\u4eec\u4e00\u4e2a\u5c42\u63a5\u7740\u4e00\u4e2a\u5c42\u7684\u5f80\u524d\u4f20\u9012\uff0c\n\u6700\u540e\u7ed9\u51fa \u8f93\u51fa(output)\u3002\n\n\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u7684\u5178\u578b\u8bad\u7ec3\u6b65\u9aa4\u5305\u62ec\u4e0b\u9762\u8fd9\u51e0\u6b65:\n\n- \u5b9a\u4e49\u5177\u6709\u53ef\u5b66\u4e60\u53c2\u6570(weights)\u7684\u795e\u7ecf\u7f51\u7edc\n- \u5728\u8f93\u5165\u7684\u4e00\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8fed\u4ee3\n- \u6cbf\u7740\u7f51\u7edc\u5904\u7406\u8f93\u5165\n- \u8ba1\u7b97\u635f\u5931 (\u5ea6\u91cf \u7f51\u7edc\u7684\u8f93\u51fa \u79bb \u6211\u4eec\u671f\u671b\u7684\u6b63\u786e\u8f93\u51fa \u8fd8\u6709\u591a\u8fdc)\n- \u628a\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u5230\u7f51\u7edc\u7684\u53c2\u6570\n- \u66f4\u65b0\u7f51\u7edc\u6743\u91cd, \u5178\u578b\u7684\u662f\u4f7f\u7528\u4e00\u4e2a\u7b80\u5355\u7684\u66f4\u65b0\u89c4\u5219:  ``weight = weight - learning_rate * gradient``\n\n\u5b9a\u4e49\u7f51\u7edc\n------------------\n\n\u8ba9\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc\u5427:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # \u8f93\u5165\u56fe\u50cf 1 \u4e2a\u901a\u9053, 6 \u4e2a\u8f93\u51fa\u901a\u9053, 5x5 \u65b9\u5f62\u5377\u79ef\u6838\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # \u4e00\u4e2a\u7ebf\u6027\u6620\u5c04: y = Wx + b\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # \u6700\u5927\u6c60\u5316\u7684 \u7a97\u53e3\u5927\u5c0f(2, 2)\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # \u5982\u679c\u6c60\u5316\u7a97\u53e3\u662f\u65b9\u5f62\u7684\uff0c\u4f60\u53ea\u9700\u8981\u6307\u5b9a\u5355\u4e2a\u6570\u5b57\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # \u9664\u4e86 batch \u7ef4 \u7684\u6240\u6709\u7eac\u5ea6\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\nnet = Net()\nprint(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4f60\u4ec5\u4ec5\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a ``forward`` \u51fd\u6570, \u5e76\u4e14 ``backward`` \u51fd\u6570\n(\u5728\u5176\u4e2d\u68af\u5ea6\u88ab\u8ba1\u7b97\u51fa\u6765) \u662f\u4f7f\u7528 ``autograd`` \u4e3a\u4f60\u81ea\u52a8\u5b9a\u4e49\u7684\u3002\n\u4f60\u53ef\u4ee5\u5728 ``forward`` \u51fd\u6570\u4e2d\u4f7f\u7528\u4efb\u610f\u7684 Tensor \u8fd0\u7b97/\u64cd\u4f5c\u3002\n\n\u6a21\u578b\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u901a\u8fc7 ``net.parameters()`` \u6765\u83b7\u53d6\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = list(net.parameters())\nprint(len(params))\nprint(params[0].size())  # conv1's .weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8ba9\u6211\u4eec\u5c1d\u8bd5\u4e00\u4e2a 32x32 \u7684\u968f\u673a\u8f93\u5165\n\u6ce8\u610f: \u8fd9\u4e2a\u7f51\u7edc(LeNet)\u671f\u671b\u7684\u8f93\u5165\u5c3a\u5bf8\u662f 32x32\u3002 \u4e3a\u4e86\u628a\u8fd9\u4e2a\u7f51\u7edc\u7528\u4e8e\nMNIST \u6570\u636e\u96c6, \u8bf7\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\u5c3a\u5bf8\u7f29\u653e\u5230 32x32.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input = torch.randn(1, 1, 32, 32)\nout = net(input)\nprint(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5c06\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u7f13\u5b58(gradient buffers)\u7f6e 0, \u5e76\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u53cd\u5411\u4f20\u64ad:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.zero_grad()\nout.backward(torch.randn(1, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.nn`` \u4ec5\u652f\u6301 mini-batches\u3002 \u6574\u4e2a ``torch.nn``\n    package \u4ec5\u652f\u6301\u4ee5\u6837\u672c\u7684 mini-batch \u4f5c\u4e3a\u8f93\u5165\uff0c\u800c\u4e0d\u652f\u6301\u5355\u4e2a\u6837\u672c\u4f5c\u4e3a\u8f93\u5165\u3002\n\n    \u4f8b\u5982, ``nn.Conv2d`` \u5c06\u63a5\u53d7\u4e00\u4e2ashape\u4e3a ``nSamples x nChannels x Height x Width`` \n    \u7684 4D Tensor \u4f5c\u4e3a\u8f93\u5165\u3002\n\n    \u5982\u679c\u4f60\u6709\u4e00\u4e2a\u5355\u6837\u672c, \u8bf7\u4f7f\u7528 ``input.unsqueeze(0)`` \u4e3a\u5176\u6dfb\u52a0\u4e00\u4e2a\u865a\u6784\u7684batch\u7eac\u5ea6\u3002</p></div>\n\n\u5728\u8fdb\u4e00\u6b65\u5904\u7406\u4e4b\u524d, \u8ba9\u6211\u4eec\u56de\u987e\u4e00\u4e0b\u76ee\u524d\u4e3a\u6b62\u4f60\u7528\u5230\u7684\u6240\u6709\u7c7b \u5427\u3002\n\n**\u603b\u7ed3:**\n  -  ``torch.Tensor`` - \u4e00\u4e2a *\u591a\u7ef4\u6570\u7ec4* , \u652f\u6301\u81ea\u52a8\u5fae\u5206(autograd)\n     \u64cd\u4f5c \u6bd4\u5982 ``backward()`` \u3002 \u5b83\u8fd8 *\u6301\u6709\u68af\u5ea6* w.r.t. the tensor\u3002\n  -  ``nn.Module`` - \u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u3002*\u5c01\u88c5\u53c2\u6570\u7684\u4fbf\u6377\u65b9\u5f0f* ,\u5e26\u6709\u4e00\u4e9b\u5e2e\u52a9\u51fd\u6570\u7528\u4e8e\u5c06\u6a21\u578b\u8fc1\u79fb\u5230GPU\u4e0a, \u6a21\u578b\u7684\u5bfc\u51fa\u52a0\u8f7d,\u7b49\u7b49\u3002\n  -  ``nn.Parameter`` - \u4e00\u79cdTensor,\u662f\u88ab\u4f5c\u4e3a\u53c2\u6570\u81ea\u52a8\u6ce8\u518c\u7684,\u5f53\u628a\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u5c5e\u6027(attribute)\u5206\u914d\u7ed9\u4e00\u4e2a ``Module`` \u7684\u65f6\u5019\u3002\n  -  ``autograd.Function`` - \u5b9e\u73b0\u4e86 *\u4e00\u4e2a\u81ea\u52a8\u5fae\u5206\u8fd0\u7b97(autograd operation) \u7684 \u524d\u5411\u548c\u53cd\u5411\u5b9a\u4e49(forward and backward definitions)*\u3002 \n     \u6bcf\u4e00\u4e2a ``Tensor`` \u8fd0\u7b97/\u64cd\u4f5c, \u521b\u5efa\u81f3\u5c11\u4e00\u4e2a\u5355\u4e2a\u7684 ``Function`` \u8282\u70b9\uff0c\u8be5\u8282\u70b9\u8fde\u63a5\u7740\u90a3\u4e9b\u521b\u5efa\u4e86\u4e00\u4e2a ``Tensor`` \u7684\u51fd\u6570\u4ee5\u53ca*\u7f16\u7801\u5b83\u7684\u5386\u53f2*\u7684\u51fd\u6570\u3002\n\n**\u5f53\u76ee\u524d\u4e3a\u6b62, \u6211\u4eec\u5b66\u4e60\u4e86:**\n  -  \u5b9a\u4e49\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\n  -  \u5904\u7406\u8f93\u5165\uff0c\u8c03\u7528 backward \u3002\n\n**\u5269\u4f59\u7684\u6b65\u9aa4:**\n  -  \u8ba1\u7b97\u635f\u5931\n  -  \u66f4\u65b0\u7f51\u7edc\u6743\u91cd\n\n\u635f\u5931\u51fd\u6570\n-------------\n\u4e00\u4e2a\u635f\u5931\u51fd\u6570\u63a5\u53d7 (output, target) \u4f5c\u4e3a\u8f93\u5165\uff0c\u7136\u540e\u8ba1\u7b97\u4e00\u4e2a\u4f30\u8ba1\u7f51\u7edc\u8f93\u51fa\u79bb\u6211\u4eec\u7684\u671f\u671b\u8f93\u51fa\u8fd8\u6709\u591a\u8fdc\u7684\u8bc4\u4f30\u503c\u3002\n\n\u5728 nn package \u91cc\u9762\u6709\u5404\u79cd\u4e0d\u540c\u5f62\u5f0f\u7684\u635f\u5931\u51fd\u6570(`loss functions <https://pytorch.org/docs/nn.html#loss-functions>`_) \u3002\n\u4e00\u4e2a\u7b80\u5355\u7684\u635f\u5931\u51fd\u6570\u662f: ``nn.MSELoss`` \uff0c\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u7684\u8f93\u5165\u4e0e\u76ee\u6807\u503c\u4e4b\u95f4\u7684\u5e73\u5747\u5e73\u65b9\u8bef\u5dee(mean-squared error)\u3002\n\n\u4e3e\u4e2a\u6817\u5b50:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output = net(input)\ntarget = torch.randn(10)  # \u4e00\u4e2a\u865a\u62df\u7684\u76ee\u6807\u503c, \u4e3a\u4e86\u4e3e\u4f8b\u5b50\uff0c\u4e0d\u8981\u592a\u5728\u610f\ntarget = target.view(1, -1)  # \u4f7f\u5176\u5177\u6709\u4e0e\u8f93\u51fa\u76f8\u540c\u7684shape\ncriterion = nn.MSELoss()\n\nloss = criterion(output, target)\nprint(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728\uff0c\u5982\u679c\u4f60\u4f7f\u7528 ``loss`` \u7684 ``.grad_fn`` \u5c5e\u6027\u5411\u540e\u8ddf\u8e2a ``loss`` \uff0c\u5c06\u770b\u5230\u5982\u4e0b\u6240\u793a\u7684\u8ba1\u7b97\u56fe:\n\n::\n\n    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n          -> view -> linear -> relu -> linear -> relu -> linear\n          -> MSELoss\n          -> loss\n\n\u56e0\u6b64, \u5f53\u6211\u4eec\u8c03\u7528 ``loss.backward()`` \u65f6, \u6574\u4e2a\u7684\u8ba1\u7b97\u56fe\u88ab\u6c42\u4e86\u76f8\u5bf9\u4e8eloss\u7684\u5fae\u5206(the whole graph is differentiated\nw.r.t. the loss), \u5e76\u4e14\u8ba1\u7b97\u56fe\u4e2d\u6240\u6709\u7684 Tensors \u53ea\u8981\u5176\u6ee1\u8db3 ``requires_grad=True`` \u5c31\u4f1a\u6709\u5b83\u4eec\u81ea\u5df1\u7684\u7528\u68af\u5ea6\u7d2f\u79ef\u8d77\u6765\u7684 ``.grad`` Tensor\u3002\n\n\u4e3a\u4e86\u8bf4\u660e, \u8ba9\u6211\u4eec\u5411\u540e\u8ddf\u8e2a\u51e0\u6b65\u5427:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(loss.grad_fn)  # MSELoss\nprint(loss.grad_fn.next_functions[0][0])  # Linear\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u53cd\u5411\u4f20\u64ad\n--------\n\u4e3a\u4e86\u53cd\u5411\u4f20\u64ad\u8bef\u5dee\uff0c\u6211\u4eec\u8981\u505a\u7684\u6240\u6709\u7684\u4e8b\u5c31\u662f\u53bb\u8c03\u7528 ``loss.backward()`` \u3002\n\u4f46\u662f\u5728\u6b64\u4e4b\u524d\uff0c\u4f60\u5fc5\u987b\u5148\u5c06\u5df2\u7ecf\u5b58\u5728\u7684\u68af\u5ea6\u6e05\u9664\uff0c\u5426\u5219\u68af\u5ea6\u4f1a\u88ab\u7d2f\u52a0\u5230\u4e0a\u4e00\u6279\u6b21\u8fed\u4ee3\u65f6\u4ea7\u751f\u7684\u65e7\u7684\u68af\u5ea6\u4e0a\u3002\n\n\n\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u8c03\u7528 ``loss.backward()``, \u7136\u540e\u6211\u4eec\u770b\u770b \nconv1 \u7684 bias gradients \u5728backward\u4e4b\u524d\u548c\u4e4b\u540e\u7684\u53d8\u5316\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.zero_grad()     # \u5c06\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u7f13\u5b58(gradient buffers)\u7f6e\u96f6\n\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\nloss.backward()\n\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\u5982\u4f55\u4f7f\u7528\u635f\u5931\u51fd\u6570\u5566.\n\n**\u63a5\u7740\u9605\u8bfb:**\n\n  \u795e\u7ecf\u7f51\u7edc\u5305(nn package)\u5305\u542b\u5404\u79cd\u6a21\u5757\u548c\u635f\u5931\u51fd\u6570\uff0c\n  \u6784\u6210\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa\u5757\uff0c\u6709\u6587\u6863\u7684\u5b8c\u6574\u5217\u8868\u5728(`\u8fd9\u91cc <https://pytorch.org/docs/nn>`_)\u3002\n\n**\u5269\u4e0b\u8981\u5b66\u4e60\u7684\u552f\u4e00\u7684\u4e8b\u60c5\u5c31\u662f:**\n\n  - \u66f4\u65b0\u7f51\u7edc\u6743\u91cd\n\n\u66f4\u65b0\u6743\u91cd\n------------------\n\u5b9e\u8df5\u4e2d\u4f7f\u7528\u7684\u6700\u7b80\u5355\u7684\u66f4\u65b0\u89c4\u5219\u662f\u968f\u673a\u68af\u5ea6\u4e0b\u964d(Stochastic Gradient Descent, SGD):\n\n     ``weight = weight - learning_rate * gradient``\n\n\u6211\u4eec\u53ef\u4ee5\u7528\u7b80\u5355\u7684Python\u4ee3\u7801\u6765\u5b9e\u73b0\u8fd9\u4e2a\u4f18\u5316\u8fc7\u7a0b:\n\n.. code:: python\n\n    learning_rate = 0.01\n    for f in net.parameters():\n        f.data.sub_(f.grad.data * learning_rate)\n\n\u7136\u800c\uff0c\u5728\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u60a8\u9700\u8981\u4f7f\u7528\u5404\u79cd\u4e0d\u540c\u7684\u66f4\u65b0\u89c4\u5219\uff0c\u5982SGD\u3001Nesterov-SGD\u3001ADAM\u3001RMSProp\u7b49\u3002\n\u4e3a\u6b64\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u5c0f\u5305: ``torch.optim`` \uff0c\u5b83\u5b9e\u73b0\u4e86\u6240\u6709\u8fd9\u4e9b\u65b9\u6cd5\u3002\u4f7f\u7528\u5b83\u975e\u5e38\u7b80\u5355\uff1a\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n\n# \u521b\u5efa\u4f60\u7684\u4f18\u5316\u5668\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\n# \u5728\u4f60\u7684\u6bcf\u4e00\u6b21\u8bad\u7ec3\u56de\u73af(training loop)\u4e2d:\noptimizer.zero_grad()   # \u5c06\u68af\u5ea6\u7f13\u5b58\u7f6e\u96f6\noutput = net(input)\nloss = criterion(output, target)\nloss.backward()\noptimizer.step()    # \u6267\u884c\u66f4\u65b0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. Note::\n\n      \u89c2\u5bdf\u5982\u4f55\u4f7f\u7528 ``optimizer.zero_grad()`` \u624b\u52a8\u5c06\u68af\u5ea6\u7f13\u5b58\u8bbe\u7f6e\u4e3a\u96f6\u3002\n      \u8fd9\u662f\u56e0\u4e3a\u68af\u5ea6\u662f\u6309\u53cd\u5411\u4f20\u64ad\u5c0f\u8282\u4e2d\u89e3\u91ca\u7684\u90a3\u6837\u7d2f\u79ef\u7684\u3002\n\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}