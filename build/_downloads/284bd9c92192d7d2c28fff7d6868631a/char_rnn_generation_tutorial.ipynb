{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u4f7f\u7528\u5b57\u7b26\u7ea7RNN\u751f\u6210\u540d\u5b57\n*******************************************\n**\u7ffb\u8bd1\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`_\n\n\u5728 :doc:`\u4e0a\u4e00\u7bc7\u6559\u7a0b </intermediate/char_rnn_classification_tutorial>` \u4e2d\uff0c\u6211\u4eec\u4f7f\u7528RNN\u5c06\u540d\u5b57(names)\u5206\u7c7b\u4e3a\u5b83\u4eec\u6240\u5c5e\u7684\u8bed\u8a00(language)\u3002\n\u8fd9\u4e00\u6b21\uff0c\u6211\u4eec\u5c06\u8f6c\u8fc7\u6765\uff0c\u4ece\u8bed\u8a00(languages)\u4e2d\u751f\u6210\u540d\u5b57(names)\u3002\n\n::\n\n    > python sample.py Russian RUS\n    Rovakov\n    Uantov\n    Shavakov\n\n    > python sample.py German GER\n    Gerren\n    Ereng\n    Rosher\n\n    > python sample.py Spanish SPA\n    Salla\n    Parer\n    Allan\n\n    > python sample.py Chinese CHI\n    Chan\n    Hang\n    Iun\n\n\u6211\u4eec\u4ecd\u7136\u624b\u5de5\u5236\u4f5c\u4e00\u4e2a\u5e26\u6709\u51e0\u4e2a\u7ebf\u6027\u5c42\u7684\u5c0fRNN\u3002\u6700\u5927\u7684\u533a\u522b\u662f\uff0c\u5728\u8bfb\u5b8c\u4e00\u4e2a\u540d\u5b57\u7684\u6240\u6709\u5b57\u6bcd(letter)\u4e4b\u540e\uff0c\n\u6211\u4eec\u4e0d\u518d\u9884\u6d4b\u4e00\u4e2a\u7c7b\u522b\uff0c\u800c\u662f\u8f93\u5165\u4e00\u4e2a\u7c7b\u522b(category)\uff0c\u7136\u540e\u4e00\u6b21\u8f93\u51fa\u4e00\u4e2a\u5b57\u6bcd\u3002\n\u9012\u5f52\u5730(Recurrently)\u9884\u6d4b\u5b57\u7b26\u4ee5\u5f62\u6210\u8bed\u8a00(\u8fd9\u4e5f\u53ef\u4ee5\u7528\u5355\u8bcd\u6216\u5176\u4ed6\u9ad8\u9636\u7ed3\u6784\u6765\u5b8c\u6210)\u901a\u5e38\u88ab\u79f0\u4e3a\u201c\u8bed\u8a00\u6a21\u578b(language model)\u201d\u3002\n\n**\u63a8\u8350\u9605\u8bfb:**\n\n\u6211\u5047\u5b9a\u4f60\u6700\u8fd1\u624d\u5b89\u88c5\u4e86 PyTorch, \u77e5\u9053 Python, \u5e76\u4e14\u7406\u89e3 \u5f20\u91cf(Tensors)\u662f\u4ec0\u4e48\u4e1c\u897f:\n\n-  https://pytorch.org/ \u67e5\u770b\u5b89\u88c5\u6307\u5357\n-  :doc:`/beginner/deep_learning_60min_blitz` \u5728\u8fd9\u4e2a\u7ae0\u8282\u83b7\u5f97PyTorch\u7684\u8d77\u6b65\u77e5\u8bc6\n-  :doc:`/beginner/pytorch_with_examples` \u83b7\u5f97\u4e00\u4e2a\u5bbd\u6cdb\u800c\u6709\u6df1\u5ea6\u7684\u6982\u89c8\n-  :doc:`/beginner/former_torchies_tutorial` \u5982\u679c\u60a8\u662f\u524dLua Torch\u7528\u6237\n\n\u5982\u679c\u4e86\u89e3 RNNs \u5e76\u77e5\u9053\u5b83\u4eec\u7684\u5de5\u4f5c\u539f\u7406\u5c06\u4f1a\u5f88\u6709\u7528:\n\n-  `\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u5408\u7406\u6709\u6548\u6027 <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__ \u5c55\u793a\u4e86\u597d\u591a\u7684\u771f\u5b9e\u751f\u6d3b\u6848\u4f8b\u3002\n-  `\u7406\u89e3 LSTM \u7f51\u7edc <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__ \u8fd9\u7bc7\u6587\u7ae0\u662f\u4e13\u95e8\u5173\u4e8eLSTMs\u7684\uff0c\u4e5f\u6709\u5173\u4e8eRNNs\u7684\u901a\u7528\u7684\u4fe1\u606f\u3002\n\n\u6211\u8fd8\u63a8\u8350\u5927\u5bb6\u9605\u8bfb\u4e0a\u4e00\u7bc7\u6559\u7a0b\uff1a :doc:`/intermediate/char_rnn_classification_tutorial`\n\n\n\u51c6\u5907\u6570\u636e\n==================\n\n.. Note::\n   \u4ece `\u8fd9\u513f <https://download.pytorch.org/tutorial/data.zip>`_\n   \u4e0b\u8f7d\u6570\u636e\u5e76\u62bd\u53d6\u5230\u5f53\u524d\u76ee\u5f55\u3002\n\n\u5173\u4e8e\u8fd9\u4e2a\u5904\u7406\u8fc7\u7a0b\u7684\u66f4\u591a\u4fe1\u606f\u8bf7\u53c2\u8003\u4e0a\u4e00\u7bc7\u6559\u7a0b\u3002\u7b80\u5355\u70b9\u8bf4, \u6211\u4eec\u6709\u4e00\u5806\u666e\u901a\u6587\u672c\u6587\u4ef6 ``data/names/[Language].txt`` \uff0c\u6587\u4ef6\u4e2d\u6bcf\u4e00\u884c\u662f\u4e00\u4e2a\u540d\u5b57(name)\u3002\n\u6211\u4eec\u5c06\u5f88\u591a\u884c(lines)\u5212\u5206\u6210\u4e00\u4e2a\u6570\u7ec4\uff0c\u518d\u4ece Unicode \u8f6c\u6362\u4e3a ASCII, \u6700\u540e\u6784\u9020\u4e86\u4e00\u4e2a\u5b57\u5178\uff1a  ``{language: [names ...]}`` \u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport glob\nimport os\nimport unicodedata\nimport string\n\nall_letters = string.ascii_letters + \" .,;'-\"\nn_letters = len(all_letters) + 1 # Plus EOS marker\n\ndef findFiles(path): return glob.glob(path)\n\n# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in all_letters\n    )\n\n# Read a file and split into lines\ndef readLines(filename):\n    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n    return [unicodeToAscii(line) for line in lines]\n\n# Build the category_lines dictionary, a list of lines per category\ncategory_lines = {}\nall_categories = []\nfor filename in findFiles('./data/names/*.txt'):\n    category = os.path.splitext(os.path.basename(filename))[0]\n    all_categories.append(category)\n    lines = readLines(filename)\n    category_lines[category] = lines\n\nn_categories = len(all_categories)\n\nif n_categories == 0:\n    raise RuntimeError('Data not found. Make sure that you downloaded data '\n        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n        'the current directory.')\n\nprint('# categories:', n_categories, all_categories)\nprint(unicodeToAscii(\"O'N\u00e9\u00e0l\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u521b\u5efa\u7f51\u7edc\n====================\n\n\u8be5\u7f51\u7edc\u6269\u5c55\u4e86 :doc:`\u4e0a\u4e00\u7bc7\u6559\u7a0b\u7684RNN\u7f51\u7edc </intermediate/char_rnn_classification_tutorial>` \uff0c\u5e76\u4e3a\u7c7b\u522b\u5f20\u91cf\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u53c2\u6570\uff0c\n\u4e0e\u5176\u4ed6\u7c7b\u5f20\u91cf\u8fde\u63a5(concatenate)\u5728\u4e00\u8d77\u3002\u7c7b\u522b\u5f20\u91cf(category tensor)\u662f\u4e00\u4e2a\u540c\u5b57\u6bcd\u8f93\u5165(letter input)\u4e00\u6837\u7684one-hot\u5411\u91cf.\n\n\u6211\u4eec\u5c06\u628a\u8f93\u51fa\u89e3\u91ca\u4e3a\u4e0b\u4e00\u4e2a\u5b57\u6bcd\u7684\u6982\u7387\u3002\u91c7\u6837\u65f6\uff0c\u6700\u6709\u53ef\u80fd\u7684\u8f93\u51fa\u5b57\u6bcd\u88ab\u7528\u4f5c\u4e0b\u4e00\u4e2a\u8f93\u5165\u5b57\u6bcd\u3002\n\n\u6211\u6dfb\u52a0\u4e86\u7b2c\u4e8c\u4e2a\u7ebf\u6027\u5c42  ``o2o`` (\u5728\u5408\u5e76\u4e86\u9690\u85cf\u548c\u8f93\u51fa\u4e4b\u540e)\u6765\u7ed9\u5b83\u63d0\u4f9b\u66f4\u591a\u7684\u5de5\u4f5c\u7a7a\u95f4\u3002\n\u8fd8\u6709\u4e00\u4e2adropout\u5c42\uff0c\u5b83\u968f\u673a\u5730\u7528\u7ed9\u5b9a\u7684\u6982\u7387(\u8fd9\u91cc\u662f0.1)\u5bf9\u5176\u8f93\u5165\u7684\u90e8\u5206\u8fdb\u884c\u7f6e\u96f6\uff0c\n\u5e76\u4e14\u901a\u5e38\u7528\u4e8e\u6a21\u7cca\u8f93\u5165\u4ee5\u9632\u6b62\u8fc7\u5ea6\u62df\u5408\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5728\u63a5\u8fd1\u7f51\u7edc\u7684\u672b\u5c3e\u4f7f\u7528\u5b83\uff0c\n\u76ee\u7684\u662f\u589e\u52a0\u4e00\u4e9b\u6df7\u4e71\u548c\u589e\u52a0\u91c7\u6837\u591a\u6837\u6027\u3002\n\n.. figure:: https://i.imgur.com/jzVrf7f.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n        self.dropout = nn.Dropout(0.1)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, category, input, hidden):\n        input_combined = torch.cat((category, input, hidden), 1)\n        hidden = self.i2h(input_combined)\n        output = self.i2o(input_combined)\n        output_combined = torch.cat((hidden, output), 1)\n        output = self.o2o(output_combined)\n        output = self.dropout(output)\n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\n=========\n\u4e3a\u8bad\u7ec3\u505a\u51c6\u5907\n----------------------\n\n\u5728\u63a5\u53d7\u8bad\u7ec3\u4e4b\u524d\uff0c\u6211\u4eec\u5e94\u8be5\u505a\u4e00\u4e9b\u8f85\u52a9\u51fd\u6570\u83b7\u5f97 (category, line) \u7684\u968f\u673a\u5bf9(random pairs):\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\n# Random item from a list\ndef randomChoice(l):\n    return l[random.randint(0, len(l) - 1)]\n\n# Get a random category and random line from that category\ndef randomTrainingPair():\n    category = randomChoice(all_categories)\n    line = randomChoice(category_lines[category])\n    return category, line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5bf9\u4e8e\u6bcf\u4e2a\u65f6\u95f4\u6b65(\u5373\uff0c\u5bf9\u4e8e\u8bad\u7ec3\u5355\u8bcd\u4e2d\u7684\u6bcf\u4e2a\u5b57\u6bcd)\uff0c\u7f51\u7edc\u7684\u8f93\u5165\u5c06\u662f ``(category, current letter, hidden state)`` \uff0c\n\u8f93\u51fa\u5c06\u662f ``(next letter, next hidden state)`` \u3002\n\u56e0\u6b64\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u8bad\u7ec3\u96c6\uff0c\u6211\u4eec\u9700\u8981category, a set of input letters, \u548c a set of output/target letters\u3002\n\n\u7531\u4e8e\u6211\u4eec\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u4ece\u5f53\u524d\u5b57\u6bcd\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5b57\u6bcd\uff0c\u6240\u4ee5\u5b57\u6bcd\u5bf9\u662f\u884c\u4e2d\u7684\u8fde\u7eed\u5b57\u6bcd\u7ec4\uff0c\u4f8b\u5982\uff0c\u5bf9\u4e8e ``\"ABCD<EOS>\"`` \uff0c\u6211\u4eec\u5c06\u521b\u5efa\n(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"D\"), (\"D\", \"EOS\").\n\n.. figure:: https://i.imgur.com/JH58tXY.png\n   :alt:\n\n\u7c7b\u522b\u5f20\u91cf(category tensor)\u662f\u4e00\u4e2a `one-hot tensor <https://en.wikipedia.org/wiki/One-hot>`__, \n\u5176 size \u662f ``<1 x n_categories>`` \u3002\u5f53\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u628a\u5b83\u4f20\u5230\u7f51\u7edc\u4e2d---\u8fd9\u662f\u4e00\u79cd\u8bbe\u8ba1\u4e0a\u7684\u9009\u62e9\uff0c\u5b83\u53ef\u4ee5\u4f5c\u4e3a\n\u521d\u59cb\u72b6\u6001\u6216\u5176\u4ed6\u67d0\u4e2a\u7b56\u7565\u7684\u4e00\u90e8\u5206\u88ab\u5305\u62ec\u8fdb\u6765\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# One-hot vector for category\ndef categoryTensor(category):\n    li = all_categories.index(category)\n    tensor = torch.zeros(1, n_categories)\n    tensor[0][li] = 1\n    return tensor\n\n# One-hot matrix of first to last letters (not including EOS) for input\ndef inputTensor(line):\n    tensor = torch.zeros(len(line), 1, n_letters)\n    for li in range(len(line)):\n        letter = line[li]\n        tensor[li][0][all_letters.find(letter)] = 1\n    return tensor\n\n# LongTensor of second letter to end (EOS) for target\ndef targetTensor(line):\n    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n    letter_indexes.append(n_letters - 1) # EOS\n    return torch.LongTensor(letter_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e3a\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u7684\u65b9\u4fbf\uff0c\u6211\u4eec\u5c06\u505a\u4e00\u4e2a ``randomTrainingExample`` \u51fd\u6570\uff0c\u83b7\u53d6\u4e00\u4e2a\u968f\u673a(category, line)\u5bf9\uff0c\n\u5e76\u5c06\u5b83\u4eec\u8f6c\u5316\u4e3a\u6240\u9700\u7684(category, input, target)\u5f20\u91cf\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Make category, input, and target tensors from a random category, line pair\ndef randomTrainingExample():\n    category, line = randomTrainingPair()\n    category_tensor = categoryTensor(category)\n    input_line_tensor = inputTensor(line)\n    target_line_tensor = targetTensor(line)\n    return category_tensor, input_line_tensor, target_line_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u7f51\u7edc\n--------------------\n\n\u4e0e\u53ea\u4f7f\u7528\u6700\u540e\u4e00\u4e2a\u8f93\u51fa(\u505a\u9884\u6d4b\u4ee5\u53ca\u8ba1\u7b97\u635f\u5931)\u7684\u5206\u7c7b\u7f51\u7edc\u76f8\u6bd4\uff0c\u6211\u4eec\u5728\u6bcf\u4e00\u6b65\u90fd\u8981\u8fdb\u884c\u9884\u6d4b\uff0c\n\u6240\u4ee5\u6211\u4eec\u5728\u6bcf\u4e00\u6b65\u90fd\u8ba1\u7b97\u635f\u5931\u3002\n\n\u81ea\u52a8\u68af\u5ea6\u7684\u9b54\u529b\u8ba9\u4f60\u5728\u6bcf\u4e00\u6b65\u90fd\u80fd\u7b80\u5355\u5730\u5c06\u8fd9\u4e9b\u635f\u5931\u76f8\u52a0\uff0c\u5e76\u5728\u7ed3\u675f\u65f6\u8c03\u7528\u53cd\u5411\u4f20\u64ad\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n\nlearning_rate = 0.0005\n\ndef train(category_tensor, input_line_tensor, target_line_tensor):\n    target_line_tensor.unsqueeze_(-1)\n    hidden = rnn.initHidden()\n\n    rnn.zero_grad()\n\n    loss = 0\n\n    for i in range(input_line_tensor.size(0)):\n        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n        l = criterion(output, target_line_tensor[i])\n        loss += l\n\n    loss.backward()\n\n    for p in rnn.parameters():\n        p.data.add_(-learning_rate, p.grad.data)\n\n    return output, loss.item() / input_line_tensor.size(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e3a\u4e86\u8ddf\u8e2a\u8bad\u7ec3\u6240\u9700\u7684\u65f6\u95f4\uff0c\u6211\u6dfb\u52a0\u4e86\u4e00\u4e2a ``timeSince(timestamp)`` \u51fd\u6570\uff0c\u5b83\u8fd4\u56de\u4e00\u4e2a\u4eba\u7c7b\u53ef\u8bfb\u7684\u5b57\u7b26\u4e32:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u5c31\u50cf\u5f80\u5e38\u4e00\u6837---\u591a\u6b21\u8c03\u7528 ``train``` \uff0c\u7b49\u5f85\u51e0\u5206\u949f\uff0c\u6bcf\u9694 ``print_every`` \n\u4e2a\u6837\u4f8b\u5c31\u6253\u5370\u5f53\u524d\u65f6\u95f4\uff0c\u635f\u5931\uff0c\n\u5e76\u628a ``print_every`` \u4e2a\u6837\u4f8b\u4e0a\u7684\u5e73\u5747\u635f\u5931 \u4fdd\u5b58\u5230 ``all_losses`` \uff0c\u4f9b\u4ee5\u540e\u7ed8\u56fe\u4f7f\u7528\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rnn = RNN(n_letters, 128, n_letters)\n\nn_iters = 100000\nprint_every = 5000\nplot_every = 500\nall_losses = []\ntotal_loss = 0 # Reset every plot_every iters\n\nstart = time.time()\n\nfor iter in range(1, n_iters + 1):\n    output, loss = train(*randomTrainingExample())\n    total_loss += loss\n\n    if iter % print_every == 0:\n        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n\n    if iter % plot_every == 0:\n        all_losses.append(total_loss / plot_every)\n        total_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u753b\u635f\u5931\u66f2\u7ebf\u56fe\n-------------------\n\n\u4ece ``all_losses`` \u4e2d\u7ed8\u5236\u5386\u53f2\u635f\u5931\u5c55\u793a\u7f51\u7edc\u5b66\u4e60\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nplt.figure()\nplt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5bf9\u7f51\u7edc\u91c7\u6837\n====================\n\n\u4e3a\u4e86\u8fdb\u884c\u91c7\u6837\uff0c\u6211\u4eec\u7ed9\u7f51\u7edc\u4e00\u4e2a\u5b57\u6bcd\u5e76\u8be2\u95ee\u4e0b\u4e00\u4e2a\u5b57\u6bcd\u662f\u4ec0\u4e48\uff0c\u518d\u5c06\u5176\u7b54\u6848\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u5b57\u6bcd\u8f93\u5165\uff0c\u5e76\u91cd\u590d\u76f4\u5230EOS token\u3002\n\n-  \u4e3a \u8f93\u5165\u7c7b\u522b\uff0c\u8d77\u59cb\u5b57\u6bcd\uff0c\u548c \u7a7a\u9690\u85cf\u72b6\u6001 \u521b\u5efa\u5f20\u91cf\n-  \u4f7f\u7528\u8d77\u59cb\u5b57\u6bcd\u521b\u5efa\u4e00\u4e2a\u5b57\u7b26\u4e32 ``output_name`` \n-  \u76f4\u5230\u8fbe\u5230 \u6700\u5927\u8f93\u51fa\u957f\u5ea6,\n\n   -  \u5c06\u5f53\u524d\u5b57\u6bcd\u5582\u7ed9\u7f51\u7edc\n   -  \u4ece\u6700\u9ad8\u8f93\u51fa\u4e2d\u83b7\u53d6\u4e0b\u4e00\u4e2a\u5b57\u6bcd\uff0c\u5e76\u83b7\u5f97\u4e0b\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\n   -  \u5982\u679c\u5b57\u6bcd\u662fEOS\uff0c\u5c31\u505c\u5728\u8fd9\u91cc\n   -  \u5982\u679c\u662f\u4e00\u4e2a\u5e38\u89c4\u7684\u5b57\u6bcd, \u628a\u5b83\u6dfb\u52a0\u5230 ``output_name`` \u7136\u540e\u7ee7\u7eed\n\n-  \u8fd4\u56de\u6700\u7ec8\u7684name\n\n.. Note::\n   \u53e6\u4e00\u79cd\u7b56\u7565\u4e0d\u662f\u7ed9\u5b83\u4e00\u4e2a\u8d77\u59cb\u5b57\u6bcd\uff0c\u800c\u662f\u5728\u8bad\u7ec3\u4e2d\u5305\u542b\u4e00\u4e2a \u201cstart of string\u201d token\uff0c\u8ba9\u7f51\u7edc\u9009\u62e9\u81ea\u5df1\u7684\u8d77\u59cb\u5b57\u6bcd\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_length = 20\n\n# Sample from a category and starting letter\ndef sample(category, start_letter='A'):\n    with torch.no_grad():  # no need to track history in sampling\n        category_tensor = categoryTensor(category)\n        input = inputTensor(start_letter)\n        hidden = rnn.initHidden()\n\n        output_name = start_letter\n\n        for i in range(max_length):\n            output, hidden = rnn(category_tensor, input[0], hidden)\n            topv, topi = output.topk(1)\n            topi = topi[0][0]\n            if topi == n_letters - 1:\n                break\n            else:\n                letter = all_letters[topi]\n                output_name += letter\n            input = inputTensor(letter)\n\n        return output_name\n\n# Get multiple samples from one category and multiple starting letters\ndef samples(category, start_letters='ABC'):\n    for start_letter in start_letters:\n        print(sample(category, start_letter))\n\nsamples('Russian', 'RUS')\n\nsamples('German', 'GER')\n\nsamples('Spanish', 'SPA')\n\nsamples('Chinese', 'CHI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ec3\u4e60\n=========\n\n-  \u5c1d\u8bd5\u5177\u6709 category -> line \u8fd9\u79cd\u7ed3\u6784\u7684\u5176\u4ed6\u6570\u636e\u96c6, \u4f8b\u5982 :\n\n   -  \u7cfb\u5217\u5c0f\u8bf4 -> \u4eba\u7269\u540d\u5b57\n   -  \u8bed\u4e49(Part of speech) -> \u5355\u8bcd(Word)\n   -  \u56fd\u5bb6 -> \u57ce\u5e02\n\n-  \u4f7f\u7528\u4e00\u4e2a \"start of sentence\" token \u4ee5\u4fbf\u5bf9\u7f51\u7edc\u7684\u91c7\u6837\u53ef\u4ee5\u5728\u4e0d\u7528\u9009\u62e9\u8d77\u59cb\u5b57\u7b26\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\n-  \u7528\u4e00\u4e2a\u66f4\u5927\u548c/\u6216\u66f4\u597d\u7684\u7f51\u7edc\u83b7\u5f97\u66f4\u597d\u7684\u6548\u679c\n\n   -  \u5c1d\u8bd5\u4f7f\u7528 nn.LSTM \u5c42 \u548c nn.GRU \u5c42\n   -  \u5c06\u8fd9\u4e9bRNNs\u4e2d\u7684\u591a\u4e2a\u5408\u5e76\u4e3a\u66f4\u9ad8\u7ea7\u7684\u7f51\u7edc\u3002\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}