{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u5e8f\u5217\u6a21\u578b\u548c\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc(LSTM)\n===================================================\n\n\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u4eec\u5df2\u7ecf\u770b\u5230\u4e86\u5404\u79cd\u5404\u6837\u7684\u524d\u9988\u7f51\u7edc(feed-forward networks)\u3002\n\u4e5f\u5c31\u662f\u8bf4\uff0c\u6839\u672c\u4e0d\u5b58\u5728\u7531\u7f51\u7edc\u7ef4\u62a4\u7684\u72b6\u6001(state)\u3002\n\u8fd9\u53ef\u80fd\u4e0d\u662f\u6211\u4eec\u60f3\u8981\u7684\u884c\u4e3a\u3002\u5e8f\u5217\u6a21\u578b(Sequence models)\u662fNLP\u7684\u6838\u5fc3\uff1a\n\u5b83\u4eec\u662f\u5728\u8f93\u5165\u4e4b\u95f4\u901a\u8fc7\u65f6\u95f4\u5b58\u5728\u67d0\u79cd\u4f9d\u8d56\u5173\u7cfb\u7684\u6a21\u578b\u3002\n\u5e8f\u5217\u6a21\u578b\u7684\u7ecf\u5178\u4f8b\u5b50\u662f\u7528\u4e8e\u8bcd\u6027\u6807\u6ce8(part-of-speech tagging)\u7684\n\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b(Hidden Markov Model)\u3002\n\u53e6\u4e00\u4e2a\u4f8b\u5b50\u662f\u6761\u4ef6\u968f\u673a\u573a(conditional random field)\u3002\n\n\u9012\u5f52\u795e\u7ecf\u7f51\u7edc(recurrent neural network)\u662f\u4e00\u79cd\u4fdd\u6301\u67d0\u79cd\u72b6\u6001\u7684\u7f51\u7edc\u3002\n\u4f8b\u5982\uff0c\u5b83\u7684\u8f93\u51fa\u53ef\u4ee5\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u8f93\u5165\u7684\u4e00\u90e8\u5206\u4f7f\u7528\uff0c\u4ee5\u4fbf\u4fe1\u606f\u53ef\u4ee5\u5728\u5e8f\u5217\u901a\u8fc7\u7f51\u7edc\u65f6\u5728\u5e8f\u5217\u4e2d\u4f20\u64ad\u3002\n\u5728LSTM\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u4e8e\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\uff0c\u90fd\u6709\u76f8\u5e94\u7684\u9690\u85cf\u72b6\u6001($h_t$)\uff0c\n\u539f\u5219\u4e0a\u53ef\u4ee5\u5305\u542b\u6765\u81ea\u5e8f\u5217\u4e2d\u8f83\u65e9\u7684\u4efb\u610f\u70b9\u7684\u4fe1\u606f\u3002\n\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u9690\u85cf\u72b6\u6001\u6765\u9884\u6d4b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5355\u8bcd\u3001\u8bcd\u6027\u6807\u6ce8(part-of-speech tags)\u4ee5\u53ca\u65e0\u6570\u5176\u4ed6\u4e8b\u7269\u3002\n\n\nPytorch\u4e2d\u7684LSTM\n~~~~~~~~~~~~~~~~~\n\n\u5728\u5f00\u59cb\u8fd9\u4e2a\u793a\u4f8b\u4e4b\u524d\uff0c\u8bf7\u6ce8\u610f\u4ee5\u4e0b\u51e0\u70b9\u3002Pytorch\u7684LSTM\u671f\u671b\u5b83\u7684\u6240\u6709\u8f93\u5165\u90fd\u662f3D\u5f20\u91cf\u3002\n\u8fd9\u4e9b\u5f20\u91cf\u7684\u6bcf\u4e2a\u8f74(axes)\u7684\u8bed\u4e49\u5f88\u91cd\u8981\u3002\u7b2c\u4e00\u4e2a\u8f74\u662f\u5e8f\u5217\u672c\u8eab\uff0c\u7b2c\u4e8c\u4e2a\u8f74\u7d22\u5f15batch\u4e2d\u7684\u6837\u4f8b\uff0c\n\u4ee5\u53ca\u7b2c\u4e09\u4e2a\u8f74\u7d22\u5f15\u8f93\u5165\u7684\u5143\u7d20\u3002\u6211\u4eec\u8fd8\u6ca1\u6709\u8ba8\u8bba\u8fc7mini-batching\uff0c\u6240\u4ee5\u8ba9\u6211\u4eec\u5ffd\u7565\u8fd9\u4e00\u70b9\uff0c\n\u5e76\u5047\u8bbe\u6211\u4eec\u603b\u662f\u53ea\u67091\u7ef4\u5728\u7b2c\u4e8c\u8f74\u3002\u5982\u679c\u6211\u4eec\u60f3\u5728\"The cow jumped\"\u8fd9\u4e2a\u53e5\u5b50\u4e0a\u8fd0\u884c\u5e8f\u5217\u6a21\u578b\uff0c\n\u6211\u4eec\u7684\u8f93\u5165\u5e94\u8be5\u770b\u8d77\u6765\u50cf\u8fd9\u6837\uff1a\n\n\\begin{align}\\begin{bmatrix}\n   \\overbrace{q_\\text{The}}^\\text{row vector} \\\\\n   q_\\text{cow} \\\\\n   q_\\text{jumped}\n   \\end{bmatrix}\\end{align}\n\n\u4e0d\u8fc7\uff0c\u8bf7\u8bb0\u4f4f\uff0c\u8fd8\u6709\u4e00\u4e2a\u989d\u5916\u7684\u7b2c\u4e8c\u7ef4,\u5176size\u4e3a1\u3002\n\n\u6b64\u5916\uff0c\u60a8\u53ef\u4ee5\u4e00\u6b21\u904d\u5386\u4e00\u904d\u5e8f\u5217\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7b2c\u4e00\u8f74\u7684size\u4e5f\u662f1\u3002\n\n\u8ba9\u6211\u4eec\u770b\u4e00\u4e2a\u5feb\u901f\u7684\u4f8b\u5b50\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Robert Guthrie\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\ninputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n\n# initialize the hidden state.\nhidden = (torch.randn(1, 1, 3),\n          torch.randn(1, 1, 3))\nfor i in inputs:\n    # Step through the sequence one element at a time.\n    # after each step, hidden contains the hidden state.\n    out, hidden = lstm(i.view(1, 1, -1), hidden)\n\n# alternatively, we can do the entire sequence all at once.\n# the first value returned by LSTM is all of the hidden states throughout\n# the sequence. the second is just the most recent hidden state\n# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n# The reason for this is that:\n# \"out\" will give you access to all hidden states in the sequence\n# \"hidden\" will allow you to continue the sequence and backpropagate,\n# by passing it as an argument  to the lstm at a later time\n# Add the extra 2nd dimension\ninputs = torch.cat(inputs).view(len(inputs), 1, -1)\nhidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\nout, hidden = lstm(inputs, hidden)\nprint(out)\nprint(hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6837\u4f8b: \u4e00\u79cd\u7528\u4e8e\u8bcd\u6027\u6807\u6ce8\u7684LSTM\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\u5728\u8fd9\u4e2a\u5c0f\u8282\u4e2d, \u6211\u4eec\u5c06\u4f7f\u7528 LSTM \u6765\u83b7\u5f97\u8bcd\u6027\u6807\u6ce8(part of speech tags)\u3002\n\u6211\u4eec\u5c06\u4e0d\u4f1a\u4f7f\u7528Viterbi \u6216 Forward-Backward \u6216 \u5176\u4ed6\u4efb\u4f55\u7c7b\u4f3c\u7684\u6280\u672f,\n\u4f46\u662f\u4f5c\u4e3a\u4e00\u4e2a\u5bf9\u8bfb\u8005\u7a0d\u5fae\u6709\u6311\u6218\u6027\u7684\u7ec3\u4e60, \u5f53\u4f60\u4e86\u89e3\u4e86\u8fd9\u4e00\u5207\u5982\u4f55\u8fd0\u8f6c\u7684\u65f6\u5019\n\u518d\u8003\u8651\u4e00\u4e0b\u5982\u4f55\u4f7f\u7528 Viterbi\u3002 \n\n\u6a21\u578b\u5982\u4e0b: \u5047\u5b9a\u6211\u4eec\u7684\u8f93\u5165\u8bed\u53e5\u662f $w_1, \\dots, w_M$, \u5176\u4e2d $w_i \\in V$, \u6211\u4eec\u7684\u8bcd\u6c47\u5e93\u3002\n\u53e6\u5916, \u5047\u5b9a $T$ \u662f\u6211\u4eec\u7684\u6807\u8bb0\u96c6\u5408, \u4ee5\u53ca $y_i$ \u662f\u5355\u8bcd $w_i$ \u7684\u6807\u8bb0\u3002\n\u628a\u6211\u4eec\u5bf9\u5355\u8bcd $w_i$ \u7684\u6807\u8bb0\u7684\u9884\u6d4b\u8bb0\u4e3a $\\hat{y}_i$ \u3002\n\n\u8fd9\u662f\u4e00\u4e2a\u7ed3\u6784\u9884\u6d4b\uff0c\u6a21\u578b\uff0c\u5176\u4e2d\u6211\u4eec\u7684\u8f93\u51fa\u662f\u5e8f\u5217 $\\hat{y}_1, \\dots, \\hat{y}_M$,\n\u5176\u4e2d $\\hat{y}_i \\in T$ \u3002\n\n\u4e3a\u4e86\u8fdb\u884c\u9884\u6d4b, \u5728\u53e5\u5b50\u4e0a\u4f20\u9012\u4e00\u4e2aLSTM(pass an LSTM over the sentence)\u3002 \n\u5728\u65f6\u95f4\u6b65(timestep) $i$ \u7684\u9690\u85cf\u72b6\u6001\u8bb0\u4e3a $h_i$ \u3002\n\u53e6\u5916\uff0c\u7ed9\u6bcf\u4e2atag\u5206\u914d\u4e00\u4e2a\u552f\u4e00\u7684index (\u5c31\u50cf\u5728\u8bcd\u5d4c\u5165\u7ae0\u8282\u4e2d\u7684 word\\_to\\_ix \u4e00\u6837)\u3002\n\u7136\u540e\uff0c\u6211\u4eec\u9884\u6d4b $\\hat{y}_i$ \u7684\u89c4\u5219\u662f\uff1a\n\n\\begin{align}\\hat{y}_i = \\text{argmax}_j \\  (\\log \\text{Softmax}(Ah_i + b))_j\\end{align}\n\n\u4e5f\u5c31\u662f\u8bf4, \u5bf9 \u9690\u85cf\u72b6\u6001\u7684\u4eff\u5c04\u6620\u5c04 \u53d6 \u5bf9\u6570\u8f6f\u6700\u5927\u5316(log softmax),\n\u5e76\u4e14\u9884\u6d4b\u51fa\u7684tag\u662f\u8fd9\u4e2a\u5411\u91cf\u4e2d\u7684\u6700\u5927\u503c\u5bf9\u5e94\u7684tag\u3002\n\u8bf7\u6ce8\u610f\uff0c\u8fd9\u7acb\u5373\u610f\u5473\u7740 $A$ \u7684\u76ee\u6807\u7a7a\u95f4\u7684\u7ef4\u6570\u4e3a $|T|$ \u3002\n\n\n\u51c6\u5907\u6570\u636e:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def prepare_sequence(seq, to_ix):\n    idxs = [to_ix[w] for w in seq]\n    return torch.tensor(idxs, dtype=torch.long)\n\n\ntraining_data = [\n    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n]\nword_to_ix = {}\nfor sent, tags in training_data:\n    for word in sent:\n        if word not in word_to_ix:\n            word_to_ix[word] = len(word_to_ix)\nprint(word_to_ix)\ntag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n\n# These will usually be more like 32 or 64 dimensional.\n# We will keep them small, so we can see how the weights change as we train.\nEMBEDDING_DIM = 6\nHIDDEN_DIM = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u521b\u5efa\u6a21\u578b:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n\n    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n        super(LSTMTagger, self).__init__()\n        self.hidden_dim = hidden_dim\n\n        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n\n        # The LSTM takes word embeddings as inputs, and outputs hidden states\n        # with dimensionality hidden_dim.\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n\n        # The linear layer that maps from hidden state space to tag space\n        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n        self.hidden = self.init_hidden()\n\n    def init_hidden(self):\n        # Before we've done anything, we dont have any hidden state.\n        # Refer to the Pytorch documentation to see exactly\n        # why they have this dimensionality.\n        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n        return (torch.zeros(1, 1, self.hidden_dim),\n                torch.zeros(1, 1, self.hidden_dim))\n\n    def forward(self, sentence):\n        embeds = self.word_embeddings(sentence)\n        lstm_out, self.hidden = self.lstm(\n            embeds.view(len(sentence), 1, -1), self.hidden)\n        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n        tag_scores = F.log_softmax(tag_space, dim=1)\n        return tag_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u6a21\u578b:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\nloss_function = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\n# See what the scores are before training\n# Note that element i,j of the output is the score for tag j for word i.\n# Here we don't need to train, so the code is wrapped in torch.no_grad()\nwith torch.no_grad():\n    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n    tag_scores = model(inputs)\n    print(tag_scores)\n\nfor epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n    for sentence, tags in training_data:\n        # Step 1. Remember that Pytorch accumulates gradients.\n        # We need to clear them out before each instance\n        model.zero_grad()\n\n        # Also, we need to clear out the hidden state of the LSTM,\n        # detaching it from its history on the last instance.\n        model.hidden = model.init_hidden()\n\n        # Step 2. Get our inputs ready for the network, that is, turn them into\n        # Tensors of word indices.\n        sentence_in = prepare_sequence(sentence, word_to_ix)\n        targets = prepare_sequence(tags, tag_to_ix)\n\n        # Step 3. Run our forward pass.\n        tag_scores = model(sentence_in)\n\n        # Step 4. Compute the loss, gradients, and update the parameters by\n        #  calling optimizer.step()\n        loss = loss_function(tag_scores, targets)\n        loss.backward()\n        optimizer.step()\n\n# See what the scores are after training\nwith torch.no_grad():\n    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n    tag_scores = model(inputs)\n\n    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n    # for word i. The predicted tag is the maximum scoring tag.\n    # Here, we can see the predicted sequence below is 0 1 2 0 1\n    # since 0 is index of the maximum value of row 1,\n    # 1 is the index of maximum value of row 2, etc.\n    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n    print(tag_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ec3\u4e60: \u4f7f\u7528\u5b57\u7b26\u7ea7\u7279\u5f81\u589e\u5f3aLSTM\u8bed\u4e49\u6807\u6ce8\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c\u6bcf\u4e2a\u5355\u8bcd\u90fd\u6709\u4e00\u4e2a\u5d4c\u5165\uff0c\u4f5c\u4e3a\u5e8f\u5217\u6a21\u578b\u7684\u8f93\u5165\u3002\n\u8ba9\u6211\u4eec\u7528 \u4ece\u5355\u8bcd\u7684\u5b57\u7b26\u6d3e\u751f\u51fa\u6765\u7684\u8868\u793a \u6765\u589e\u5f3a \u5355\u8bcd\u5d4c\u5165\u3002\n\u6211\u4eec\u5e0c\u671b\u8fd9\u4f1a\u6709\u5f88\u5927\u7684\u5e2e\u52a9\uff0c\u56e0\u4e3a\u8bcd\u7f00(affixes)\u4e4b\u7c7b\u7684\u5b57\u7b26\u7ea7\u4fe1\u606f\u5bf9\u8bcd\u6027(part-of-speech)\u6709\u5f88\u5927\u7684\u5f71\u54cd\u3002\n\u4f8b\u5982\uff0c\u5e26\u6709\u8bcd\u7f00 *-ly* \u7684\u8bcd\u5728\u82f1\u8bed\u4e2d\u51e0\u4e4e\u603b\u662f\u88ab\u6807\u8bb0\u4e3a\u526f\u8bcd(adverbs)\u3002\n\n\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9, \u4ee4 $c_w$ \u662f\u5355\u8bcd $w$ \u7684\u5b57\u7b26\u7ea7\u8868\u793a(character-level representation)\u3002\n\u50cf\u4e4b\u524d\u4e00\u6837\uff0c\u4ee4 $x_w$ \u662f\u5355\u8bcd\u5d4c\u5165\u3002 \u7136\u540e\uff0c\u6211\u4eec\u5e8f\u5217\u6a21\u578b\u7684\u8f93\u5165\u662f $x_w$ \u548c $c_w$\n\u7684\u4e32\u63a5(concatenation)\u3002\u56e0\u6b64\uff0c\u5982\u679c $x_w$ \u6709 5 \u4e2a\u7ef4\u5ea6, \u5e76\u4e14 $c_w$ \u7684\u7eac\u5ea6\u662f 3 ,\n\u90a3\u4e48\u6211\u4eec\u7684 LSTM \u5e94\u8be5\u63a5\u53d7\u7ef4\u6570\u4e3a8\u7684\u8f93\u5165\u3002\n\n\u4e3a\u4e86\u83b7\u5f97\u5b57\u7b26\u7ea7\u8868\u793a, \u5728\u4e00\u4e2a\u5355\u8bcd\u7684\u82e5\u5e72\u5b57\u7b26\u4e0a\u505aLSTM ,\u5e76\u4e14\u4ee4 $c_w$ \u662f\u8fd9\u4e2aLSTM\u7684\u6700\u7ec8\u9690\u85cf\u72b6\u6001\u3002\n\n\u63d0\u793a:\n\n* \u4f60\u7684\u65b0\u6a21\u578b\u5c06\u4f1a\u6709\u4e24\u4e2aLSTM\u3002\u539f\u6765\u7684LSTM\u8f93\u51faPOS\u6807\u7b7e\u5206\u6570(POS tag scores),\n  \u65b0\u7684LSTM\u8f93\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u5b57\u7b26\u7ea7\u8868\u793a\u3002\n* \u4e3a\u4e86\u5728\u5b57\u7b26\u96c6\u4e0a\u5efa\u4e00\u4e2a\u5e8f\u5217\u6a21\u578b, \u4f60\u5fc5\u987b\u5d4c\u5165\u5b57\u7b26(embed characters)\u3002\n  \u5b57\u7b26\u5d4c\u5165\u5c06\u4f1a\u6210\u4e3a\u5b57\u7b26\u7ea7LSTM\u7684\u8f93\u5165\u3002\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}