{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\n=========================\n**\u7ffb\u8bd1\u8005:** `Antares <http://wwww.studyai.com/antares>`_\n\n\u672c\u6587\u6863\u63d0\u4f9b\u4e86\u5173\u4e8ePyTorch\u6a21\u578b\u7684\u4fdd\u5b58\u548c\u52a0\u8f7d\u7684\u5404\u79cd\u7528\u4f8b\u7684\u89e3\u51b3\u65b9\u6848\u3002\n\u53ef\u4ee5\u968f\u610f\u9605\u8bfb\u6574\u4e2a\u6587\u6863\uff0c\u6216\u8005\u8df3\u8fc7\u6240\u9700\u7684\u4ee3\u7801\u4ee5\u83b7\u5f97\u6240\u9700\u7684\u7528\u4f8b\u3002\n\n\u5f53\u6d89\u53ca\u5230\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\u65f6\uff0c\u9700\u8981\u719f\u6089\u4e09\u4e2a\u6838\u5fc3\u51fd\u6570:\n\n1) `torch.save <https://pytorch.org/docs/stable/torch.html?highlight=save#torch.save>`__:\n   \u5c06\u5e8f\u5217\u5316\u5bf9\u8c61\u4fdd\u5b58\u5230\u78c1\u76d8\u3002\u6b64\u51fd\u6570\u4f7f\u7528Python\u7684 `pickle <https://docs.python.org/3/library/pickle.html>`__ \n   \u5b9e\u7528\u7a0b\u5e8f\u8fdb\u884c\u5e8f\u5217\u5316\u3002\u4f7f\u7528\u6b64\u51fd\u6570\u53ef\u4ee5\u4fdd\u5b58\u5404\u79cd\u5bf9\u8c61\u7684\u6a21\u578b\u3001\u5f20\u91cf\u548c\u5b57\u5178\u3002\n\n2) `torch.load <https://pytorch.org/docs/stable/torch.html?highlight=torch%20load#torch.load>`__:\n   \u4f7f\u7528 `pickle <https://docs.python.org/3/library/pickle.html>`__ \u7684unpickling facilities\n   \u5c06\u88abpickled\u7684\u5bf9\u8c61\u6587\u4ef6\u53cd\u5e8f\u5217\u5316\u5230\u5185\u5b58\u3002\u6b64\u51fd\u6570\u8fd8\u53ef\u65b9\u4fbf\u8bbe\u5907\u5c06\u6570\u636e\u52a0\u8f7d\u8fdb\u6765(\u8bf7\u770b \n   `Saving & Loading Model Across Devices <#saving-loading-model-across-devices>`__).\n\n3) `torch.nn.Module.load_state_dict <https://pytorch.org/docs/stable/nn.html?highlight=load_state_dict#torch.nn.Module.load_state_dict>`__:\n   \u4f7f\u7528\u53cd\u5e8f\u5217\u5316\u7684 *state_dict* \u52a0\u8f7d\u6a21\u578b\u7684\u53c2\u6570\u5b57\u5178\u3002 \u5173\u4e8e *state_dict* \u7684\u66f4\u591a\u4fe1\u606f, \u8bf7\u770b `\u4ec0\u4e48\u662f state_dict? <#what-is-a-state-dict>`__.\n\n\n\n**Contents:**\n\n-  `\u4ec0\u4e48\u662f state_dict? <#what-is-a-state-dict>`__\n-  `\u4fdd\u5b58 & \u52a0\u8f7d Model \u7528\u4e8e\u63a8\u65ad <#saving-loading-model-for-inference>`__\n-  `\u4fdd\u5b58 & \u52a0\u8f7d\u4e00\u4e2aCheckPointCheckPoint <#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training>`__\n-  `\u4fdd\u5b58\u591a\u4e2a Models \u5230\u4e00\u4e2a\u6587\u4ef6 <#saving-multiple-models-in-one-file>`__\n-  `\u4f7f\u7528\u6765\u81ea\u4e0d\u540cModel\u7684\u53c2\u6570\u70ed\u542f\u52a8\u53e6\u4e00\u4e2aModel <#warmstarting-model-using-parameters-from-a-different-model>`__\n-  `\u8de8\u8bbe\u5907 \u4fdd\u5b58 & \u52a0\u8f7d Model <#saving-loading-model-across-devices>`__\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4ec0\u4e48\u662f ``state_dict``?\n-------------------------\n\n\u5728PyTorch\u4e2d\uff0c``torch.nn.Module`` \u6a21\u578b\u7684\u53ef\u5b66\u4e60\u53c2\u6570(\u5373\u6743\u91cd\u548c\u504f\u7f6e)\u5305\u542b\u5728\u6a21\u578b\u7684 \n*parameters* \u4e2d(\u4f7f\u7528 ``model.parameters()`` \u8bbf\u95ee)\u3002\n*state_dict* \u53ea\u662f\u4e00\u4e2aPython\u5b57\u5178\u5bf9\u8c61\uff0c\u5b83\u5c06\u6bcf\u4e2a\u5c42\u6620\u5c04\u5230\u5176\u53c2\u6570\u5f20\u91cf\u3002\n\u8bf7\u6ce8\u610f\uff0c\u53ea\u6709\u5177\u6709\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u5c42(\u5377\u79ef\u5c42\u3001\u7ebf\u6027\u5c42\u7b49)\u5728\u6a21\u578b\u7684 *state_dict* \u4e2d\u6709\u6761\u76ee(entries)\u3002\nOptimizer\u5bf9\u8c61(``torch.optim``)\u8fd8\u6709\u4e00\u4e2a *state_dict* \uff0c\u5b83\u5305\u542b\u5173\u4e8e\u4f18\u5316\u5668\u72b6\u6001\u7684\u4fe1\u606f\u4ee5\u53ca\u4f7f\u7528\u7684\u8d85\u53c2\u6570\u3002\n\n\u56e0\u4e3a *state_dict* \u5bf9\u8c61\u662fPython\u5b57\u5178\uff0c\u6240\u4ee5\u53ef\u4ee5\u8f7b\u677e\u5730\u4fdd\u5b58\u3001\u66f4\u65b0\u3001\u4fee\u6539\u548c\u6062\u590d\u5b83\u4eec\uff0c\n\u4ece\u800c\u4e3aPyTorch\u6a21\u578b\u548c\u4f18\u5316\u5668\u6dfb\u52a0\u4e86\u5927\u91cf\u7684\u6a21\u5757\u5316\u3002\n\n\u4f8b\u5b50:\n^^^^^^^^\n\n\u8ba9\u6211\u4eec\u4ece `Training a classifier <https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py>`__  \n\u4e2d\u4f7f\u7528\u7684\u7b80\u5355\u6a21\u578b\u4e2d\u67e5\u770b *state_dict* \u3002\n\n.. code:: python\n\n   # \u5b9a\u4e49\u6a21\u578b\n   class TheModelClass(nn.Module):\n       def __init__(self):\n           super(TheModelClass, self).__init__()\n           self.conv1 = nn.Conv2d(3, 6, 5)\n           self.pool = nn.MaxPool2d(2, 2)\n           self.conv2 = nn.Conv2d(6, 16, 5)\n           self.fc1 = nn.Linear(16 * 5 * 5, 120)\n           self.fc2 = nn.Linear(120, 84)\n           self.fc3 = nn.Linear(84, 10)\n\n       def forward(self, x):\n           x = self.pool(F.relu(self.conv1(x)))\n           x = self.pool(F.relu(self.conv2(x)))\n           x = x.view(-1, 16 * 5 * 5)\n           x = F.relu(self.fc1(x))\n           x = F.relu(self.fc2(x))\n           x = self.fc3(x)\n           return x\n\n   # \u521d\u59cb\u5316 model\n   model = TheModelClass()\n\n   # \u521d\u59cb\u5316 optimizer\n   optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n   # \u8f93\u51fa model \u7684 state_dict\n   print(\"Model's state_dict:\")\n   for param_tensor in model.state_dict():\n       print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n\n   # \u8f93\u51fa optimizer \u7684 state_dict\n   print(\"Optimizer's state_dict:\")\n   for var_name in optimizer.state_dict():\n       print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n\n**Output:**\n\n::\n\n   Model's state_dict:\n   conv1.weight     torch.Size([6, 3, 5, 5])\n   conv1.bias   torch.Size([6])\n   conv2.weight     torch.Size([16, 6, 5, 5])\n   conv2.bias   torch.Size([16])\n   fc1.weight   torch.Size([120, 400])\n   fc1.bias     torch.Size([120])\n   fc2.weight   torch.Size([84, 120])\n   fc2.bias     torch.Size([84])\n   fc3.weight   torch.Size([10, 84])\n   fc3.bias     torch.Size([10])\n\n   Optimizer's state_dict:\n   state    {}\n   param_groups     [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [4675713712, 4675713784, 4675714000, 4675714072, 4675714216, 4675714288, 4675714432, 4675714504, 4675714648, 4675714720]}]\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4fdd\u5b58 & \u52a0\u8f7d Model \u7528\u4e8e\u63a8\u65ad\n------------------------------------\n\n\u4fdd\u5b58/\u52a0\u8f7d ``state_dict`` (\u63a8\u8350\u65b9\u5f0f)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n**\u4fdd\u5b58:**\n\n.. code:: python\n\n   torch.save(model.state_dict(), PATH)\n\n**\u52a0\u8f7d:**\n\n.. code:: python\n\n   model = TheModelClass(*args, **kwargs)\n   model.load_state_dict(torch.load(PATH))\n   model.eval()\n\n\u5728\u4fdd\u5b58\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u65f6\uff0c\u53ea\u9700\u4fdd\u5b58\u7ecf\u8fc7\u8bad\u7ec3\u7684\u6a21\u578b\u7684\u5b66\u4e60\u53c2\u6570\u5373\u53ef\u3002\u4f7f\u7528 ``torch.save()`` \u51fd\u6570\n\u4fdd\u5b58\u6a21\u578b\u7684 *state_dict* \u5c06\u4e3a\u4ee5\u540e\u6062\u590d\u6a21\u578b\u63d0\u4f9b\u6700\u5927\u7684\u7075\u6d3b\u6027\uff0c\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u63a8\u8350\u4f7f\u7528\u5b83\u6765\u4fdd\u5b58\u6a21\u578b\u3002\n\n\u4e00\u4e2a\u5e38\u89c1\u7684PyTorch\u7ea6\u5b9a\u662f\u4f7f\u7528  ``.pt`` \u6216 ``.pth`` \u6587\u4ef6\u6269\u5c55\u540d\u4fdd\u5b58\u6a21\u578b\u3002\n\n\u8bf7\u8bb0\u4f4f\uff0c\u5728\u8fd0\u884c\u63a8\u7406\u4e4b\u524d\uff0c\u60a8\u5fc5\u987b\u8c03\u7528 ``model.eval()``  \u6765\u5c06 \ndropout \u548c batch normalization layers \n\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\u3002\u5982\u679c\u4e0d\u8fd9\u6837\u505a\uff0c\u5c31\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u63a8\u7406\u7ed3\u679c\u3002\n\n.. Note ::\n\n   \u6ce8\u610f\uff0c``load_state_dict()`` \u51fd\u6570\u63a5\u53d7\u5b57\u5178\u5bf9\u8c61\uff0c\u800c **\u4e0d\u662f** \u4fdd\u5b58\u5bf9\u8c61\u7684\u8def\u5f84\u3002\n   \u8fd9\u610f\u5473\u7740\u5728\u5c06\u4fdd\u5b58\u7684 *state_dict* \u4f20\u9012\u7ed9 ``load_state_dict()`` \u51fd\u6570\u4e4b\u524d\uff0c\u5fc5\u987b\u5bf9\u5176\u8fdb\u884c\u53cd\u5e8f\u5217\u5316\u3002\n   \u4f8b\u5982\uff0c\u4e0d\u80fd\u4f7f\u7528 ``model.load_state_dict(Path)`` \u52a0\u8f7d \u3002\n\n\n\u4fdd\u5b58/\u52a0\u8f7d \u6574\u4e2a Model\n^^^^^^^^^^^^^^^^^^^^^^\n\n**\u4fdd\u5b58:**\n\n.. code:: python\n\n   torch.save(model, PATH)\n\n**\u52a0\u8f7d:**\n\n.. code:: python\n\n   # Model class must be defined somewhere\n   model = torch.load(PATH)\n   model.eval()\n\n\u8fd9\u4e2a\u4fdd\u5b58/\u52a0\u8f7d\u8fc7\u7a0b\u4f7f\u7528\u6700\u76f4\u89c2\u7684\u8bed\u6cd5\uff0c\u6d89\u53ca\u7684\u4ee3\u7801\u6700\u5c11\u3002\u4ee5\u8fd9\u79cd\u65b9\u5f0f\u4fdd\u5b58\u6a21\u578b\u5c06\u4f7f\u7528Python\u7684 \n`pickle <https://docs.python.org/3/library/pickle.html>`__ \u6a21\u5757\u4fdd\u5b58\u6574\u4e2amodel\u3002\n\u8fd9\u79cd\u65b9\u6cd5\u7684\u7f3a\u70b9\u662f\u5e8f\u5217\u5316\u6570\u636e\u88ab\u7ed1\u5b9a\u5230\u4fdd\u5b58\u6a21\u578b\u65f6\u4f7f\u7528\u7684\u7279\u5b9a\u7c7b\u548c\u7cbe\u786e\u7684\u76ee\u5f55\u7ed3\u6784\u3002\n\u539f\u56e0\u662fpickle\u6ca1\u6709\u4fdd\u5b58\u6a21\u578b\u7c7b\u672c\u8eab\u3002\u76f8\u53cd\uff0c\u5b83\u4fdd\u5b58\u5230\u5305\u542b\u7c7b\u7684\u6587\u4ef6\u7684\u8def\u5f84\uff0c\u8be5\u7c7b\u5728\u52a0\u8f7d\u65f6\u4f7f\u7528\u3002\n\u6b63\u56e0\u4e3a\u5982\u6b64\uff0c\u5f53\u60a8\u5728\u5176\u4ed6\u9879\u76ee\u4e2d\u4f7f\u7528\u65f6\u6216\u5728\u91cd\u6784\u4e4b\u540e\uff0c\u60a8\u7684\u4ee3\u7801\u53ef\u80fd\u4ee5\u5404\u79cd\u65b9\u5f0f\u4e2d\u65ad\u3002\n\n\u4e00\u4e2a\u5e38\u89c1\u7684PyTorch\u7ea6\u5b9a\u662f\u4f7f\u7528  ``.pt`` \u6216 ``.pth`` \u6587\u4ef6\u6269\u5c55\u540d\u4fdd\u5b58\u6a21\u578b\u3002\n\n\u8bf7\u8bb0\u4f4f\uff0c\u5728\u8fd0\u884c\u63a8\u7406\u4e4b\u524d\uff0c\u60a8\u5fc5\u987b\u8c03\u7528 ``model.eval()``  \u6765\u5c06 \ndropout \u548c batch normalization layers \n\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\u3002\u5982\u679c\u4e0d\u8fd9\u6837\u505a\uff0c\u5c31\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u63a8\u7406\u7ed3\u679c\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4fdd\u5b58 & \u52a0\u8f7d Checkpoint \u7528\u4e8e \u63a8\u65ad and/or \u6062\u590d\u8bad\u7ec3\n----------------------------------------------------------------------------\n\n\u4fdd\u5b58:\n^^^^^\n\n.. code:: python\n\n   torch.save({\n               'epoch': epoch,\n               'model_state_dict': model.state_dict(),\n               'optimizer_state_dict': optimizer.state_dict(),\n               'loss': loss,\n               ...\n               }, PATH)\n\n\u52a0\u8f7d:\n^^^^^\n\n.. code:: python\n\n   model = TheModelClass(*args, **kwargs)\n   optimizer = TheOptimizerClass(*args, **kwargs)\n\n   checkpoint = torch.load(PATH)\n   model.load_state_dict(checkpoint['model_state_dict'])\n   optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n   epoch = checkpoint['epoch']\n   loss = checkpoint['loss']\n\n   model.eval()\n   # - or -\n   model.train()\n\n\u5f53\u4fdd\u5b58\u4e00\u822c\u68c0\u67e5\u70b9(\u7528\u4e8e\u63a8\u7406\u6216\u6062\u590d\u8bad\u7ec3)\u65f6\uff0c\u60a8\u5fc5\u987b\u4fdd\u5b58\u7684\u4e0d\u4ec5\u4ec5\u662f\u6a21\u578b\u7684 *state_dict* \u3002\n\u4fdd\u5b58\u4f18\u5316\u5668\u7684 *state_dict* \u4e5f\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u5305\u542b\u7f13\u51b2\u533a\u548c\u53c2\u6570\uff0c\u8fd9\u4e9b\u7f13\u51b2\u533a\u548c\u53c2\u6570\u662f\u968f\u7740\u6a21\u578b\u7684\u8bad\u7ec3\u800c\u66f4\u65b0\u7684\u3002\n\u5176\u4ed6\u4f60\u53ef\u80fd\u60f3\u8981\u4fdd\u5b58\u7684\u9879\u662f \u4f60\u79bb\u5f00\u8bad\u7ec3\u8fc7\u7a0b\u65f6\u7684epoch\uff0c\u6700\u65b0\u8bb0\u5f55\u7684\u8bad\u7ec3\u635f\u5931\uff0c\u5916\u90e8\u7684 ``torch.nn.Embedding`` \u5c42\uff0c\u7b49\u7b49\u3002\n\n\u82e5\u8981\u4fdd\u5b58\u591a\u4e2a\u7ec4\u4ef6\uff0c\u8bf7\u5c06\u5b83\u4eec\u7ec4\u7ec7\u5728\u5b57\u5178\u4e2d\uff0c\u5e76\u4f7f\u7528 ``torch.save()`` \u5bf9\u5b57\u5178\u8fdb\u884c\u5e8f\u5217\u5316\u3002\n\u4e00\u4e2a\u5e38\u89c1\u7684PyTorch\u7ea6\u5b9a\u662f\u4f7f\u7528  ``.tar``  \u6587\u4ef6\u6269\u5c55\u540d\u4fdd\u5b58\u8fd9\u4e9b\u68c0\u67e5\u70b9\u3002\n\n\u8981\u52a0\u8f7d\u8fd9\u4e9b\u9879\uff0c\u9996\u5148\u521d\u59cb\u5316\u6a21\u578b\u548c\u4f18\u5316\u5668\uff0c\u7136\u540e\u4f7f\u7528 ``torch.load()`` \u5728\u672c\u5730\u52a0\u8f7d\u5b57\u5178\u3002\u4ece\u8fd9\u91cc\uff0c\u60a8\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u8bbf\u95ee\u4fdd\u5b58\u7684\u9879\u76ee\uff0c\n\u53ea\u9700\u67e5\u8be2\u5b57\u5178\uff0c\u6b63\u5982\u60a8\u6240\u671f\u671b\u7684\u3002\n\n\u8bf7\u8bb0\u4f4f\uff0c\u5728\u8fd0\u884c\u63a8\u7406\u4e4b\u524d\uff0c\u60a8\u5fc5\u987b\u8c03\u7528 ``model.eval()``  \u6765\u5c06 dropout \u548c batch normalization layers \n\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\u3002\u5982\u679c\u4e0d\u8fd9\u6837\u505a\uff0c\u5c31\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u63a8\u7406\u7ed3\u679c\u3002\n\u5982\u679c\u5e0c\u671b\u6062\u590dtraining\uff0c\u8bf7\u8c03\u7528 ``model.train()`` \u4ee5\u786e\u4fdd\u8fd9\u4e9b\u5c42\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5728\u4e00\u4e2a\u6587\u4ef6\u4e2d\u4fdd\u5b58\u591a\u4e2a Models \n----------------------------------\n\n\u4fdd\u5b58:\n^^^^^\n\n.. code:: python\n\n   torch.save({\n               'modelA_state_dict': modelA.state_dict(),\n               'modelB_state_dict': modelB.state_dict(),\n               'optimizerA_state_dict': optimizerA.state_dict(),\n               'optimizerB_state_dict': optimizerB.state_dict(),\n               ...\n               }, PATH)\n\n\u52a0\u8f7d:\n^^^^^\n\n.. code:: python\n\n   modelA = TheModelAClass(*args, **kwargs)\n   modelB = TheModelBClass(*args, **kwargs)\n   optimizerA = TheOptimizerAClass(*args, **kwargs)\n   optimizerB = TheOptimizerBClass(*args, **kwargs)\n\n   checkpoint = torch.load(PATH)\n   modelA.load_state_dict(checkpoint['modelA_state_dict'])\n   modelB.load_state_dict(checkpoint['modelB_state_dict'])\n   optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n   optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n\n   modelA.eval()\n   modelB.eval()\n   # - or -\n   modelA.train()\n   modelB.train()\n\n\u5f53\u4fdd\u5b58\u7531\u591a\u4e2a ``torch.nn.Modules`` \u7ec4\u6210\u7684\u6a21\u578b\u65f6\uff0c\u4f8b\u5982GAN\u3001sequence-to-sequence model \u6216 ensemble of models\uff0c\n\u60a8\u5c06\u9075\u5faa\u4e0e\u4fdd\u5b58\u4e00\u822c\u68c0\u67e5\u70b9\u76f8\u540c\u7684\u65b9\u6cd5\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u4fdd\u5b58\u6bcf\u4e2a\u6a21\u578b\u7684 *state_dict* \u7684\u5b57\u5178\u548c\u76f8\u5e94\u7684\u4f18\u5316\u5668\u3002\n\u5982\u524d\u6240\u8ff0\uff0c\u53ea\u9700\u5c06\u4efb\u4f55\u5176\u4ed6\u9879\u76ee\u8ffd\u52a0\u5230\u5b57\u5178\u4e2d\uff0c\u5c31\u53ef\u4ee5\u4fdd\u5b58\u53ef\u80fd\u5e2e\u52a9\u60a8\u6062\u590d\u8bad\u7ec3\u7684\u4efb\u4f55\u5176\u4ed6\u9879\u76ee\u3002\n\n\u4e00\u4e2a\u5e38\u89c1\u7684PyTorch\u7ea6\u5b9a\u662f\u4f7f\u7528  ``.tar``  \u6587\u4ef6\u6269\u5c55\u540d\u4fdd\u5b58\u8fd9\u4e9b\u68c0\u67e5\u70b9\u3002\n\n\u8981\u52a0\u8f7d\u6a21\u578b\uff0c\u9996\u5148\u521d\u59cb\u5316\u6a21\u578b\u548c\u4f18\u5316\u5668\uff0c\u7136\u540e\u4f7f\u7528 ``torch.load()`` \u672c\u5730\u52a0\u8f7d\u5b57\u5178\u3002\n\u4ece\u8fd9\u91cc\uff0c\u60a8\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u8bbf\u95ee\u4fdd\u5b58\u7684\u9879\u76ee\uff0c\u53ea\u9700\u67e5\u8be2\u5b57\u5178\uff0c\u6b63\u5982\u60a8\u6240\u671f\u671b\u7684\u3002\n\n\u8bf7\u8bb0\u4f4f\uff0c\u5728\u8fd0\u884c\u63a8\u7406\u4e4b\u524d\uff0c\u60a8\u5fc5\u987b\u8c03\u7528 ``model.eval()``  \u6765\u5c06 dropout \u548c batch normalization layers \n\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\u3002\u5982\u679c\u4e0d\u8fd9\u6837\u505a\uff0c\u5c31\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u63a8\u7406\u7ed3\u679c\u3002\n\u5982\u679c\u5e0c\u671b\u6062\u590dtraining\uff0c\u8bf7\u8c03\u7528 ``model.train()`` \u4ee5\u786e\u4fdd\u8fd9\u4e9b\u5c42\u5904\u4e8e\u8bad\u7ec3\u6a21\u5f0f\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4f7f\u7528\u6765\u81ea\u4e0d\u540cModel\u7684\u53c2\u6570\u70ed\u542f\u52a8\u53e6\u4e00\u4e2aModel \n----------------------------------------------------------\n\n\u4fdd\u5b58:\n^^^^^\n\n.. code:: python\n\n   torch.save(modelA.state_dict(), PATH)\n\n\u52a0\u8f7d:\n^^^^^\n\n.. code:: python\n\n   modelB = TheModelBClass(*args, **kwargs)\n   modelB.load_state_dict(torch.load(PATH), strict=False)\n\n\u5f53\u8fc1\u79fb\u5b66\u4e60\u6216\u8bad\u7ec3\u4e00\u4e2a\u65b0\u7684\u590d\u6742\u6a21\u578b\u65f6\uff0c\u90e8\u5206\u52a0\u8f7d\u6a21\u578b\u6216\u52a0\u8f7d\u90e8\u5206\u6a21\u578b\u662f\u5e38\u89c1\u7684\u573a\u666f\u3002\n\u5229\u7528\u7ecf\u8fc7\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u5373\u4f7f\u53ea\u6709\u5c11\u6570\u53c2\u6570\u662f\u53ef\u7528\u7684\uff0c\u4e5f\u5c06\u6709\u52a9\u4e8e\u542f\u52a8\u8bad\u7ec3\u8fc7\u7a0b\uff0c\n\u5e76\u6709\u671b\u5e2e\u52a9\u60a8\u7684\u6a21\u578b\u6bd4\u4ece\u5934\u5f00\u59cb\u7684\u8bad\u7ec3\u66f4\u5feb\u5730\u6536\u655b\u3002\n\n\u65e0\u8bba\u60a8\u662f\u4ece\u7f3a\u5c11\u4e00\u4e9b\u952e\u7684\u90e8\u5206 *state_dict* \u52a0\u8f7d\uff0c\u8fd8\u662f\u52a0\u8f7d\u4e00\u4e2a *state_dict* \u4e2d\u7684\u952e\u6bd4\u60a8\u8981\u52a0\u8f7d\u7684\u6a21\u578b\u591a\uff0c\n\u60a8\u90fd\u53ef\u4ee5\u5728 ``load_state_dict()`` \u51fd\u6570\u4e2d\u5c06 ``strict``  \u53c2\u6570\u8bbe\u7f6e\u4e3a ``false`` \uff0c\u4ee5\u5ffd\u7565\u4e0d\u5339\u914d\u7684\u952e\u3002\n\n\u5982\u679c\u5e0c\u671b\u5c06\u53c2\u6570\u4ece\u4e00\u4e2a\u5c42\u52a0\u8f7d\u5230\u53e6\u4e00\u4e2a\u5c42\uff0c\u4f46\u6709\u4e9b\u952e\u4e0d\u5339\u914d\uff0c\u5219\u53ea\u9700\u66f4\u6539\u8981\u52a0\u8f7d\u7684 *state_dict*  \u4e2d\u53c2\u6570\u952e\u7684\u540d\u79f0\uff0c\n\u4ee5\u4e0e\u52a0\u8f7d\u5230\u7684\u6a21\u578b\u4e2d\u7684\u952e\u5339\u914d\u3002 \n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8de8\u8bbe\u5907 \u4fdd\u5b58 & \u52a0\u8f7d Model \n-------------------------------------\n\n\u4fdd\u5b58\u5728GPU, \u52a0\u8f7d\u5230CPU\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n**\u4fdd\u5b58:**\n\n.. code:: python\n\n   torch.save(model.state_dict(), PATH)\n\n**\u52a0\u8f7d:**\n\n.. code:: python\n\n   device = torch.device('cpu')\n   model = TheModelClass(*args, **kwargs)\n   model.load_state_dict(torch.load(PATH, map_location=device))\n\n\u5728CPU\u4e0a\u52a0\u8f7d\u7528GPU\u8bad\u7ec3\u7684\u6a21\u578b\u65f6\uff0c\u5c06 ``torch.device('cpu')`` \u4f20\u9012\u5230 ``torch.load()`` \u51fd\u6570\u4e2d\u7684 ``map_location`` \u53c2\u6570\u3002\n\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5728\u5f20\u91cf\u57fa\u7840\u4e0a\u7684\u5b58\u50a8\u5c06\u4f7f\u7528 ``map_location`` \u53c2\u6570\u52a8\u6001\u5730\u91cd\u6620\u5c04\u5230CPU\u8bbe\u5907\u3002\n\n\u4fdd\u5b58\u5728 GPU, \u52a0\u8f7d\u5230 GPU\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n**\u4fdd\u5b58:**\n\n.. code:: python\n\n   torch.save(model.state_dict(), PATH)\n\n**\u52a0\u8f7d:**\n\n.. code:: python\n\n   device = torch.device(\"cuda\")\n   model = TheModelClass(*args, **kwargs)\n   model.load_state_dict(torch.load(PATH))\n   model.to(device)\n   # Make sure to call input = input.to(device) on any input tensors that you feed to the model\n\n\u5f53\u628a\u5728GPU\u4e0a\u8bad\u7ec3\u548c\u4fdd\u5b58\u7684\u6a21\u578b\u52a0\u8f7d\u5230GPU\u4e0a\u65f6\uff0c\u53ea\u9700\u4f7f\u7528 ``model.to(torch.device('cuda'))`` \u5c06\u521d\u59cb\u5316\u7684 ``model`` \u8f6c\u6362\u4e3aCUDA\u4f18\u5316\u6a21\u578b\u3002\n\u6b64\u5916\uff0c\u786e\u4fdd\u5728\u6240\u6709\u6a21\u578b\u8f93\u5165\u4e0a\u4f7f\u7528 ``.to(torch.device('cuda'))`` \u51fd\u6570\u6765\u4e3a\u6a21\u578b\u51c6\u5907\u6570\u636e\u3002\n\u6ce8\u610f\uff0c\u8c03\u7528 ``my_tensor.to(device)`` \u5c06\u8fd4\u56deGPU\u4e0a ``my_tensor`` \u7684\u65b0\u526f\u672c\u3002\u5b83 **\u4e0d\u4f1a** \u8986\u76d6  ``my_tensor`` \u3002\n\u56e0\u6b64\uff0c\u8bf7\u8bb0\u4f4f\u624b\u52a8\u8986\u76d6\u5f20\u91cf\uff1a``my_tensor = my_tensor.to(torch.device('cuda'))`` \u3002\n\n\n\u4fdd\u5b58\u5728CPU, \u52a0\u8f7d\u5230GPU\n^^^^^^^^^^^^^^^^^^^^^^^^\n\n**\u4fdd\u5b58:**\n\n.. code:: python\n\n   torch.save(model.state_dict(), PATH)\n\n**\u52a0\u8f7d:**\n\n.. code:: python\n\n   device = torch.device(\"cuda\")\n   model = TheModelClass(*args, **kwargs)\n   model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n   model.to(device)\n   # \u786e\u4fdd\u8c03\u7528 input = input.to(device) \u5728\u4efb\u610f\u7684\u8f93\u5165tensors\u4e0a \n\n\u5f53\u628a\u5728CPU\u4e0a\u8bad\u7ec3\u548c\u4fdd\u5b58\u7684\u6a21\u578b \u52a0\u8f7d\u5230GPU\u4e0a\u65f6\uff0c\u8bf7\u5c06 ``torch.load()`` \u51fd\u6570\u4e2d\u7684 ``map_location`` \u53c2\u6570\u8bbe\u7f6e\u4e3a\n*cuda:device_id* \u3002\u8fd9\u4f1a\u5c06\u6a21\u578b\u52a0\u8f7d\u5230\u7ed9\u5b9a\u7684GPU\u8bbe\u5907\u4e0a\u3002\u63a5\u4e0b\u6765\uff0c\u8bf7\u786e\u4fdd\u8c03\u7528\n``model.to(torch.device('cuda'))`` \u5c06\u6a21\u578b\u7684\u53c2\u6570\u5f20\u91cf\u8f6c\u6362\u4e3aCUDA\u5f20\u91cf\u3002\n\u6700\u540e\uff0c\u786e\u4fdd\u5728\u6240\u6709\u6a21\u578b\u8f93\u5165\u4e0a\u4f7f\u7528 ``.to(torch.device('cuda'))`` \u51fd\u6570\u6765\u4e3aCUDA\u4f18\u5316\u6a21\u578b\u51c6\u5907\u6570\u636e\u3002\n\u6ce8\u610f\uff0c\u8c03\u7528 ``my_tensor.to(device)`` \u5c06\u8fd4\u56deGPU\u4e0a ``my_tensor`` \u7684\u65b0\u526f\u672c\u3002\u5b83\u4e0d\u4f1a\u8986\u76d6 ``my_tensor`` \u3002\n\u56e0\u6b64\uff0c\u8bf7\u8bb0\u4f4f\u624b\u52a8\u8986\u76d6\u5f20\u91cf\uff1a``my_tensor = my_tensor.to(torch.device('cuda'))`` \u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u4fdd\u5b58 ``torch.nn.DataParallel`` Models\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n#\n# **\u4fdd\u5b58:**\n#\n# .. code:: python\n#\n#    torch.save(model.module.state_dict(), PATH)\n#\n# **\u52a0\u8f7d:**\n#\n# .. code:: python\n#\n#    # \u52a0\u8f7d\u5230\u4efb\u4f55\u4f60\u60f3\u52a0\u8f7d\u7684\u8bbe\u5907\u4e0a\n#\n# ``torch.nn.DataParallel`` \u662f\u4e00\u4e2a\u652f\u6301\u5e76\u884cGPU\u5229\u7528\u7387\u7684\u6a21\u578b\u5305\u88c5\u5668\u3002\n# \u8981\u4e00\u822c\u6027\u5730\u4fdd\u5b58 ``DataParallel`` \u6a21\u578b\uff0c\u8bf7\u4fdd\u5b58 ``model.module.state_dict()``\u3002\n# \u8fd9\u6837\uff0c\u60a8\u5c31\u53ef\u4ee5\u7075\u6d3b\u5730\u5c06\u6a21\u578b\u52a0\u8f7d\u5230\u4efb\u4f55\u60a8\u60f3\u8981\u7684\u8bbe\u5907\u4e0a\u3002\n#"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}