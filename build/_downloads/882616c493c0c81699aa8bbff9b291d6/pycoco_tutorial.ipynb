{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nMSCOCO\u6570\u636e\u96c6\u7684\u52a0\u8f7d\u8bfb\u53d6\n==============================\n\n**\u4f5c\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`__\n\n\u6211\u4eec\u5c06\u4ecb\u7ecdMSCOCO\u6570\u636e\u96c6\u7684pycocotools\u7684Python API\u7684\u4f7f\u7528\u65b9\u6cd5\uff0c\u4ee5\u53ca ``torchvison.datasets.CocoCaptions`` \u3001\n``torchvison.datasets.CocoDetection`` \u7684\u7528\u6cd5\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b89\u88c5 pycocotools\n-------------------------\n\n\u8bf7\u6309\u7167\u8fd9\u4e2a\u6587\u6863\u7684\u8bf4\u660e\u4e0b\u8f7d\u5b89\u88c5\uff1ahttps://blog.csdn.net/daniaokuye/article/details/78699138\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6570\u636e\u6587\u4ef6\u76ee\u5f55\u7ed3\u6784\n-------------------------\n\n**\u4e0b\u8f7d\u6570\u636e**: \n\n- annotations_trainval2017.zip  (`[\u4e0b\u8f7d\u8fde\u63a5] <http://images.cocodataset.org/annotations/annotations_trainval2017.zip>`__)\n- image_info_test2017.zip     (`[\u4e0b\u8f7d\u8fde\u63a5] <http://images.cocodataset.org/annotations/image_info_test2017.zip>`__)\n- stuff_annotations_trainval2017.zip (`[\u8fde\u63a5] <http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip>`__)\n- test2017.zip    (`[\u4e0b\u8f7d\u8fde\u63a5] <http://images.cocodataset.org/zips/test2017.zip>`__)\n- train2017.zip   (`[\u4e0b\u8f7d\u8fde\u63a5] <http://images.cocodataset.org/zips/train2017.zip>`__)\n- val2017.zip    (`[\u4e0b\u8f7d\u8fde\u63a5] <http://images.cocodataset.org/zips/val2017.zip>`__)\n\n\u5c06zip\u6587\u4ef6\u89e3\u538b\u5230coco\u8fd9\u4e2a\u76ee\u5f55\u4e0b\uff0c\u5176\u4e2d\uff0c\u56fe\u50cf\u653e\u5728 ```coco/images/``` \u4e0b\u9762\uff0c\u6807\u6ce8\u653e\u5728 ```coco/annotations``` \u4e0b\u9762\n\n\u4e0b\u9762\u662f\u6211\u7684\u76ee\u5f55\u6811\uff0c\u5b89\u88c5\u4e0aUbuntu\u7684tree\u547d\u4ee4\u5c31\u53ef\u4ee5\u67e5\u770b\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ```\n# (pytorchenv1) zhjm@tower:~/Downloads/MSCOCO2017$ tree -L 3\n# .\n# \u251c\u2500\u2500 coco\n# \u2502\u00a0\u00a0 \u251c\u2500\u2500 annotations\n# \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 annotations_trainval2017\n# \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 image_info_test2017\n# \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 stuff_annotations_trainval2017\n# \u2502\u00a0\u00a0 \u2514\u2500\u2500 images\n# \u2502\u00a0\u00a0     \u251c\u2500\u2500 test2017\n# \u2502\u00a0\u00a0     \u251c\u2500\u2500 train2017\n# \u2502\u00a0\u00a0     \u2514\u2500\u2500 val2017\n# \u2514\u2500\u2500 zip files\n#     \u251c\u2500\u2500 annotations_trainval2017.zip \n#     \u251c\u2500\u2500 image_info_test2017.zip     \n#     \u251c\u2500\u2500 stuff_annotations_trainval2017.zip \n#     \u251c\u2500\u2500 test2017.zip  \n#     \u251c\u2500\u2500 train2017.zip  \n#     \u2514\u2500\u2500 val2017.zip  \n\n# ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5bfc\u5165\u4f9d\u8d56\u5305\n-------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pycocotools.coco import COCO\nimport numpy as np\nimport skimage.io as io\nimport matplotlib.pyplot as plt\nimport pylab\npylab.rcParams['figure.figsize'] = (8.0, 10.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6307\u5b9a\u6570\u636e\u5b58\u653e\u8def\u5f84\n-------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataDir='/home/zhjm/Downloads/MSCOCO2017/coco'\ndataType='val2017'\nannFile='{}/annotations/annotations_trainval2017/instances_{}.json'.format(dataDir,dataType)\nprint(annFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pycocotools\u7684API\u7684\u7528\u6cd5\n----------------------------\n\u603b\u5171\u6709\u4e09\u79cd\u4efb\u52a1\uff1a\n\n* \u5b9e\u4f8b\u6807\u6ce8(Instances Annotations);\n* \u4eba\u4f53\u5173\u952e\u70b9\u6807\u6ce8(Human Keypoints Annotations);\n* \u770b\u56fe\u8bf4\u8bdd\u6807\u6ce8(Caption Annotations)\n\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u521d\u59cb\u5316\u5b9e\u4f8b\u6807\u6ce8\u7684COCO API\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coco=COCO(annFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5c55\u793aCOCO\u7c7b\u522b\u548c\u8d85\u7c7b\u522b\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cats = coco.loadCats(coco.getCatIds())\nnms=[cat['name'] for cat in cats]\nprint('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n\nnms = set([cat['supercategory'] for cat in cats])\nprint('COCO supercategories: \\n{}'.format(' '.join(nms)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u83b7\u53d6\u5305\u542b\u67d0\u4e9b\u7c7b\u522b\u7684\u6240\u6709\u56fe\u50cf\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\u610f\u601d\u662f\u83b7\u53d6\u5230\u7684\u6bcf\u4e2a\u56fe\u50cf\u90fd\u5fc5\u987b\u5305\u542bcatNms=['person','dog','skateboard']\u4e2d\u6307\u5b9a\u7684\u7269\u4f53\u5b9e\u4f8b\u3002\n\n\u6ee1\u8db3\u68c0\u7d22\u6761\u4ef6\u7684\u53ea\u6709\u4e09\u5f20\u56fe\u50cf\uff1a\u540c\u65f6\u5305\u542b\u4e86 \u4eba\uff0c \u72d7 \uff0c \u6ed1\u677f(skateboard)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "catIds = coco.getCatIds(catNms=['person','dog','skateboard']);\nprint(\"\u7c7b\u522b\u7f16\u53f7\uff1a\", catIds)\nimgIds = coco.getImgIds(catIds=catIds);\nprint(type(imgIds),len(imgIds))\nprint(\"\u56fe\u50cf\u7f16\u53f7\uff1a\", imgIds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5728\u7b26\u5408\u6761\u4ef6\u7684\u591a\u5f20\u56fe\u7247\u4e2d\u968f\u673a\u9009\u62e9\u4e00\u5f20\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imgIds = coco.getImgIds(imgIds = [549220, 324158, 279278])\nprint(imgIds)\nimg = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\nprint(type(img))\nprint(list(img.keys()))\nprint(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u4e0e\u663e\u793a\u56fe\u50cf\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# I = io.imread('%s/images/%s/%s'%(dataDir,dataType,img['file_name']))\n# use url to load image\nI = io.imread(img['coco_url'])  # img \u662f\u4e2a\u5b57\u5178\uff0c\u4fdd\u5b58\u7740\u8be5\u56fe\u50cf\u7684anns\u4fe1\u606f\nplt.figure(figsize=[6.5, 2.5])\nplt.axis('off')\nplt.imshow(I)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u4e0e\u663e\u793a\u5b9e\u4f8b\u6807\u6ce8\u4fe1\u606f\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[6.5, 2.5])\nplt.imshow(I); plt.axis('off')\nannIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\nanns = coco.loadAnns(annIds)\ncoco.showAnns(anns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u521d\u59cb\u5316\u4eba\u4f53\u5173\u952e\u70b9\u6807\u6ce8\u4fe1\u606f\u7684COCO API\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "annFile = '{}/annotations/annotations_trainval2017/person_keypoints_{}.json'.format(dataDir,dataType)\ncoco_kps=COCO(annFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u4e0e\u663e\u793a\u5173\u952e\u70b9\u6807\u6ce8\u4fe1\u606f\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[6.5, 2.5])\nplt.imshow(I); plt.axis('off')\nax = plt.gca()\nannIds = coco_kps.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\nanns = coco_kps.loadAnns(annIds)\ncoco_kps.showAnns(anns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u521d\u59cb\u5316Caption\u6807\u6ce8\u4fe1\u606f\u7684COCO API\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "annFile = '{}/annotations/annotations_trainval2017/captions_{}.json'.format(dataDir,dataType)\ncoco_caps=COCO(annFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u548c\u663e\u793aCaption\u6807\u6ce8\u4fe1\u606f\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "annIds = coco_caps.getAnnIds(imgIds=img['id']);\nanns = coco_caps.loadAnns(annIds)\nplt.figure(figsize=[6.5, 2.5])\ncoco_caps.showAnns(anns)\nplt.imshow(I); plt.axis('off'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch\u4e2d\u7684MSCOCO\u8bfb\u53d6\u65b9\u6cd5\n-----------------------------------\n\u4e3b\u8981\u4ecb\u7ecd ``torchvison.datasets.CocoCaptions`` \u3001\n``torchvison.datasets.CocoDetection`` \u7684\u7528\u6cd5\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CocoCaptions(\u00b7\u00b7\u00b7)\u7684\u4f7f\u7528\u65b9\u6cd5\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\ndataDir='/home/zhjm/Downloads/MSCOCO2017/coco'\ndataType='train2017'  #\u5982\u679c\u8981\u83b7\u53d6\u6d4b\u8bd5\u96c6\uff0c\u5c31 'test2017'\nannFile = '{}/annotations/annotations_trainval2017/captions_{}.json'.format(dataDir,dataType)\nprint(annFile)\n\nroot = dataDir + '/images/' + dataType\n\n# \u5bf9\u6570\u636e\u505a\u53d8\u6362\u7684\u53d8\u6362\u7c7b\ntransform_train = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = dset.CocoCaptions(root = root, annFile = annFile, transform=transform_train)\n\nprint('\u6837\u672c\u6570\u91cf: ', len(trainset))\nimg, target = trainset[3] # \u52a0\u8f7d\u7b2c\u56db\u4e2a\u6837\u672c\n\nprint(\"\u6570\u636e\u7c7b\u578b\uff1a\", type(img))\nprint(\"\u56fe\u50cf\u5c3a\u5bf8: \", img.size())\nprint(\"\u6807\u6ce8\u4fe1\u606f\uff1a\",target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u663e\u793a\u56fe\u50cf\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    # \u628a Tensor \u8f6c\u6362\u4e3a Numpy\u7c7b\u578b\n    npimg = img.numpy()\n    # \u5fc5\u987b\u8981\u8c03\u6574\u901a\u9053\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.axis('off'); plt.show()\n\n# get a random training image\nimage, target = trainset[np.random.randint(0,len(trainset))]\nplt.figure()\n# show images\nimshow(image)\n# print labels\nprint(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CocoDetection(\u00b7\u00b7\u00b7)\u7684\u4f7f\u7528\u65b9\u6cd5\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as dset\nimport torchvision.transforms as transforms\n\ndataDir='/home/zhjm/Downloads/MSCOCO2017/coco'\ndataType='val2017'  #\u5982\u679c\u8981\u83b7\u53d6\u6d4b\u8bd5\u96c6\uff0c\u5c31 'val2017'\nannFile = '{}/annotations/annotations_trainval2017/instances_{}.json'.format(dataDir,dataType)\nprint(annFile)\n\nroot = dataDir + '/images/' + dataType\n\n# \u5bf9\u6570\u636e\u505a\u53d8\u6362\u7684\u53d8\u6362\u7c7b\ntransform_train = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = dset.CocoDetection(root = root, annFile = annFile, transform=transform_train)\n\nprint('\u6837\u672c\u6570\u91cf: ', len(trainset))\nimg, target = trainset[3] # \u52a0\u8f7d\u7b2c\u56db\u4e2a\u6837\u672c,Tuple (image, target). target is the object returned by `coco.loadAnns`\n\nprint(\"\u56fe\u50cf\u6570\u636e\u7c7b\u578b\uff1a\", type(img))\nprint(\"\u56fe\u50cf\u5c3a\u5bf8: \", img.size())\nprint(\"\u6570\u636e\u7c7b\u578b\uff1a\",type(target))  # \u662f\u4e00\u4e2a\u5b57\u5178\u5217\u8868\uff0c\u6bcf\u4e2a\u7269\u4f53\u5bf9\u5e94\u4e00\u4e2a\u5b57\u5178\nprint(\"\u7269\u4f53\u6570\u91cf\uff1a\",len(target))  # \nprint(\"\u5b57\u5178\u7684\u952e\uff1a\",list(target[0].keys()))  # \nprint(\"\u7b2c\u4e00\u4e2a\u7269\u4f53\u7684\u6807\u6ce8\u4fe1\u606f\uff1a\",target[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u663e\u793a\u56fe\u50cf\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image and anns\ndef imshow(img, anns=None):\n    img = img / 2 + 0.5     # unnormalize\n    # \u628a Tensor \u8f6c\u6362\u4e3a Numpy\u7c7b\u578b\n    npimg = img.numpy()\n    plt.figure(figsize=[6.5, 2.5])\n    # \u5fc5\u987b\u8981\u8c03\u6574\u901a\u9053\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    if anns is not None:\n        coco.showAnns(anns=anns)\n    plt.axis('off'); plt.show()\n\n# get a random training image\nimage, target = trainset[np.random.randint(0,len(trainset))]\n\n# show images and target(anns)\nimshow(image, target)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}