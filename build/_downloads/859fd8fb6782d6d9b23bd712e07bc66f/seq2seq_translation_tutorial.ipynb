{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u4f7f\u7528\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u7f51\u7edc\u548c\u6ce8\u610f\u673a\u5236\u8fdb\u884c\u7ffb\u8bd1\n*************************************************************\n**\u7ffb\u8bd1\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`_\n\n\u5728\u8fd9\u4e2a\u9879\u76ee\u4e2d\uff0c\u6211\u4eec\u5c06\u6559\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u628a\u6cd5\u8bed\u7ffb\u8bd1\u6210\u82f1\u8bed\u3002\n\n::\n\n    [KEY: > input, = target, < output]\n\n    > il est en train de peindre un tableau .\n    = he is painting a picture .\n    < he is painting a picture .\n\n    > pourquoi ne pas essayer ce vin delicieux ?\n    = why not try that delicious wine ?\n    < why not try that delicious wine ?\n\n    > elle n est pas poete mais romanciere .\n    = she is not a poet but a novelist .\n    < she not not a poet but a novelist .\n\n    > vous etes trop maigre .\n    = you re too skinny .\n    < you re all alone .\n\n... \u53d6\u5f97\u4e0d\u540c\u7a0b\u5ea6\u7684\u6210\u529f\u3002\n\n\u8fd9\u662f\u56e0\u4e3a\u7b80\u5355\u800c\u6709\u529b\u7684 `\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u7f51\u7edc <http://arxiv.org/abs/1409.3215>`__ \u601d\u60f3\uff0c\n\u5176\u4e2d\u4e24\u4e2a\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u4e00\u8d77\u5de5\u4f5c\uff0c\u5c06\u4e00\u4e2a\u5e8f\u5217\u8f6c\u6362\u6210\u53e6\u4e00\u4e2a\u5e8f\u5217\u3002\n\u7f16\u7801\u5668\u7f51\u7edc\u5c06\u8f93\u5165\u5e8f\u5217\u538b\u7f29\u4e3a\u5411\u91cf\uff0c\u89e3\u7801\u5668\u7f51\u7edc\u5c06\u8be5\u5411\u91cf\u5c55\u5f00\u4e3a\u65b0\u5e8f\u5217\u3002\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\n\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e2a\u6a21\u578b\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u4e00\u79cd\u6ce8\u610f\u673a\u5236(`attention mechanism <https://arxiv.org/abs/1409.0473>`__)\uff0c\n\u5b83\u8ba9\u89e3\u7801\u5668\u5b66\u4f1a\u5c06\u6ce8\u610f\u529b\u96c6\u4e2d\u5728\u8f93\u5165\u5e8f\u5217\u7684\u7279\u5b9a\u8303\u56f4\u4e0a\u3002\n\n**\u63a8\u8350\u9605\u8bfb:**\n\n\u6211\u5047\u5b9a\u4f60\u6700\u8fd1\u624d\u5b89\u88c5\u4e86 PyTorch, \u77e5\u9053 Python, \u5e76\u4e14\u7406\u89e3 \u5f20\u91cf(Tensors)\u662f\u4ec0\u4e48\u4e1c\u897f:\n\n-  https://pytorch.org/ \u67e5\u770b\u5b89\u88c5\u6307\u5357\n-  :doc:`/beginner/deep_learning_60min_blitz` \u5728\u8fd9\u4e2a\u7ae0\u8282\u83b7\u5f97PyTorch\u7684\u8d77\u6b65\u77e5\u8bc6\n-  :doc:`/beginner/pytorch_with_examples` \u83b7\u5f97\u4e00\u4e2a\u5bbd\u6cdb\u800c\u6709\u6df1\u5ea6\u7684\u6982\u89c8\n-  :doc:`/beginner/former_torchies_tutorial` \u5982\u679c\u60a8\u662f\u524dLua Torch\u7528\u6237\n\n\n\u5982\u679c\u4e86\u89e3 \u5e8f\u5217\u5230\u5e8f\u5217\u7f51\u7edc(Sequence to Sequence networks) \u5e76\u77e5\u9053\u5b83\u4eec\u7684\u5de5\u4f5c\u539f\u7406\u5c06\u4f1a\u5f88\u6709\u7528:\n\n-  `\u4f7f\u7528\u7528\u4e8e\u7edf\u8ba1\u673a\u5668\u7ffb\u8bd1\u7684RNN\u7f16\u89e3\u7801\u5668\u5b66\u4e60\u77ed\u8bed\u8868\u793a <http://arxiv.org/abs/1406.1078>`__\n-  `\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u5b66\u4e60 <http://arxiv.org/abs/1409.3215>`__\n-  `\u8054\u5408\u5b66\u4e60\u5bf9\u9f50\u4e0e\u7ffb\u8bd1\u7684\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1 <https://arxiv.org/abs/1409.0473>`__\n-  `\u4e00\u79cd\u795e\u7ecf\u4f1a\u8bdd\u6a21\u578b <http://arxiv.org/abs/1506.05869>`__\n\n\u4f60\u8fd8\u4f1a\u53d1\u73b0\u4e4b\u524d\u7684\u6559\u7a0b :doc:`/intermediate/char_rnn_classification_tutorial`\n\u548c :doc:`/intermediate/char_rnn_generation_tutorial` \u662f\u975e\u5e38\u6709\u5e2e\u52a9\u7684\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6982\u5ff5\u662f\u4e0e\u4e4b\u524d\n\u4ecb\u7ecd\u8fc7\u7684Encoder \u548c Decoder\u6a21\u578b\u975e\u5e38\u76f8\u4f3c\u3002\n\n\u8981\u4e86\u89e3\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u9605\u8bfb\u4ecb\u7ecd\u8fd9\u4e9b\u4e3b\u9898\u7684\u8bba\u6587:\n\n-  `Learning Phrase Representations using RNN Encoder-Decoder for\n   Statistical Machine Translation <http://arxiv.org/abs/1406.1078>`__\n-  `Sequence to Sequence Learning with Neural\n   Networks <http://arxiv.org/abs/1409.3215>`__\n-  `Neural Machine Translation by Jointly Learning to Align and\n   Translate <https://arxiv.org/abs/1409.0473>`__\n-  `A Neural Conversational Model <http://arxiv.org/abs/1506.05869>`__\n\n\n**\u9700\u8981\u5bfc\u5165\u7684\u5305**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u6570\u636e\u6587\u4ef6\n==================\n\n\u8fd9\u4e2a\u9879\u76ee\u7684\u6570\u636e\u662f\u4e00\u5957\u6210\u5343\u4e0a\u4e07\u7684\u82f1\u6cd5\u7ffb\u8bd1\u5bf9(English to French translation pairs)\u3002\n\n`\u5728\u8fd9\u4e2a Open Data Stack Exchange \u4e0a\u7684\u95ee\u9898 <http://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages>`__\n\u628a\u6211\u6307\u5411\u4e00\u4e2a\u5f00\u653e\u7ffb\u8bd1\u7f51\u7ad9 http://tatoeba.org/ \uff0c\u5b83\u6709\u4e0b\u8f7d\u53ef\u7528 http://tatoeba.org/eng/downloads - \n\u66f4\u597d\u7684\u662f\uff0c\u6709\u4eba\u5728\u8fd9\u91cc\u505a\u4e86\u989d\u5916\u7684\u5de5\u4f5c\uff0c\u5c06\u8bed\u8a00\u5bf9\u5206\u5272\u6210\u5355\u72ec\u7684\u6587\u672c\u6587\u4ef6: http://www.manythings.org/anki/\n\n\u4ece\u82f1\u8bed\u5230\u6cd5\u8bed\u7684\u914d\u5bf9\u592a\u5927\uff0c\u65e0\u6cd5\u5305\u542b\u5728\u4ed3\u5e93(repo)\u4e2d\uff0c\u6240\u4ee5\u5728\u7ee7\u7eed\u4e4b\u524d\u8bf7\u4e0b\u8f7d\u5230 ``data/eng-fra.txt`` \u3002\n\u8be5\u6587\u4ef6\u662f\u4e00\u4e2a\u4ee5tab\u5206\u9694\u7684\u7ffb\u8bd1\u5bf9\u5217\u8868:\n\n::\n\n    I am cold.    J'ai froid.\n\n.. Note::\n   \u4ece `\u8fd9\u513f <https://download.pytorch.org/tutorial/data.zip>`_ \u4e0b\u8f7d\u6570\u636e\uff0c\u5e76\u4e14\u62bd\u53d6\u5230\u5f53\u524d\u76ee\u5f55\u4e0b\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7c7b\u4f3c\u4e8e\u5b57\u7b26\u7ea7rnn\u6559\u7a0b\u4e2d\u4f7f\u7528\u7684\u5b57\u7b26\u7f16\u7801\uff0c\u6211\u4eec\u5c06\u4e00\u79cd\u8bed\u8a00\u4e2d\u7684\u6bcf\u4e2a\u5355\u8bcd\u8868\u793a\u4e3aone-hot vector\uff0c\n\u6216\u9664\u5355\u4e2a\u96f6\u5411\u91cf(\u5728\u5355\u8bcd\u7d22\u5f15\u5904)\u5916\u7684\u5de8\u5927\u96f6\u5411\u91cf\u3002\u4e0e\u67d0\u4e00\u79cd\u8bed\u8a00\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u51e0\u5341\u4e2a\u5b57\u7b26\u76f8\u6bd4\uff0c\n\u5355\u8bcd\u7684\u6570\u91cf\u53ef\u80fd\u5927\u5f97\u591a\uff0c\u56e0\u6b64\u7f16\u7801\u5411\u91cf\u8981\u5927\u5f97\u591a\u3002\u7136\u800c\uff0c\u6211\u4eec\u5c06\u6b3a\u9a97\u4e00\u70b9\uff0c\u5e76\u51cf\u5c11\u6570\u636e\uff0c\n\u4f7f\u5176\u6bcf\u79cd\u8bed\u8a00\u53ea\u4f7f\u7528\u51e0\u5343\u4e2a\u5355\u8bcd\u3002\n\n.. figure:: /_static/img/seq-seq-images/word-encoding.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u9700\u8981\u4e3a\u6bcf\u4e2a\u5355\u8bcd\u5206\u914d\u4e00\u4e2a\u552f\u4e00\u7684\u7d22\u5f15\u4ee5\u4fbf\u5728\u7a0d\u540e\u7528\u4e8e\u7f51\u7edc\u7684\u8f93\u5165(inputs)\u548c\u76ee\u6807(targets)\u3002\u4e3a\u4e86\u8ddf\u8e2a\u8fd9\u4e00\u5207\uff0c\n\u6211\u4eec\u5c06\u4f7f\u7528\u4e00\u4e2a\u540d\u4e3a ``Lang`` \u7684\u8f85\u52a9\u7c7b\uff0c\u8be5\u7c7b\u5177\u6709word \u2192 index (``word2index``)\u5b57\u5178\u548c\nindex \u2192 word(``index2word``)\u5b57\u5178\uff0c\u4ee5\u53ca\u6bcf\u4e2a\u5355\u8bcd\u7684\u6570\u91cf(``word2count``)\u7528\u4e8e\u7a0d\u540e\u66ff\u6362\u7a00\u6709\u5355\u8bcd\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6240\u6709\u7684\u6587\u4ef6\u90fd\u662fUnicode\u7f16\u7801\u7684, \u4e3a\u4e86\u7b80\u5316\uff0c\u6211\u4eec\u5c06\u628aUnicode\u7f16\u7801\u7684\u5b57\u7b26\u8f6c\u53d8\u4e3aASCII,\n\u5168\u90e8\u8f6c\u6362\u4e3a\u5c0f\u5199\uff0c\u88c1\u51cf\u6389\u6807\u70b9\u7b26\u53f7\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u628a\u4e00\u4e2a Unicode \u5b57\u7b26\u4e32\u8f6c\u53d8\u4e3a\u7b80\u5355\u7684 ASCII \u5b57\u7b26\u4e32, \u611f\u8c22\n# http://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# \u5c0f\u5199, \u88c1\u526a, \u5e76\u79fb\u9664\u975e\u5b57\u6bcd\u5b57\u7b26\n\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8981\u8bfb\u53d6\u6570\u636e\u6587\u4ef6\uff0c\u6211\u4eec\u5c06\u6587\u4ef6(file)\u62c6\u5206\u6210\u884c(lines)\uff0c\u7136\u540e\u5c06\u884c(lines)\u62c6\u5206\u6210\u5bf9(pairs)\u3002\n\u8fd9\u4e9b\u6587\u4ef6\u90fd\u662f \u82f1\u8bed\u2192\u5176\u4ed6\u8bed\u8a00\uff0c\u56e0\u6b64\uff0c\u5982\u679c\u6211\u4eec\u60f3\u8981\u628a\u5176\u4ed6\u8bed\u8a00\u7ffb\u8bd1\u4e3a\u82f1\u8bed\uff0c\u6211\u6dfb\u52a0\u4e86\u4e00\u4e2a\n``reverse`` \u6807\u8bb0\u6765\u53cd\u8f6cpairs\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    lines = open('./data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u56e0\u4e3a\u6709 *\u5f88\u591a* \u6837\u4f8b\u53e5\u5b50\uff0c\u6211\u4eec\u60f3\u8981\u5feb\u901f\u5730\u8bad\u7ec3\u4e00\u4e9b\u4e1c\u897f\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u628a\u6570\u636e\u96c6\u4e2d\u5230\u76f8\u5bf9\u8f83\u77ed\u548c\u7b80\u5355\u7684\u53e5\u5b50\u4e0a\u3002\n\u8fd9\u91cc\u7684\u6700\u5927\u957f\u5ea6\u662f10\u4e2a\u5355\u8bcd(\u5305\u62ec\u7ed3\u675f\u6807\u70b9\u7b26\u53f7)\uff0c\u6211\u4eec\u8fc7\u6ee4\u6389\u7ffb\u8bd1\u6210\u201cI am\u201d\u6216\u201che is\u201d\u7b49\u5f62\u5f0f\u7684\u53e5\u5b50\u3002\n(\u8f83\u65e9\u65f6\u7528\u6487\u53f7\u4ee3\u66ff)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s\",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u51c6\u5907\u6570\u636e\u7684\u5168\u6d41\u7a0b\u5982\u4e0b:\n\n-  \u8bfb\u53d6\u6587\u672c\u6587\u4ef6\uff0c\u62c6\u5206\u6210\u884c\uff0c\u5c06\u884c\u62c6\u5206\u6210\u5bf9(pairs)\n-  \u5f52\u4e00\u5316\u6587\u672c\uff0c\u4f7f\u7528\u957f\u5ea6\u548c\u5185\u5bb9\u8fc7\u6ee4\n-  \u4ece\u53e5\u5b50\u4e2d\u5236\u4f5c\u5355\u8bcd\u5bf9\u7684\u5217\u8868\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n\ninput_lang, output_lang, pairs = prepareData('eng', 'fra', True)\nprint(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Seq2Seq Model\n=================\n\n\u5faa\u73af\u795e\u7ecf\u7f51\u7edc(Recurrent Neural Network, or RNN) \u662f\u4e00\u79cd\u5bf9\u5e8f\u5217\u8fdb\u884c\u64cd\u4f5c\u5e76\u5229\u7528\u81ea\u5df1\u7684\u8f93\u51fa\u4f5c\u4e3a\u540e\u7eed\u6b65\u9aa4\u7684\u8f93\u5165\u7684\u7f51\u7edc\u3002\n\n\u4e00\u4e2a\u5e8f\u5217\u5230\u5e8f\u5217\u7f51\u7edc(`Sequence to Sequence network <http://arxiv.org/abs/1409.3215>`__) , \u6216\nseq2seq \u7f51\u7edc, \u6216 \u7f16\u7801\u89e3\u7801\u7f51\u7edc(`Encoder Decoder network <https://arxiv.org/pdf/1406.1078v3.pdf>`__), \u662f\u4e00\u4e2a\u6a21\u578b\uff0c\n\u5b83\u7531\u4e24\u4e2a\u79f0\u4e4b\u4e3a\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7684RNNs\u6784\u6210\u3002\u7f16\u7801\u5668\u8bfb\u53d6\u8f93\u5165\u5e8f\u5217\u7136\u540e\u8f93\u51fa\u5355\u4e2a\u5411\u91cf(single vector),\u800c\u89e3\u7801\u5668\u8bfb\u53d6\u7f16\u7801\u5668\u8f93\u51fa\u7684\u90a3\u4e2a\u5411\u91cf\n\u7136\u540e\u518d\u4ea7\u751f\u4e00\u4e2a\u8f93\u51fa\u5e8f\u5217\u3002\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\n\u4e0e\u4f7f\u7528\u5355\u4e2aRNN\u8fdb\u884c\u5e8f\u5217\u9884\u6d4b(\u5728\u8fd9\u91cc\u6bcf\u4e00\u4e2a\u8f93\u5165\u5bf9\u5e94\u4e00\u4e2a\u8f93\u51fa)\u4e0d\u4e00\u6837\uff0cseq2seq \u6a21\u578b\n\u5c06\u6211\u4eec\u4ece\u5e8f\u5217\u957f\u5ea6\u548c\u987a\u5e8f\u4e2d\u89e3\u653e\u51fa\u6765\uff0c\u8fd9\u4f7f\u5f97\u5b83\u9002\u5408\u4e8e\u4e24\u79cd\u8bed\u8a00\u4e4b\u95f4\u7684\u7ffb\u8bd1(translation)\u3002\n\n\u8bf7\u8003\u8651\u53e5\u5b50 \"Je ne suis pas le chat noir\" \u2192 \"I am not the black cat\" \u3002\n\u8f93\u5165\u53e5\u5b50\u7684\u5927\u591a\u6570\u5355\u8bcd\u5728\u8f93\u51fa\u8bed\u53e5\u4e2d\u90fd\u6709\u76f4\u63a5\u7684\u7ffb\u8bd1\uff0c\u4f46\u662f\u4e24\u4e2a\u53e5\u5b50\u7684\u987a\u5e8f\u6709\u4e9b\u4e0d\u4e00\u6837\uff0c\ne.g. \"chat noir\" \u548c \"black cat\"\u3002 \u56e0\u4e3a \"ne/pas\" \u7684\u6784\u9020\uff0c\u8f93\u5165\u53e5\u5b50\u4e2d\u8fd8\u591a\u51fa\u4e86\u4e00\u4e2a\u5355\u8bcd\u3002\n\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u5982\u679c\u4ece\u8f93\u5165\u5355\u8bcd\u7684\u5e8f\u5217\u76f4\u63a5\u4ea7\u751f\u4e00\u4e2a\u6b63\u786e\u7684\u7ffb\u8bd1\u662f\u4e00\u4ef6\u5f88\u96be\u7684\u4e8b\u60c5\u3002\n\n\u6709\u4e86 seq2seq \u6a21\u578b\u4e4b\u540e\uff0c\u7f16\u7801\u5668\u521b\u5efa\u4e00\u4e2a\u5355\u4e2a\u5411\u91cf(single vector)\uff0c\u8fd9\u4e2a\u5411\u91cf\uff0c\u5728\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u7f16\u7801\u4e86\u8f93\u5165\u5355\u8bcd\u5e8f\u5217\u7684\u610f\u4e49(\"meaning\")\u3002\n\u8be5\u5355\u4e2a\u5411\u91cf\u662f\u53e5\u5b50\u7684\u67d0\u4e2aN\u7ef4\u7a7a\u95f4\u4e2d\u7684\u5355\u4e2a\u70b9\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Encoder\n-----------\n\nseq2seq\u7f51\u7edc\u7684\u7f16\u7801\u5668\u662f\u4e00\u4e2aRNN\uff0c\u5b83\u4e3a\u6765\u81ea\u8f93\u5165\u53e5\u5b50\u4e2d\u7684\u6bcf\u4e2a\u5355\u8bcd\u8f93\u51fa\u4e00\u4e9b\u503c\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u8f93\u5165\u5355\u8bcd\uff0c\u7f16\u7801\u5668\u8f93\u51fa\u4e00\u4e2a\u5411\u91cf\u548c\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\uff0c\n\u5e76\u4e3a\u4e0b\u4e00\u4e2a\u8f93\u5165\u5355\u8bcd\u4f7f\u7528\u9690\u85cf\u72b6\u6001\u3002\n\n.. figure:: /_static/img/seq-seq-images/encoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Decoder\n-----------\n\n\u89e3\u7801\u5668\u662f\u53e6\u4e00\u4e2aRNN\uff0c\u5b83\u63a5\u53d7\u7f16\u7801\u5668\u8f93\u51fa\u5411\u91cf\u5e76\u8f93\u51fa\u4e00\u7cfb\u5217\u5355\u8bcd\u4ee5\u521b\u5efa\u7ffb\u8bd1\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7b80\u5355\u89e3\u7801\u5668\n^^^^^^^^^^^^^^\n\n\u5728\u6700\u7b80\u5355\u7684seq2seq\u89e3\u7801\u5668\u4e2d\uff0c\u6211\u4eec\u53ea\u4f7f\u7528\u7f16\u7801\u5668\u7684\u6700\u540e\u8f93\u51fa\u3002\u6700\u540e\u4e00\u4e2a\u8f93\u51fa\u6709\u65f6\u88ab\u79f0\u4e3a\u4e0a\u4e0b\u6587\u5411\u91cf(*context vector*)\uff0c\n\u56e0\u4e3a\u5b83\u4ece\u6574\u4e2a\u8f93\u5165\u5e8f\u5217\u4e2d\u7f16\u7801\u4e0a\u4e0b\u6587\u3002\u8be5\u4e0a\u4e0b\u6587\u5411\u91cf\u7528\u4f5c\u89e3\u7801\u5668\u7684\u521d\u59cb\u9690\u85cf\u72b6\u6001\u3002\n\n\u5728\u89e3\u7801\u7684\u6bcf\u4e00\u6b65\uff0c\u7ed9\u89e3\u7801\u5668\u4e00\u4e2a\u8f93\u5165\u4ee4\u724c\u548c\u9690\u85cf\u72b6\u6001\u3002\u521d\u59cb\u8f93\u5165\u4ee4\u724c\u662f\u5b57\u7b26\u4e32\u7684\u8d77\u59cb ``<SOS>`` \u4ee4\u724c\uff0c\n\u7b2c\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\u662f\u4e0a\u4e0b\u6587\u5411\u91cf(\u7f16\u7801\u5668\u7684\u6700\u540e\u4e00\u4e2a\u9690\u85cf\u72b6\u6001)\u3002\n\n.. figure:: /_static/img/seq-seq-images/decoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u9f13\u52b1\u4f60\u4eec\u8bad\u7ec3\u548c\u89c2\u5bdf\u8fd9\u4e2a\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u4f46\u4e3a\u4e86\u8282\u7701\u7a7a\u95f4\uff0c\u6211\u4eec\u5c06\u76f4\u63a5\u5954\u7740\u91d1\u724c\u53bb\n(\u4f5c\u8005\u610f\u601d\u662f\u76f4\u63a5\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u6700\u597d\u7684\u6a21\u578b)\uff0c\u5e76\u5f15\u5165\u6ce8\u610f\u673a\u5236(Attention Mechanism)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6ce8\u610f\u529b\u89e3\u7801\u5668\n^^^^^^^^^^^^^^^^^\n\n\u5982\u679c\u53ea\u6709\u4e0a\u4e0b\u6587\u5411\u91cf\u5728\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u4e4b\u95f4\u4f20\u9012\uff0c\u90a3\u4e48\u8be5\u5411\u91cf\u5c31\u627f\u62c5\u4e86\u5bf9\u6574\u4e2a\u53e5\u5b50\u8fdb\u884c\u7f16\u7801\u7684\u8d1f\u62c5\u3002\n\nAttention\u5141\u8bb8\u89e3\u7801\u5668\u7f51\u7edc\u5bf9\u81ea\u8eab\u8f93\u51fa\u7684\u6bcf\u4e00\u6b65\u201c\u805a\u7126\u201d\u7f16\u7801\u5668\u8f93\u51fa\u7684\u4e0d\u540c\u90e8\u5206\u3002\n\u9996\u5148\uff0c\u6211\u4eec\u8ba1\u7b97\u4e86\u4e00\u7ec4\u6ce8\u610f\u529b\u6743\u91cd(*attention weights*)\u3002\u8fd9\u4e9b\u5c06\u88ab\u4e58\u4ee5\u7f16\u7801\u5668\u8f93\u51fa\u5411\u91cf\uff0c\u4ee5\u521b\u5efa\u52a0\u6743\u7ec4\u5408\u3002\n\u7ed3\u679c(\u5728\u4ee3\u7801\u4e2d\u79f0\u4e3a ``attn_applied`` )\u5e94\u8be5\u5305\u542b\u6709\u5173\u8f93\u5165\u5e8f\u5217\u7684\u7279\u5b9a\u90e8\u5206\u7684\u4fe1\u606f\uff0c\n\u4ece\u800c\u5e2e\u52a9\u89e3\u7801\u5668\u9009\u62e9\u6b63\u786e\u7684\u8f93\u51fa\u5355\u8bcd\u3002\n\n.. figure:: https://i.imgur.com/1152PYf.png\n   :alt:\n\n\u5229\u7528\u89e3\u7801\u5668\u7684\u8f93\u5165\u548c\u9690\u85cf\u72b6\u6001\u4f5c\u4e3a\u8f93\u5165\uff0c\u7528\u53e6\u4e00\u4e2a\u524d\u9988\u5c42 ``attn`` \u8fdb\u884c\u6ce8\u610f\u529b\u6743\u503c\u7684\u8ba1\u7b97\u3002\n\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u4e2d\u6709\u5404\u79cd\u5927\u5c0f\u7684\u53e5\u5b50\uff0c\u4e3a\u4e86\u5b9e\u9645\u521b\u5efa\u548c\u8bad\u7ec3\u8fd9\u4e00\u5c42\uff0c\u6211\u4eec\u5fc5\u987b\u9009\u62e9\u4e00\u4e2a\n\u6700\u5927\u7684\u53e5\u5b50\u957f\u5ea6(\u8f93\u5165\u957f\u5ea6\uff0c\u7528\u4e8e\u7f16\u7801\u5668\u8f93\u51fa)\u3002\u6700\u5927\u957f\u5ea6\u7684\u53e5\u5b50\u5c06\u4f7f\u7528\u6240\u6709\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\n\u800c\u8f83\u77ed\u7684\u53e5\u5b50\u53ea\u4f7f\u7528\u524d\u51e0\u4e2a\u3002\n\n.. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n        super(AttnDecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n        self.out = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, input, hidden, encoder_outputs):\n        embedded = self.embedding(input).view(1, 1, -1)\n        embedded = self.dropout(embedded)\n\n        attn_weights = F.softmax(\n            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n                                 encoder_outputs.unsqueeze(0))\n\n        output = torch.cat((embedded[0], attn_applied[0]), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n\n        output = F.log_softmax(self.out(output[0]), dim=1)\n        return output, hidden, attn_weights\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\u8fd8\u6709\u5176\u4ed6\u5f62\u5f0f\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u4f7f\u7528\u76f8\u5bf9\u4f4d\u7f6e\u65b9\u6cd5\uff0c\u7ed5\u8fc7\u957f\u5ea6\u9650\u5236\u3002\n  \u9605\u8bfb `\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\u7684\u6709\u6548\u65b9\u6cd5 <https://arxiv.org/abs/1508.04025>`__ \n  \u4e2d\u7684\u201c\u5c40\u90e8\u6ce8\u610f\u201d \u3002</p></div>\n\n\u8bad\u7ec3\n========\n\n\u51c6\u5907\u8bad\u7ec3\u6570\u636e\n-----------------------\n\n\u4e3a\u4e86\u8bad\u7ec3\uff0c\u5bf9\u4e8e\u6bcf\u4e2apair\u6211\u4eec\u5c06\u9700\u8981\u4e00\u4e2a\u8f93\u5165\u5f20\u91cf(\u8f93\u5165\u53e5\u5b50\u4e2d\u5355\u8bcd\u7684\u7d22\u5f15)\u548c\u76ee\u6807\u5f20\u91cf(\u76ee\u6807\u53e5\u5b50\u4e2d\u5355\u8bcd\u7684\u7d22\u5f15)\u3002\n\u5728\u521b\u5efa\u8fd9\u4e9b\u5411\u91cf\u65f6\uff0c\u6211\u4eec\u5c06EOS\u4ee4\u724c\u8ffd\u52a0\u5230\u8fd9\u4e24\u4e2a\u5e8f\u5217\u4e2d\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u6a21\u578b\n------------------\n\n\u4e3a\u4e86\u8bad\u7ec3\uff0c\u6211\u4eec\u8ba9\u8f93\u5165\u8bed\u53e5\u901a\u8fc7\u7f16\u7801\u5668\uff0c\u5e76\u8ddf\u8e2a\u6bcf\u4e2a\u8f93\u51fa\u548c\u6700\u65b0\u7684\u9690\u85cf\u72b6\u6001\u3002\n\u7136\u540e\uff0c\u89e3\u7801\u5668\u88ab\u8d4b\u4e88 ``<SOS>`` \u4ee4\u724c\u4f5c\u4e3a\u5b83\u7684\u7b2c\u4e00\u4e2a\u8f93\u5165\uff0c\u7f16\u7801\u5668\u7684\u6700\u540e\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\n\u4f5c\u4e3a\u5b83\u7684\u7b2c\u4e00\u4e2a\u9690\u85cf\u72b6\u6001\u3002\n\n\"\u6559\u5e08\u5f3a\u8feb(Teacher forcing)\" \u662f\u8fd9\u6837\u4e00\u4e2a\u6982\u5ff5(concept),\u5b83\u5c06\u771f\u6b63\u7684\u76ee\u6807\u8f93\u51fa\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u8f93\u5165\uff0c\n\u800c\u4e0d\u662f\u4f7f\u7528\u89e3\u7801\u5668\u7684\u731c\u6d4b\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u8f93\u5165\u3002\u4f7f\u7528\u6559\u5e08\u5f3a\u8feb\u53ef\u4ee5\u4f7f\u5176\u6536\u655b\u66f4\u5feb\uff0c\u4f46\u662f\n`\u5f53\u7ecf\u8fc7\u8bad\u7ec3\u7684\u7f51\u7edc\u88ab\u5229\u7528(exploited)\u65f6\uff0c\u5b83\u53ef\u80fd\u4f1a\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u6027 \n<http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf>`__ \u3002\n\n\u4f60\u53ef\u4ee5\u89c2\u5bdf\u5230\u6559\u5e08\u5f3a\u8feb\u7f51\u7edc\u7684\u8f93\u51fa-\u7528\u8fde\u8d2f\u7684\u8bed\u6cd5\u9605\u8bfb\uff0c\u5374\u8fdc\u79bb\u6b63\u786e\u7684\u7ffb\u8bd1-\u76f4\u89c2\u5730\u8bf4\uff0c\u5b83\u5df2\u7ecf\u5b66\u4f1a\u4e86\u8868\u793a\u8f93\u51fa\u8bed\u6cd5\uff0c\n\u5e76\u4e14\u4e00\u65e6\u8001\u5e08\u544a\u8bc9\u5b83\u524d\u51e0\u4e2a\u5355\u8bcd\uff0c\u5b83\u5c31\u53ef\u4ee5\u201c\u6361\u8d77(pick up)\u201d\u610f\u4e49\uff0c\u4f46\u5b83\u4e00\u5f00\u59cb\u5c31\u6ca1\u6709\u5b66\u4f1a\u5982\u4f55\u4ece\u7ffb\u8bd1\u4e2d\u521b\u9020\u53e5\u5b50\u3002\n\n\u7531\u4e8ePyTorch\u7684autograd\u7ed9\u6211\u4eec\u7684\u81ea\u7531\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e00\u6761\u7b80\u5355\u7684if\u8bed\u53e5\u968f\u673a\u9009\u62e9\u4f7f\u7528\u8001\u5e08\u5f3a\u8feb\u6216\u4e0d\u4f7f\u7528\u3002\n\u628a ``teacher_forcing_ratio`` \u63d0\u9ad8\u5230\u66f4\u591a\u5730\u4f7f\u7528\u5b83\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd9\u662f\u4e00\u4e2a\u8f85\u52a9\u51fd\u6570\uff0c\u7528\u4e8e\u5728\u7ed9\u5b9a\u6d88\u901d\u7684\u65f6\u95f4\u548c\u8fdb\u5ea6\u767e\u5206\u6bd4\u7684\u60c5\u51b5\u4e0b\u6253\u5370\u7ecf\u8fc7\u7684\u65f6\u95f4\u548c\u4f30\u8ba1\u7684\u5269\u4f59\u65f6\u95f4\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b :\n\n-  \u5f00\u542f\u4e00\u4e2a\u8ba1\u65f6\u5668\n-  \u521d\u59cb\u5316\u4f18\u5316\u5668\u548c\u51c6\u5219\n-  \u521b\u5efa\u4e00\u7ec4\u8bad\u7ec3\u5bf9(training pairs)\n-  \u51c6\u5907\u4e00\u4e2a\u7a7a\u635f\u5931\u6570\u7ec4\u7528\u4e8e\u7ed8\u56fe\n\n\u7136\u540e\u6211\u4eec\u8c03\u7528 ``train`` \u5f88\u591a\u6b21\uff0c\u5e76\u4e14\u5076\u5c14\u6253\u5370\u8fdb\u5ea6 (\u6837\u4f8b\u767e\u5206\u6bd4, \u76ee\u524d\u6240\u82b1\u8d39\u65f6\u95f4, \u4f30\u8ba1\u5269\u4f59\u65f6\u95f4) \u548c \u5e73\u5747\u635f\u5931\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ed8\u5236\u7ed3\u679c\n----------------\n\n\u7ed8\u56fe\u662f\u4f7f\u7528matplotlib\u5b8c\u6210\u7684\uff0c\u4f7f\u7528\u8bad\u7ec3\u65f6\u4fdd\u5b58\u7684\u635f\u5931\u503c ``plot_losses`` \u7684\u6570\u7ec4\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bc4\u4f30\n==========\n\n\u8bc4\u4f30\u8fc7\u7a0b\u7684\u5927\u90e8\u5206\u4e0e\u8bad\u7ec3\u662f\u76f8\u540c\u7684\uff0c\u4f46\u6ca1\u6709\u76ee\u6807\u51fd\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u7b80\u5355\u5730\u5728\u6bcf\u4e00\u6b65\u5c06\u89e3\u7801\u5668\u7684\u9884\u6d4b\u53cd\u9988\u7ed9\u81ea\u5df1\u3002\n\u6bcf\u6b21\u5b83\u9884\u6d4b\u4e00\u4e2a\u5355\u8bcd\u65f6\uff0c\u6211\u4eec\u90fd\u4f1a\u5c06\u5b83\u6dfb\u52a0\u5230\u8f93\u51fa\u5b57\u7b26\u4e32\u4e2d\uff0c\u5982\u679c\u5b83\u9884\u6d4b\u5230EOS\u4ee4\u724c\uff0c\u5c31\u4f1a\u505c\u6b62\u3002\n\u6211\u4eec\u8fd8\u5b58\u50a8\u89e3\u7801\u5668\u7684\u6ce8\u610f\u529b\u8f93\u51fa\uff0c\u4ee5\u4f9b\u4ee5\u540e\u663e\u793a\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n\n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n        decoder_attentions = torch.zeros(max_length, max_length)\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            decoder_attentions[di] = decoder_attention.data\n            topv, topi = decoder_output.data.topk(1)\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u53ef\u4ee5\u4ece\u8bad\u7ec3\u96c6\u4e2d\u5bf9\u968f\u673a\u53e5\u5b50\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u6253\u5370\u51fa\u8f93\u5165\u3001\u76ee\u6807\u548c\u8f93\u51fa\uff0c\n\u4ece\u800c\u505a\u51fa\u4e00\u4e9b\u4e3b\u89c2\u7684\u8d28\u91cf\u5224\u65ad\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, attentions = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3 \u548c \u8bc4\u4f30\n=======================\n\n\u6709\u4e86\u6240\u6709\u8fd9\u4e9b\u8f85\u52a9\u51fd\u6570(\u5b83\u770b\u8d77\u6765\u50cf\u662f\u989d\u5916\u7684\u5de5\u4f5c\uff0c\u4f46\u5b83\u4f7f\u8fd0\u884c\u591a\u4e2a\u5b9e\u9a8c\u66f4\u5bb9\u6613)\uff0c\n\u6211\u4eec\u5b9e\u9645\u4e0a\u5c31\u53ef\u4ee5\u521d\u59cb\u5316\u4e00\u4e2a\u7f51\u7edc\u5e76\u5f00\u59cb\u8bad\u7ec3\u3002\n\n\u8bb0\u4f4f\uff0c\u8f93\u5165\u7684\u53e5\u5b50\u662f\u7ecf\u8fc7\u4e25\u683c\u8fc7\u6ee4\u7684\u3002\u5bf9\u4e8e\u8fd9\u4e2a\u5c0f\u6570\u636e\u96c6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u76f8\u5bf9\u8f83\u5c0f\u7684\u7f51\u7edc\uff0c\n\u5305\u62ec256\u4e2a\u9690\u85cf\u8282\u70b9\u548c\u4e00\u4e2aGRU\u5c42\u3002\u5728MacBook\u7684CPU\u4e0a\u5927\u7ea640\u5206\u949f\u540e\uff0c\u6211\u4eec\u5c06\u5f97\u5230\u4e00\u4e9b\u5408\u7406\u7684\u7ed3\u679c\u3002\n\n.. Note::\n   \u5982\u679c\u4f60\u8fd0\u884c\u8fd9\u4e2anotebook\uff0c\u4f60\u53ef\u4ee5\u8bad\u7ec3\uff0c\u4e2d\u65ad\u5185\u6838\uff0c\u8bc4\u4f30\uff0c\u5e76\u5728\u4ee5\u540e\u7ee7\u7eed\u8bad\u7ec3\u3002\n   \u5bf9\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u521d\u59cb\u5316\u7684\u884c\u8fdb\u884c\u6ce8\u91ca\uff0c\u5e76\u518d\u6b21\u8fd0\u884c ``trainIters`` \u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hidden_size = 256\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n\ntrainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u53ef\u89c6\u5316\u6ce8\u610f\u529b\u7f51\u7edc\u8f93\u51fa\n---------------------\n\n\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e00\u4e2a\u6709\u7528\u7684\u7279\u6027\u662f\u5176\u9ad8\u5ea6\u53ef\u89e3\u91ca\u7684\u8f93\u51fa\u3002\u7531\u4e8e\u5b83\u7528\u4e8e\u52a0\u6743\u7f16\u7801\u5668\u8f93\u51fa\u7684\u7279\u5b9a\u90e8\u5206\uff0c\n\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u67e5\u770b\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7f51\u7edc\u6700\u805a\u7126\u7684\u8f93\u51fa\u90e8\u5206\u662f\u54ea\u91cc\u3002\n\n\u60a8\u53ea\u9700\u7b80\u5355\u8fd0\u884c ``plt.matshow(attentions)`` \u5c31\u53ef\u4ee5\u5c06\u6ce8\u610f\u529b\u8f93\u51fa\u663e\u793a\u4e3a\u4e00\u4e2a\u77e9\u9635\uff0c\n\u5176\u4e2d\u77e9\u9635\u7684\u5217\u662f\u8f93\u5165\u6b65(input steps)\uff0c\u77e9\u9635\u7684\u884c\u662f\u8f93\u51fa\u6b65(output steps)\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output_words, attentions = evaluate(\n    encoder1, attn_decoder1, \"je suis trop froid .\")\nplt.matshow(attentions.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e3a\u4e86\u83b7\u5f97\u66f4\u597d\u7684\u53ef\u89c6\u5316\u4f53\u9a8c\uff0c\u6211\u4eec\u5c06\u505a\u989d\u5916\u7684\u5de5\u4f5c\uff0c\u6dfb\u52a0\u8f74\u548c\u6807\u7b7e\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n    # Set up figure with colorbar\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.numpy(), cmap='bone')\n    fig.colorbar(cax)\n\n    # Set up axes\n    ax.set_xticklabels([''] + input_sentence.split(' ') +\n                       ['<EOS>'], rotation=90)\n    ax.set_yticklabels([''] + output_words)\n\n    # Show label at every tick\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n\n\ndef evaluateAndShowAttention(input_sentence):\n    output_words, attentions = evaluate(\n        encoder1, attn_decoder1, input_sentence)\n    print('input =', input_sentence)\n    print('output =', ' '.join(output_words))\n    showAttention(input_sentence, output_words, attentions)\n\n\nevaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n\nevaluateAndShowAttention(\"elle est trop petit .\")\n\nevaluateAndShowAttention(\"je ne crains pas de mourir .\")\n\nevaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ec3\u4e60\n=========\n\n-  \u5c1d\u8bd5\u4f7f\u7528\u4e0d\u540c\u7684\u6570\u636e\u96c6\n\n   -  Another language pair\n   -  Human \u2192 Machine (e.g. IOT commands)\n   -  Chat \u2192 Response\n   -  Question \u2192 Answer\n\n-  \u5c06\u5d4c\u5165\u66ff\u6362\u4e3a\u9884\u5148\u8bad\u7ec3\u8fc7\u7684\u5355\u8bcd\u5d4c\u5165\uff0c\u4f8b\u5982 word2vec \u6216 GloVe\u3002\n-  \u5c1d\u8bd5\u7528\u66f4\u591a\u7684\u5c42\uff0c\u66f4\u591a\u7684\u9690\u85cf\u5355\u5143\uff0c\u66f4\u591a\u7684\u53e5\u5b50\u3002\u6bd4\u8f83\u8bad\u7ec3\u65f6\u95f4\u548c\u7ed3\u679c\u3002\n-  \u5982\u679c\u60a8\u4f7f\u7528\u4e00\u4e2a\u7ffb\u8bd1\u6587\u4ef6\uff0c\u5176\u4e2d pairs \u6709\u4e24\u4e2a\u76f8\u540c\u7684\u77ed\u8bed(``I am test \\t I am test``)\uff0c\n   \u5219\u53ef\u4ee5\u5c06\u5176\u7528\u4f5c\u81ea\u52a8\u7f16\u7801\u5668\u3002\u8bd5\u8bd5\u8fd9\u4e2a:\n\n   -  \u4f5c\u4e3a\u81ea\u7f16\u7801\u5668\u8fdb\u884c\u8bad\u7ec3\n   -  \u53ea\u4fdd\u5b58\u7f16\u7801\u5668\u7f51\u7edc\n   -  \u8bad\u7ec3\u4e00\u4e2a\u89e3\u7801\u5668\u7528\u4e8e\u7ffb\u8bd1\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}