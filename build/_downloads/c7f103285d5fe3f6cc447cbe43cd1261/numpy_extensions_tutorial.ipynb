{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u4f7f\u7528 numpy \u548c scipy \u521b\u5efa\u6269\u5c55\n=========================================\n**\u7ffb\u8bd1\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`_\n\n\u5728\u672c\u6559\u7a0b\u4e2d, \u6211\u4eec\u8981\u5b8c\u6210\u4e24\u4e2a\u4efb\u52a1:\n\n1. \u521b\u5efa\u4e00\u4e2a\u6ca1\u6709\u53c2\u6570\u7684\u795e\u7ecf\u7f51\u7edc:\n\n    -  \u8c03\u7528 **numpy** \u4f5c\u4e3a\u5176\u5b9e\u73b0\u7684\u4e00\u90e8\u5206\n\n2. \u521b\u5efa\u4e00\u4e2a\u6709\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u795e\u7ecf\u7f51\u7edc:\n\n    -  \u8c03\u7528 **SciPy** \u4f5c\u4e3a\u5176\u5b9e\u73b0\u7684\u4e00\u90e8\u5206\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.autograd import Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u65e0\u53c2\u6570\u7684\u793a\u4f8b\n----------------------\n\n\u8fd9\u4e00\u5c42\u6ca1\u6709\u505a\u4efb\u4f55\u6709\u7528\u7684\u6216\u6570\u5b66\u4e0a\u6b63\u786e\u7684\u4e8b\u60c5\u3002\n\n\u88ab\u6070\u5f53\u5730\u547d\u540d\u4e3a  BadFFTFunction\n\n**Layer \u5b9e\u73b0**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from numpy.fft import rfft2, irfft2\n\n\nclass BadFFTFunction(Function):\n\n    def forward(self, input):\n        numpy_input = input.detach().numpy()\n        result = abs(rfft2(numpy_input))\n        return input.new(result)\n\n    def backward(self, grad_output):\n        numpy_go = grad_output.numpy()\n        result = irfft2(numpy_go)\n        return grad_output.new(result)\n\n# \u7531\u4e8e\u8be5\u5c42\u6ca1\u6709\u4efb\u4f55\u53c2\u6570\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u5730\u5c06\u5176\u58f0\u660e\u4e3a\u51fd\u6570\uff0c\u800c\u4e0d\u662f nn.Module \u7c7b\u3002\n\n\ndef incorrect_fft(input):\n    return BadFFTFunction()(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\u600e\u4e48\u4f7f\u7528\u81ea\u5df1\u521b\u9020\u7684Layers:**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input = torch.randn(8, 8, requires_grad=True)\nresult = incorrect_fft(input)\nprint(result)\nresult.backward(torch.randn(result.size()))\nprint(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u53c2\u6570\u5316\u7684\u793a\u4f8b\n--------------------\n\n\u5728\u6df1\u5ea6\u5b66\u4e60\u7684\u6587\u732e\u4e2d, \u8fd9\u4e2a\u5c42\u88ab\u542b\u7cca\u7684\u79f0\u4e3a\u5377\u79ef\u5c42\u800c\u5b9e\u9645\u4e0a\u7684\u64cd\u4f5c\u662f\u4ea4\u53c9\u4e92\u76f8\u5173(cross-correlation)\n(\u5377\u79ef\u548c\u4ea4\u53c9\u4e92\u76f8\u5173\u7684\u552f\u4e00\u533a\u522b\u662f \u505a\u5377\u79ef\u7684\u65f6\u5019\u6ee4\u6ce2\u5668\u6838\u4f1a\u88ab\u53cd\u8f6c\uff0c\u800c\u4ea4\u53c9\u4e92\u76f8\u5173\u5219\u4e0d\u8981\u53cd\u8f6c\u6ee4\u6ce2\u5668\u6838)\u3002\n\n\u5177\u6709\u53ef\u5b66\u4e60\u6743\u503c\u7684\u5c42\u7684\u5b9e\u73b0\uff0c\u5176\u4e2d\u4e92\u76f8\u5173\u6709\u4e00\u4e2a\u8868\u793a\u6743\u91cd\u7684\u6ee4\u6ce2\u5668\u6838\u3002\n\n\u53cd\u5411\u4f20\u9012\u8ba1\u7b97\u635f\u5931\u76f8\u5bf9\u4e8e\u8f93\u5165\u7684\u68af\u5ea6\u548c\u635f\u5931\u76f8\u5bf9\u4e8e\u6ee4\u6ce2\u5668\u7684\u68af\u5ea6\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from numpy import flip\nimport numpy as np\nfrom scipy.signal import convolve2d, correlate2d\nfrom torch.nn.modules.module import Module\nfrom torch.nn.parameter import Parameter\n\n\nclass ScipyConv2dFunction(Function):\n    @staticmethod\n    def forward(ctx, input, filter, bias):\n        # detach so we can cast to NumPy\n        input, filter, bias = input.detach(), filter.detach(), bias.detach()\n        result = correlate2d(input.numpy(), filter.numpy(), mode='valid')\n        result += bias.numpy()\n        ctx.save_for_backward(input, filter, bias)\n        return torch.as_tensor(result, dtype=input.dtype)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        grad_output = grad_output.detach()\n        input, filter, bias = ctx.saved_tensors\n        grad_output = grad_output.numpy()\n        grad_bias = np.sum(grad_output, keepdims=True)\n        grad_input = convolve2d(grad_output, filter.numpy(), mode='full')\n        # the previous line can be expressed equivalently as:\n        # grad_input = correlate2d(grad_output, flip(flip(filter.numpy(), axis=0), axis=1), mode='full')\n        grad_filter = correlate2d(input.numpy(), grad_output, mode='valid')\n        return torch.from_numpy(grad_input), torch.from_numpy(grad_filter).to(torch.float), torch.from_numpy(grad_bias).to(torch.float)\n\n\nclass ScipyConv2d(Module):\n    def __init__(self, filter_width, filter_height):\n        super(ScipyConv2d, self).__init__()\n        self.filter = Parameter(torch.randn(filter_width, filter_height))\n        self.bias = Parameter(torch.randn(1, 1))\n\n    def forward(self, input):\n        return ScipyConv2dFunction.apply(input, self.filter, self.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\u7528\u6cd5\u793a\u4f8b:**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "module = ScipyConv2d(3, 3)\nprint(\"Filter and bias: \", list(module.parameters()))\ninput = torch.randn(10, 10, requires_grad=True)\noutput = module(input)\nprint(\"Output from the convolution: \", output)\noutput.backward(torch.randn(8, 8))\nprint(\"Gradient for the input map: \", input.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\u68c0\u67e5\u68af\u5ea6:**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.autograd.gradcheck import gradcheck\n\nmoduleConv = ScipyConv2d(3, 3)\n\ninput = [torch.randn(20, 20, dtype=torch.double, requires_grad=True)]\ntest = gradcheck(moduleConv, input, eps=1e-6, atol=1e-4)\nprint(\"Are the gradients correct: \", test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}