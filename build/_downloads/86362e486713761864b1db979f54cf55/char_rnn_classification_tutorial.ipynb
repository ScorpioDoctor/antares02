{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u4f7f\u7528\u5b57\u7b26\u7ea7RNN\u5bf9\u540d\u5b57\u5206\u7c7b\n*********************************************\n**\u7ffb\u8bd1\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`_\n\n\u6211\u4eec\u5c06\u5efa\u7acb\u548c\u8bad\u7ec3\u4e00\u4e2a\u57fa\u672c\u7684\u5b57\u7b26\u7ea7RNN\u6765\u5bf9\u5355\u8bcd\u8fdb\u884c\u5206\u7c7b\u3002\n\u5b57\u7b26\u7ea7RNN\u5c06\u5355\u8bcd\u8bfb\u53d6\u4e3a\u4e00\u7cfb\u5217\u5b57\u7b26(characters)-\u5728\u6bcf\u4e00\u6b65\u8f93\u51fa\u4e00\u4e2a\u9884\u6d4b\u548c\u201c\u9690\u85cf\u72b6\u6001(hidden state)\u201d\uff0c\n\u5c06\u5176\u5148\u524d\u7684\u9690\u85cf\u72b6\u6001\u8f93\u5165\u5230\u4e0b\u4e00\u6b65\u3002\u6211\u4eec\u5c06\u6700\u540e\u7684\u9884\u6d4b\u4f5c\u4e3a\u8f93\u51fa\uff0c\u5373\u5355\u8bcd\u5c5e\u4e8e\u54ea\u4e00\u7c7b\u3002\n\n\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5c06\u5bf9\u6765\u81ea18\u79cd\u8bed\u8a00\u7684\u51e0\u5343\u4e2a\u59d3\u6c0f(surnames)\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u6839\u636e\u62fc\u5199\u9884\u6d4b\u4e00\u4e2a\u540d\u5b57\u6765\u81ea\u54ea\u79cd\u8bed\u8a00\uff1a\n\n::\n\n    $ python predict.py Hinton\n    (-0.47) Scottish\n    (-1.52) English\n    (-3.57) Irish\n\n    $ python predict.py Schmidhuber\n    (-0.19) German\n    (-2.48) Czech\n    (-2.68) Dutch\n\n\n**\u63a8\u8350\u9605\u8bfb:**\n\n\u6211\u5047\u5b9a\u4f60\u6700\u8fd1\u624d\u5b89\u88c5\u4e86 PyTorch, \u77e5\u9053 Python, \u5e76\u4e14\u7406\u89e3 \u5f20\u91cf(Tensors)\u662f\u4ec0\u4e48\u4e1c\u897f:\n\n-  https://pytorch.org/ \u67e5\u770b\u5b89\u88c5\u6307\u5357\n-  :doc:`/beginner/deep_learning_60min_blitz` \u5728\u8fd9\u4e2a\u7ae0\u8282\u83b7\u5f97PyTorch\u7684\u8d77\u6b65\u77e5\u8bc6\n-  :doc:`/beginner/pytorch_with_examples` \u83b7\u5f97\u4e00\u4e2a\u5bbd\u6cdb\u800c\u6709\u6df1\u5ea6\u7684\u6982\u89c8\n-  :doc:`/beginner/former_torchies_tutorial` \u5982\u679c\u60a8\u662f\u524dLua Torch\u7528\u6237\n\n\u5982\u679c\u4e86\u89e3 RNNs \u5e76\u77e5\u9053\u5b83\u4eec\u7684\u5de5\u4f5c\u539f\u7406\u5c06\u4f1a\u5f88\u6709\u7528:\n\n-  `\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u5408\u7406\u6709\u6548\u6027 <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__ \u5c55\u793a\u4e86\u597d\u591a\u7684\u771f\u5b9e\u751f\u6d3b\u6848\u4f8b\u3002\n-  `\u7406\u89e3 LSTM \u7f51\u7edc <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__ \u8fd9\u7bc7\u6587\u7ae0\u662f\u4e13\u95e8\u5173\u4e8eLSTMs\u7684\uff0c\u4e5f\u6709\u5173\u4e8eRNNs\u7684\u901a\u7528\u7684\u4fe1\u606f\u3002\n\n\u51c6\u5907\u6570\u636e\n==================\n\n.. Note::\n   \u4ece `\u8fd9\u513f <https://download.pytorch.org/tutorial/data.zip>`_\n   \u4e0b\u8f7d\u6570\u636e\u5e76\u62bd\u53d6\u5230\u5f53\u524d\u76ee\u5f55\u3002\n\n\u5305\u542b\u5728 ``data/names`` \u76ee\u5f55\u4e2d\u7684\u662f 18 \u4e2a\u6587\u672c\u6587\u4ef6\uff0c\u53d6\u540d\u4e3a \"[Language].txt\"\u3002 \u6bcf\u4e2a\u6587\u4ef6\u5305\u542b\u5f88\u591a\u540d\u5b57\uff0c\u4e00\u4e2a\u540d\u5b57\u5360\u4e00\u884c\n\u5927\u591a\u6570\u7528\u62c9\u4e01\u5b57\u6bcd\u62fc\u5199 (\u4f46\u662f\u6211\u4eec\u4ecd\u7136\u9700\u8981\u5c06\u5b83\u4eec\u4ece Unicode \u8f6c\u6362\u4e3a ASCII)\u3002\n\n\u6700\u540e\uff0c\u6211\u4eec\u5c06\u5f97\u5230\u4e00\u672c\u8bcd\u5178\uff0c\u5176\u4e2d\u5217\u51fa\u4e86\u6bcf\u79cd\u8bed\u8a00\u7684\u540d\u5b57(names)\u5217\u8868\uff0c ``{language: [names ...]}`` \u3002\n\u6cdb\u5316\u53d8\u91cf\u201ccategory\u201d\u548c\u201cline\u201d(\u5728\u672c\u4f8b\u4e2d\u7528\u4e8e\u8bed\u8a00\u548c\u540d\u5b57)\u7528\u4e8e\u4ee5\u540e\u7684\u53ef\u6269\u5c55\u6027\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport glob\nimport os\n\ndef findFiles(path): return glob.glob(path)\n\nprint(findFiles('./data/names/*.txt'))\n\nimport unicodedata\nimport string\n\nall_letters = string.ascii_letters + \" .,;'\"\nn_letters = len(all_letters)\n\n# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in all_letters\n    )\n\nprint(unicodeToAscii('\u015alus\u00e0rski'))\n\n# Build the category_lines dictionary, a list of names per language\ncategory_lines = {}\nall_categories = []\n\n# Read a file and split into lines\ndef readLines(filename):\n    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n    return [unicodeToAscii(line) for line in lines]\n\nfor filename in findFiles('./data/names/*.txt'):\n    category = os.path.splitext(os.path.basename(filename))[0]\n    all_categories.append(category)\n    lines = readLines(filename)\n    category_lines[category] = lines\n\nn_categories = len(all_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728\u6211\u4eec\u6709\u4e86 ``category_lines`` \uff0c\u8fd9\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u5c06\u6bcf\u4e2a\u7c7b\u522b(\u8bed\u8a00)\u6620\u5c04\u5230\u4e00\u884c(\u540d\u5b57)\u7684\u5217\u8868\u4e2d\u3002\n\u6211\u4eec\u8fd8\u8ddf\u8e2a\u4e86 ``all_categories`` (\u53ea\u662f\u4e00\u4e2a\u8bed\u8a00\u7684\u5217\u8868)\u548c ``n_categories`` \uff0c\u4ee5\u4f9b\u4ee5\u540e\u53c2\u8003\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(category_lines['Italian'][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u628a\u540d\u5b57(Names)\u8f6c\u6362\u4e3a\u5f20\u91cf\n--------------------------\n\n\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u7ec4\u7ec7\u597d\u4e86\u6240\u6709\u7684\u540d\u5b57\uff0c\u6211\u4eec\u9700\u8981\u628a\u5b83\u4eec\u8f6c\u6362\u6210\u5f20\u91cf\u6765\u4f7f\u7528\u5b83\u4eec\u3002\n\n\u4e3a\u4e86\u8868\u793a\u5355\u4e2a\u5b57\u6bcd\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2asize\u4e3a ``<1 x n_letters>`` \u7684 \u201cone-hot vector\u201d \u3002\none-hot vector\u586b\u5145\u4e860\uff0c\u9664\u4e86\u5f53\u524d\u5b57\u6bcd\u7d22\u5f15\u5904\u76841\uff0c\u4f8b\u5982, e.g. ``\"b\" = <0 1 0 0 0 ...>`` \u3002\n\n\u4e3a\u4e86\u521b\u9020\u4e00\u4e2a\u8bcd\uff0c\u6211\u4eec\u5c06\u8fd9\u4e9b\u5143\u7d20\u52a0\u5165\u5230\u4e00\u4e2a2D\u77e9\u9635 ``<line_length x 1 x n_letters>`` \u4e2d\u3002\n\n\u8fd9\u4e2a\u989d\u5916\u7684\u4e00\u7ef4\u662f\u56e0\u4e3aPyTorch\u5047\u8bbe\u6240\u6709\u7684\u4e1c\u897f\u90fd\u662f\u6309\u6279\u6b21\u7684(batches)-\u6211\u4eec\u53ea\u662f\u5728\u8fd9\u91cc\u4f7f\u7528batch size \u4e3a 1 \u7684batch\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\n# Find letter index from all_letters, e.g. \"a\" = 0\ndef letterToIndex(letter):\n    return all_letters.find(letter)\n\n# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\ndef letterToTensor(letter):\n    tensor = torch.zeros(1, n_letters)\n    tensor[0][letterToIndex(letter)] = 1\n    return tensor\n\n# Turn a line into a <line_length x 1 x n_letters>,\n# or an array of one-hot letter vectors\ndef lineToTensor(line):\n    tensor = torch.zeros(len(line), 1, n_letters)\n    for li, letter in enumerate(line):\n        tensor[li][0][letterToIndex(letter)] = 1\n    return tensor\n\nprint(letterToTensor('J'))\n\nprint(lineToTensor('Jones').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u521b\u5efa\u7f51\u7edc\n====================\n\n\u5728\u81ea\u52a8\u68af\u5ea6\u4e4b\u524d\uff0c\u5728Torch\u4e2d\u521b\u5efa\u4e00\u4e2a\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u5728\u82e5\u5e72\u4e2a\u65f6\u95f4\u6b65\u4e2d\u514b\u9686\u4e00\u4e2a\u5c42\u7684\u53c2\u6570\u3002\n\u5c42\u5305\u542b\u9690\u85cf\u72b6\u6001\u548c\u68af\u5ea6\uff0c\u73b0\u5728\u5b8c\u5168\u7531\u56fe\u81ea\u5df1\u6765\u5904\u7406\u3002\n\u8fd9\u610f\u5473\u7740\u60a8\u53ef\u4ee5\u975e\u5e38\u201c\u7eaf\u201d\u7684\u65b9\u5f0f\u5b9e\u73b0RNN\uff0c\u4f5c\u4e3a\u5e38\u89c4\u7684\u524d\u9988\u5c42\u3002\n\n\u8fd9\u4e2a RNN module (\u4e3b\u8981\u662f\u4ece `\u4e3aTorch\u7528\u6237\u5199\u7684PyTorch\u6559\u7a0b <https://pytorch.org/tutorials/beginner/former_torchies/nn_tutorial.html#example-2-recurrent-net>`__ \u91cc\u9762\u590d\u5236\u7684)\n\u53ea\u662f\u4e24\u4e2a\u7ebf\u6027\u5c42\uff0c\u5b83\u4eec\u5728\u8f93\u5165\u548c\u9690\u85cf\u72b6\u6001\u4e0b\u5de5\u4f5c\uff0c\u8f93\u51fa\u540e\u6709\u4e00\u4e2aLogSoftmax\u5c42\u3002\n\n.. figure:: https://i.imgur.com/Z2xbySO.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        combined = torch.cat((input, hidden), 1)\n        hidden = self.i2h(combined)\n        output = self.i2o(combined)\n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)\n\nn_hidden = 128\nrnn = RNN(n_letters, n_hidden, n_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8981\u8fd0\u884c\u8fd9\u4e2a\u7f51\u7edc\u7684\u4e00\u4e2astep\uff0c\u6211\u4eec\u9700\u8981\u4f20\u9012\u4e00\u4e2a\u8f93\u5165(\u5728\u6211\u4eec\u7684\u4f8b\u5b50\u4e2d\uff0c\u662f\u5f53\u524d\u5b57\u6bcd\u7684\u5f20\u91cf)\u548c\n\u4e00\u4e2a\u5148\u524d\u7684\u9690\u85cf\u72b6\u6001(\u6211\u4eec\u9996\u5148\u5c06\u5176\u521d\u59cb\u5316\u4e3a\u96f6)\u3002\u6211\u4eec\u5c06\u8fd4\u56de\u8f93\u51fa(\u6bcf\u79cd\u8bed\u8a00\u7684\u6982\u7387)\u548c\n\u4e0b\u4e00\u4e2a\u9690\u85cf\u72b6\u6001(\u6211\u4eec\u5c06\u5728\u4e0b\u4e00\u6b65\u4fdd\u6301\u8fd9\u79cd\u72b6\u6001)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input = letterToTensor('A')\nhidden =torch.zeros(1, n_hidden)\n\noutput, next_hidden = rnn(input, hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e3a\u4e86\u63d0\u9ad8\u6548\u7387\uff0c\u6211\u4eec\u4e0d\u60f3\u4e3a\u6bcf\u4e00\u6b65\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u4f7f\u7528 ``lineToTensor``  \n\u800c\u4e0d\u662f ``letterToTensor`` \u5e76\u4f7f\u7528\u5207\u7247\u3002\n\u8fd9\u53ef\u4ee5\u901a\u8fc7\u9884\u8ba1\u7b97\u5f20\u91cf\u7684batches\u6765\u8fdb\u4e00\u6b65\u4f18\u5316\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input = lineToTensor('Albert')\nhidden = torch.zeros(1, n_hidden)\n\noutput, next_hidden = rnn(input[0], hidden)\nprint(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5982\u60a8\u6240\u89c1\uff0c\u8f93\u51fa\u662f ``<1 x n_categories>`` \u5f20\u91cf\uff0c\u5176\u4e2d\u6bcf\u4e2aitem\u90fd\u662f\u8be5\u7c7b\u522b\u7684\u53ef\u80fd\u6027(likelihood)\n(\u66f4\u9ad8\u7684\u53ef\u80fd\u6027\u66f4\u5927)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\n========\n\u4e3a\u8bad\u7ec3\u505a\u51c6\u5907\n----------------------\n\n\u5728\u63a5\u53d7\u8bad\u7ec3\u4e4b\u524d\uff0c\u6211\u4eec\u5e94\u8be5\u505a\u4e00\u4e9b\u8f85\u52a9\u51fd\u6570\u3002\u9996\u5148\u662f\u89e3\u91ca\u7f51\u7edc\u7684\u8f93\u51fa\uff0c\n\u6211\u4eec\u77e5\u9053\u7f51\u7edc\u8f93\u51fa\u662f\u6bcf\u4e2a\u7c7b\u522b\u7684\u53ef\u80fd\u6027\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 ``Tensor.topk`` \u83b7\u5f97\u6700\u5927\u503c\u5bf9\u5e94\u7684\u7d22\u5f15\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def categoryFromOutput(output):\n    top_n, top_i = output.topk(1)\n    category_i = top_i[0].item()\n    return all_categories[category_i], category_i\n\nprint(categoryFromOutput(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u8fd8\u9700\u8981\u4e00\u79cd\u5feb\u901f\u83b7\u53d6\u8bad\u7ec3\u6837\u4f8b(\u540d\u79f0\u53ca\u5176\u8bed\u8a00)\u7684\u65b9\u6cd5\uff1a \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\ndef randomChoice(l):\n    return l[random.randint(0, len(l) - 1)]\n\ndef randomTrainingExample():\n    category = randomChoice(all_categories)\n    line = randomChoice(category_lines[category])\n    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n    line_tensor = lineToTensor(line)\n    return category, line, category_tensor, line_tensor\n\nfor i in range(10):\n    category, line, category_tensor, line_tensor = randomTrainingExample()\n    print('category =', category, '/ line =', line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u7f51\u7edc\n--------------------\n\n\u73b0\u5728\u8bad\u7ec3\u8fd9\u4e2a\u7f51\u7edc\u6240\u9700\u8981\u7684\u5c31\u662f\u7ed9\u5b83\u5c55\u793a\u4e00\u5806\u6837\u4f8b\uff0c\u8ba9\u5b83\u53bb\u731c\u6d4b\uff0c\u5982\u679c\u5b83\u9519\u4e86\uff0c\u5c31\u544a\u8bc9\u5b83\u72af\u9519\u4e86\u3002\n\n\u5bf9\u4e8e\u635f\u5931\u51fd\u6570  ``nn.NLLLoss`` \u662f\u5408\u9002\u7684\uff0c\u56e0\u4e3aRNN\u7684\u6700\u540e\u4e00\u5c42\u662f ``nn.LogSoftmax`` \u3002 \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u7684\u6bcf\u4e2a\u5faa\u73af\u90fd:\n\n-  \u521b\u5efa\u8f93\u5165\u5f20\u91cf\u548c\u76ee\u6807\u5f20\u91cf\n-  \u521b\u5efa\u96f6\u521d\u59cb\u5316\u7684\u9690\u85cf\u72b6\u6001\n-  \u628a\u6bcf\u4e00\u4e2a\u5b57\u7b26\u8bfb\u8fdb\u6765\uff0c\u5e76\u4e14\n\n   -  \u4e3a\u4e0b\u4e00\u4e2a\u5b57\u7b26\u4fdd\u7559\u9690\u85cf\u72b6\u6001\n\n-  \u5c06\u6700\u7ec8\u8f93\u51fa\u4e0e\u76ee\u6807\u503c\u8fdb\u884c\u5bf9\u6bd4\u3002\n-  \u53cd\u5411\u4f20\u64ad\n-  \u8fd4\u56de\u8f93\u51fa\u548c\u635f\u5931\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n\ndef train(category_tensor, line_tensor):\n    hidden = rnn.initHidden()\n\n    rnn.zero_grad()\n\n    for i in range(line_tensor.size()[0]):\n        output, hidden = rnn(line_tensor[i], hidden)\n\n    loss = criterion(output, category_tensor)\n    loss.backward()\n\n    # Add parameters' gradients to their values, multiplied by learning rate\n    for p in rnn.parameters():\n        p.data.add_(-learning_rate, p.grad.data)\n\n    return output, loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728\u6211\u4eec\u53ea\u9700\u8981\u7528\u4e00\u5806\u6837\u4f8b\u6765\u5206\u6790\u8fd9\u4e2a\u95ee\u9898\u3002\u7531\u4e8e ``train`` \u51fd\u6570\u8fd4\u56de\u8f93\u51fa\u548c\u635f\u5931\uff0c\u6211\u4eec\u53ef\u4ee5\u6253\u5370\u5b83\u7684\u731c\u6d4b\uff0c\n\u4e5f\u53ef\u4ee5\u8ddf\u8e2a\u635f\u5931\u8fdb\u884c\u7ed8\u56fe\u3002\u7531\u4e8e\u67091000\u4e2a\u6837\u4f8b(examples)\uff0c\u6211\u4eec\u53ea\u6253\u5370\u6bcf\u4e00\u4e2a ``print_every`` \u6837\u4f8b\uff0c\n\u5e76\u53d6\u4e00\u4e2a\u5e73\u5747\u635f\u5931\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\nn_iters = 100000\nprint_every = 5000\nplot_every = 1000\n\n\n\n# Keep track of losses for plotting\ncurrent_loss = 0\nall_losses = []\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\nstart = time.time()\n\nfor iter in range(1, n_iters + 1):\n    category, line, category_tensor, line_tensor = randomTrainingExample()\n    output, loss = train(category_tensor, line_tensor)\n    current_loss += loss\n\n    # Print iter number, loss, name and guess\n    if iter % print_every == 0:\n        guess, guess_i = categoryFromOutput(output)\n        correct = '\u2713' if guess == category else '\u2717 (%s)' % category\n        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n\n    # Add current loss avg to list of losses\n    if iter % plot_every == 0:\n        all_losses.append(current_loss / plot_every)\n        current_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ed8\u5236\u7ed3\u679c\n--------------------\n\n\u4ece ``all_losses`` \u7ed8\u5236\u5386\u53f2\u635f\u5931\u6765\u5c55\u793a\u7f51\u7edc\u7684\u5b66\u4e60:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nplt.figure()\nplt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bc4\u4f30\u7ed3\u679c\n======================\n\n\u4e3a\u4e86\u67e5\u770b\u7f51\u7edc\u5728\u4e0d\u540c\u7c7b\u522b\u4e0a\u7684\u6027\u80fd\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u4e00\u4e2a\u6df7\u6dc6\u77e9\u9635\uff0c\u4e3a\u6bcf\u79cd\u5b9e\u9645\u8bed\u8a00(\u884c)\u6307\u793a\u7f51\u7edc\u731c\u6d4b\u7684\u8bed\u8a00(\u5217)\u3002\n\u4e3a\u4e86\u8ba1\u7b97\u6df7\u6dc6\u77e9\u9635\uff0c\u8fd0\u884c ``evaluate()`` \u4f7f\u4e00\u5806\u6837\u672c\u5728\u7f51\u7edc\u4e2d\u901a\u8fc7\uff0c\u8fd9\u4e0e\u9664\u53bb\u4e86\u53cd\u5411\u4f20\u64ad\u7684 ``train()`` \u76f8\u540c\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Keep track of correct guesses in a confusion matrix\nconfusion = torch.zeros(n_categories, n_categories)\nn_confusion = 10000\n\n# Just return an output given a line\ndef evaluate(line_tensor):\n    hidden = rnn.initHidden()\n\n    for i in range(line_tensor.size()[0]):\n        output, hidden = rnn(line_tensor[i], hidden)\n\n    return output\n\n# Go through a bunch of examples and record which are correctly guessed\nfor i in range(n_confusion):\n    category, line, category_tensor, line_tensor = randomTrainingExample()\n    output = evaluate(line_tensor)\n    guess, guess_i = categoryFromOutput(output)\n    category_i = all_categories.index(category)\n    confusion[category_i][guess_i] += 1\n\n# Normalize by dividing every row by its sum\nfor i in range(n_categories):\n    confusion[i] = confusion[i] / confusion[i].sum()\n\n# Set up plot\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(confusion.numpy())\nfig.colorbar(cax)\n\n# Set up axes\nax.set_xticklabels([''] + all_categories, rotation=90)\nax.set_yticklabels([''] + all_categories)\n\n# Force label at every tick\nax.xaxis.set_major_locator(ticker.MultipleLocator(1))\nax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n# sphinx_gallery_thumbnail_number = 2\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4f60\u53ef\u4ee5\u4ece\u4e3b\u8f74\u4e0a\u627e\u51fa\u4eae\u70b9\uff0c\u663e\u793a\u5b83\u731c\u9519\u4e86\u54ea\u79cd\u8bed\u8a00\uff0c\u4f8b\u5982Chinese for Korean, \u548c Spanish for Italian\u3002\n\u5b83\u4f3c\u4e4e\u5728\u5e0c\u814a\u8bed\u65b9\u9762\u505a\u5f97\u5f88\u597d\uff0c\u5728\u82f1\u8bed\u65b9\u9762\u5219\u5f88\u5dee(\u4e5f\u8bb8\u662f\u56e0\u4e3a\u4e0e\u5176\u4ed6\u8bed\u8a00\u7684\u91cd\u53e0)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd0\u884c\u6211\u4eec\u7684\u7528\u6237\u8f93\u5165\n---------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def predict(input_line, n_predictions=3):\n    print('\\n> %s' % input_line)\n    with torch.no_grad():\n        output = evaluate(lineToTensor(input_line))\n\n        # Get top N categories\n        topv, topi = output.topk(n_predictions, 1, True)\n        predictions = []\n\n        for i in range(n_predictions):\n            value = topv[0][i].item()\n            category_index = topi[0][i].item()\n            print('(%.2f) %s' % (value, all_categories[category_index]))\n            predictions.append([value, all_categories[category_index]])\n\npredict('Dovesky')\npredict('Jackson')\npredict('Satoshi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`PyTorch \u5b9e\u6218 <https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>`__ \n\u7684\u6700\u7ec8\u7248\u672c\u5c06\u4e0a\u9762\u7684\u4ee3\u7801\u5206\u6210\u51e0\u4e2a\u6587\u4ef6:\n\n-  ``data.py`` (\u52a0\u8f7d\u6587\u4ef6)\n-  ``model.py`` (\u5b9a\u4e49 RNN)\n-  ``train.py`` (\u8fd0\u884c\u8bad\u7ec3\u8fc7\u7a0b)\n-  ``predict.py`` (\u4f7f\u7528\u547d\u4ee4\u884c\u53c2\u6570\u8fd0\u884c ``predict()`` )\n-  ``server.py`` (\u4f7f\u7528 bottle.py \u628a\u9884\u6d4b\u4f5c\u4e3aJSON API)\n\n\u8fd0\u884c ``train.py`` \u6765\u8bad\u7ec3\u548c\u4fdd\u5b58\u7f51\u7edc\u3002\n\n\u4f7f\u7528\u4e00\u4e2a name \u8fd0\u884c ``predict.py`` \u6765\u67e5\u770b\u9884\u6d4b\u7ed3\u679c:\n\n::\n\n    $ python predict.py Hazaki\n    (-0.42) Japanese\n    (-1.39) Polish\n    (-3.51) Czech\n\n\u8fd0\u884c ``server.py`` \u5e76\u8bbf\u95ee  http://localhost:5533/Yourname \u6765\u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ec3\u4e60\n=========\n\n-  \u5c1d\u8bd5\u5177\u6709 line -> category \u8fd9\u79cd\u7ed3\u6784\u7684\u5176\u4ed6\u6570\u636e\u96c6, \u4f8b\u5982:\n\n   -  \u4efb\u610f\u5355\u8bcd -> \u8bed\u8a00\n   -  First name -> \u6027\u522b\n   -  \u4eba\u7269\u89d2\u8272 -> \u4f5c\u8005\n   -  \u9875\u6807\u9898 -> \u535a\u5ba2\n\n-  \u7528\u4e00\u4e2a\u66f4\u5927 \u548c/\u6216 \u66f4\u597d\u7684\u7f51\u7edc\u83b7\u5f97\u66f4\u597d\u7684\u6548\u679c\n\n   -  \u6dfb\u52a0\u66f4\u591a\u7684\u7ebf\u6027\u5c42\n   -  \u5c1d\u8bd5 ``nn.LSTM`` \u548c ``nn.GRU`` layers\n   -  \u5c06\u8fd9\u4e9bRNNs\u4e2d\u7684\u591a\u4e2a\u5408\u5e76\u4e3a\u66f4\u9ad8\u7ea7\u522b\u7684\u7f51\u7edc\u3002\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}