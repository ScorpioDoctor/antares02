{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u5728CIFAR100\u4e0a\u8bad\u7ec3CNN\n==============================\n\n**\u4f5c\u8005**: `Antares\u535a\u58eb <http://www.studyai.com/antares>`__\n\n\u6211\u4eec\u5c06\u91c7\u53d6\u4ee5\u4e0b\u6b65\u9aa4:\n\n1. \u4f7f\u7528 ``torchvision`` \u52a0\u8f7d\u548c\u89c4\u8303\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\n2. \u5b9a\u4e49\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\n3. \u5c06\u6a21\u578b\u5199\u5165\u6587\u4ef6\u5e76\u7528TensorBoardX\u67e5\u770b\n4. \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\n5. \u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u8bad\u7ec3\u7f51\u7edc\n6. \u5728\u6d4b\u8bd5\u6570\u636e\u4e0a\u6d4b\u8bd5\u7f51\u7edc\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\n\n# \u5ffd\u7565 warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cifar100 \u6570\u636e\u96c6\u7684\u52a0\u8f7d\u4e0e\u9884\u5904\u7406\n-------------------------------------------\n\nCIFAR-100 dataset: \u6570\u636e\u96c6\u5305\u542b100\u5c0f\u7c7b\uff0c\u6bcf\u5c0f\u7c7b\u5305\u542b600\u4e2a\u56fe\u50cf\uff0c\u5176\u4e2d\u6709500\u4e2a\u8bad\u7ec3\u56fe\u50cf\u548c100\u4e2a\u6d4b\u8bd5\u56fe\u50cf\u3002\n100\u7c7b\u88ab\u5206\u7ec4\u4e3a20\u4e2a\u5927\u7c7b\u3002\u6bcf\u4e2a\u56fe\u50cf\u5e26\u67091\u4e2a\u5c0f\u7c7b\u7684\u201cfine\u201d\u6807\u7b7e\u548c1\u4e2a\u5927\u7c7b\u201ccoarse\u201d\u6807\u7b7e\u3002\n\u6570\u636e\u96c6\u4e2d\u6837\u672c\u7684\u987a\u5e8f\u662f\u968f\u673a\u7684\uff0c\u67d0\u4e9b\u8bad\u7ec3\u6279\u6b21\u5185\u5404\u4e2a\u7c7b\u7684\u6837\u672c\u6570\u91cf\u4e0d\u4e00\u5b9a\u4e25\u683c\u76f8\u540c\n\u8be6\u7ec6\u4fe1\u606f\u770b\u5b98\u7f51\uff1ahttp://www.cs.toronto.edu/~kriz/cifar.html\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49\u53d8\u6362\uff0c\u52a0\u8f7d\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n\ntransform_train = transforms.Compose([transforms.Pad(4), transforms.RandomCrop(32), \n                                      transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n\ntransform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR100(root='./data/cifar100', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR100(root='./data/cifar100', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# \u8fd9\u6837\u7b97\u51fa\u6765\u7684\u6837\u672c\u6570\u91cf\u4e0d\u662f\u5f88\u4e25\u683c\nprint(\"\u8bad\u7ec3\u96c6\u5927\u5c0f\uff1a\",len(trainloader)*batch_size)\nprint(\"\u6d4b\u8bd5\u96c6\u5927\u5c0f\uff1a\",len(testloader)*batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u6807\u7b7e\u540d\u79f0\u6587\u4ef6\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\nlabels_filepath = \"./data/cifar100/cifar-100-python/meta\"\nlabels_dict = unpickle(labels_filepath)\n\nprint(labels_dict.keys(),'\\n')\n\nclasses = labels_dict[b'fine_label_names']\nsuperclasses = labels_dict[b'coarse_label_names']\n\nprint(\"100\u4e2a\u7cbe\u7ec6\u5206\u7c7b\u7684\u540d\u79f0\uff1a\", classes,'\\n')\nprint(\"20\u4e2a\u7c97\u7565\u5206\u7c7b\u7684\u540d\u79f0\uff1a\", superclasses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5c55\u793a\u4e00\u4e2a\u6279\u6b21\u7684\u56fe\u7247\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u7528\u4e8e\u663e\u793a\u4e00\u5f20\u56fe\u50cf\u7684\u51fd\u6570\ndef imshow(img, title=None):\n    img = img / 2 + 0.5     # \u53bb\u5f52\u4e00\u5316\n    npimg = img.numpy()\n    plt.figure(figsize=[6.5, 2.5])\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.axis('off')\n    if title is not None:\n        plt.title(title)\n    plt.show()\n    plt.pause(0.1)\n\n# \u83b7\u53d6\u4e00\u4e2a\u6279\u6b21\u7684\u56fe\u50cf\uff0c\u4e00\u6b21\u8fed\u4ee3\u53d6\u51fabatch_size\u5f20\u56fe\u7247\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# \u663e\u793a\u4e00\u4e2a\u6279\u6b21\u7684\u56fe\u50cf\nimshow(torchvision.utils.make_grid(images),\"One Batch Train Images\")\n# \u8f93\u51fa \u5bf9\u5e94\u6279\u6b21\u56fe\u50cf\u7684\u6807\u7b7e\nprint(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49CNN\u7f51\u7edc\u6a21\u578b\n---------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom collections import OrderedDict\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1), # 32\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2), # 16\n\n            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 16\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2), # 8\n                      \n            nn.Conv2d(64, 64, kernel_size=3, padding=1), # 8\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2), # 4\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(64 * 4 * 4, 128),\n            nn.ReLU(inplace=True),\n            nn.Linear(128, 100)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n    \nmodel_urls = {\n    'cifar100': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/cifar100-3a55a987.pth',\n}\n\nclass CIFAR(nn.Module):\n    def __init__(self, features, n_channel, num_classes):\n        super(CIFAR, self).__init__()\n        assert isinstance(features, nn.Sequential), type(features)\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(n_channel, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for i, v in enumerate(cfg):\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            padding = v[1] if isinstance(v, tuple) else 1\n            out_channels = v[0] if isinstance(v, tuple) else v\n            conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(out_channels, affine=False), nn.ReLU()]\n            else:\n                layers += [conv2d, nn.ReLU()]\n            in_channels = out_channels\n    return nn.Sequential(*layers)\n\ndef cifar100(n_channel, pretrained=None):\n    cfg = [n_channel, n_channel, 'M', 2*n_channel, 2*n_channel, 'M', 4*n_channel, 4*n_channel, 'M', (8*n_channel, 0), 'M']\n    layers = make_layers(cfg, batch_norm=True)\n    model = CIFAR(layers, n_channel=8*n_channel, num_classes=100)\n    if pretrained is not None:\n        m = model_zoo.load_url(model_urls['cifar100'])\n        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n        model.load_state_dict(state_dict)\n    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5c06\u6a21\u578b\u5199\u5165\u6587\u4ef6\u5e76\u7528TensorBoardX\u67e5\u770b\n-----------------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tensorboardX import SummaryWriter\n\n# \u865a\u62df\u8f93\u5165\uff0c\u4e0e CIFAR10 \u7684\u4e00\u4e2abatch\u6570\u636e\u7684shape\u76f8\u540c\ndummy_input = torch.autograd.Variable(torch.rand(batch_size, 3, 32, 32))\n\nmodel = cifar100(n_channel=32, pretrained=None)\n#\u6216 model = SimpleNet()\n\nprint(model)\n\nwith SummaryWriter(comment='_cifar100_net') as w:\n    w.add_graph(model, (dummy_input, ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u628a\u6a21\u578b\u8fc1\u79fb\u5230GPU\u4e0a\n----------------------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed = 117\ncuda = torch.cuda.is_available()\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nnet = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\n----------------------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n\nloss = nn.CrossEntropyLoss()\n# loss = F.cross_entropy\n\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n# optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8ba1\u7b97\u521d\u59cb\u7f51\u7edc\u7684\u51c6\u786e\u7387\n--------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5f00\u59cb\u8bad\u7ec3\n----------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nnum_epochs = 50\nnum_batches = len(trainloader)\nlog_interval = 200\n\nbest_acc, old_file = 0, None\nt_begin = time.time()\n\ndecreasing_lr=[20, 30]\nwriter = SummaryWriter(comment='_cifar100_logs')\n\nnet.train()\n\nfor epoch in range(num_epochs):\n    \n    if epoch in decreasing_lr:\n            optimizer.param_groups[0]['lr'] *= 0.1\n            \n    running_loss = 0.0        \n    for batch_idx, batch_data in enumerate(trainloader):\n        n_iter = epoch * num_batches + batch_idx\n        images, labels = batch_data[0].to(device), batch_data[1].to(device)\n        # \u5c06\u68af\u5ea6\u6e05\u96f6\n        optimizer.zero_grad()\n        # forward\n        out = net(images)\n        # \u8ba1\u7b97\u635f\u5931\n        loss_value = loss(out, labels)\n        # backward\n        loss_value.backward()\n        # optimise\n        optimizer.step()\n        # \u5c06\u635f\u5931\u548c\u5b66\u4e60\u7387\u5199\u5165\u65e5\u5fd7\u6587\u4ef6\n        writer.add_scalar('loss', loss_value.item(), n_iter)\n        writer.add_scalar('lr', optimizer.param_groups[0]['lr'], n_iter)\n\n        running_loss += loss_value.item()\n        if batch_idx % log_interval == 0 and batch_idx > 0:\n            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / log_interval))\n            running_loss = 0.0\n\n    elapse_time = time.time() - t_begin\n    speed_epoch = elapse_time / (epoch + 1)\n    speed_batch = speed_epoch / num_batches\n    eta = speed_epoch * num_epochs - elapse_time\n    print(\"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(elapse_time, speed_epoch, speed_batch, eta))\n        \nprint(\"Total Elapse: {:.2f}, Best Result: {:.3f}%\".format(time.time()-t_begin, best_acc))\nwriter.close()\nprint('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5f00\u59cb\u6d4b\u8bd5\n----------------\n\n\u5728\u6574\u4e2a\u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7edf\u8ba1\u6bcf\u4e2a\u7c7b\u4e0a\u7684\u51c6\u786e\u7387\n~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.eval()\nnum_classes = len(classes)\nclass_correct = list(0. for i in range(num_classes))\nclass_total = list(0. for i in range(num_classes))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(labels.size()[0]):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(num_classes):\n    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5c55\u793a\u6d4b\u8bd5\u6837\u672c\uff0c\u771f\u5b9e\u6807\u7b7e\u548c\u9884\u6d4b\u6807\u7b7e\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images), \"One Test Batch Images\")\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n\noutputs = net(images.to(device))\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted:   ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}